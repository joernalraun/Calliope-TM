<!doctype html>
<html lang="de">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<title>Calliope Teachable Machine</title>

<!-- TensorFlow.js / MobileNet -->
<script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@4.11.0/dist/tf.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/mobilenet@2.1.0/dist/mobilenet.min.js"></script>
<!-- JSZip for creating zip files -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/jszip/3.10.1/jszip.min.js"></script>
<!-- FileSaver.js for downloading files -->
<script src="https://cdnjs.cloudflare.com/ajax/libs/FileSaver.js/2.0.5/FileSaver.min.js"></script>
<!-- Chart.js for graphs -->
<script src="https://cdn.jsdelivr.net/npm/chart.js@4.3.0/dist/chart.umd.min.js"></script>

<style>
:root {
  --md-sys-color-primary: 0, 0, 0;
  --md-sys-color-on-primary: 255, 255, 255;
  --md-sys-color-primary-container: 0, 0, 0, 0.2;
  --md-sys-color-on-primary-container: 28, 52, 8;

  --md-sys-color-secondary: 67, 160, 219;
  --md-sys-color-on-secondary: 255, 255, 255;
  --md-sys-color-secondary-container: 173, 245, 76;
  --md-sys-color-on-secondary-container: 8, 37, 52;

  --md-sys-color-tertiary: 187, 239, 83;
  --md-sys-color-on-tertiary: 219, 251, 128;
  --md-sys-color-tertiary-container: 187, 239, 83;
  --md-sys-color-on-tertiary-container: 219, 251, 128;

  --md-sys-color-hover: 152, 163, 167;

  --md-sys-color-error: 186, 26, 26;
  --md-sys-color-on-error: 255, 255, 255;
  --md-sys-color-error-container: 255, 218, 214;
  --md-sys-color-on-error-container: 65, 0, 2;

  --md-sys-color-surface: 255, 255, 255;
  --md-sys-color-on-surface: 28, 27, 31;
  --md-sys-color-surface-variant: 232, 234, 237;
  --md-sys-color-on-surface-variant: 70, 70, 79;
  --md-sys-color-outline: 118, 118, 128;
  --md-sys-color-outline-variant: 202, 204, 211;

  --md-sys-color-background: 250, 250, 253;
  --md-sys-color-on-background: 28, 27, 31;

  --md-sys-elevation-1: 0 1px 3px 1px rgba(0, 0, 0, 0.15), 0 1px 2px 0 rgba(0, 0, 0, 0.3);
  --md-sys-elevation-2: 0 2px 6px 2px rgba(0, 0, 0, 0.15), 0 1px 2px 0 rgba(0, 0, 0, 0.3);
  --md-sys-elevation-3: 0 4px 8px 3px rgba(0, 0, 0, 0.15), 0 1px 3px 0 rgba(0, 0, 0, 0.3);

  --md-sys-typescale-body-medium-font: 'Inter', system-ui, -apple-system, sans-serif;
  --md-sys-typescale-body-medium-size: 14px;
  --md-sys-typescale-body-medium-line-height: 20px;
  --md-sys-typescale-label-large-font: 'Inter', system-ui, -apple-system, sans-serif;
  --md-sys-typescale-label-large-size: 14px;
  --md-sys-typescale-label-large-line-height: 20px;
  --md-sys-typescale-title-medium-font: 'Inter', system-ui, -apple-system, sans-serif;
  --md-sys-typescale-title-medium-size: 16px;
  --md-sys-typescale-title-medium-line-height: 24px;

  --md-sys-shape-corner-small: 8px;
  --md-sys-shape-corner-medium: 12px;
  --md-sys-shape-corner-large: 16px;
  --md-sys-shape-corner-extra-large: 28px;

  --btn-green: 83, 100%, 48%;
  --btn-green-light: 83, 100%, 58%;
  --btn-text-dark: 0, 0%, 0%;
  --btn-text-light: 0, 0%, 100%;
}

* {
  box-sizing: border-box;
}

html, body {
  height: 100%;
  margin: 0;
  background: rgb(var(--md-sys-color-background));
  color: rgb(var(--md-sys-color-on-background));
  font-family: var(--md-sys-typescale-body-medium-font);
  font-size: var(--md-sys-typescale-body-medium-size);
  line-height: var(--md-sys-typescale-body-medium-line-height);
}

body {
  margin-top: 50px;
}

/* ==== UNIFIED BUTTON STYLES ==== */
button,
label.file-label {
  background: rgb(var(--md-sys-color-primary));
  color: rgb(var(--md-sys-color-on-primary));
  border: none;
  border-radius: var(--md-sys-shape-corner-small);
  padding: 10px 24px;
  cursor: pointer;
  user-select: none;
  font-family: var(--md-sys-typescale-label-large-font);
  font-size: var(--md-sys-typescale-label-large-size);
  line-height: var(--md-sys-typescale-label-large-line-height);
  font-weight: 500;
  letter-spacing: 0.1px;
  transition: all 0.2s cubic-bezier(0.2, 0, 0, 1);
  box-shadow: var(--md-sys-elevation-1);
  min-height: 40px;
  display: inline-flex;
  align-items: center;
  justify-content: center;
  text-align: center;
  vertical-align: middle;
}

button:hover,
label.file-label:hover {
  box-shadow: var(--md-sys-elevation-2);
  background: hsl(var(--md-sys-color-hover), 0.9);
}

button:active {
  box-shadow: var(--md-sys-elevation-1);
}

button:disabled {
  background: rgba(var(--md-sys-color-on-surface), 0.12);
  color: rgba(var(--md-sys-color-on-surface), 0.38);
  box-shadow: none;
  cursor: not-allowed;
}

button.ghost,
label.file-label {
  background: transparent;
  color: rgb(var(--md-sys-color-primary));
  border: 1px solid rgb(var(--md-sys-color-outline));
  box-shadow: none;
}

button.ghost:hover,
label.file-label:hover {
  background: rgba(var(--md-sys-color-primary), 0.08);
  border-color: rgb(var(--md-sys-color-primary));
  box-shadow: none;
}

button.ghost:active,
label.file-label:active {
  background: rgba(var(--md-sys-color-primary), 0.12);
}

button.active {
  background: rgb(var(--md-sys-color-tertiary));
  color: rgb(var(--md-sys-color-on-tertiary), 0.9);
}

button.active:hover {
  background: rgb(var(--md-sys-color-tertiary));
}

/* Left panel button hover override */
.left-panel button:hover,
.left-panel label.file-label:hover {
  background: rgb(var(--md-sys-color-tertiary)) !important;
  border-color: rgb(var(--md-sys-color-tertiary)) !important;
  color: black !important;
}

/* ==== LAYOUT ==== */
.app {
  display: flex;
  height: 100vh;
  padding: 0;
  gap: 16px;
}

.view {
  display: flex;
  width: 100%;
  height: 100vh;
  padding: 16px;
  gap: 16px;
}

.panel {
  background: rgb(var(--md-sys-color-surface));
  border-radius: var(--md-sys-shape-corner-large);
  padding: 16px;
  overflow: auto;
  display: flex;
  flex-direction: column;
  box-shadow: var(--md-sys-elevation-1);
}

.left-panel {
  width: 340px;
  flex-shrink: 0;
}

.right-panel {
  flex-grow: 1;
}

.full-width-panel {
  width: 100%;
  flex-grow: 1;
  position: relative;
  height: 100%;
  display: flex;
  flex-direction: column;
  padding-left: 16px;
}

/* ==== TYPOGRAPHY ==== */
h1 {
  font-family: var(--md-sys-typescale-title-medium-font);
  font-size: var(--md-sys-typescale-title-medium-size);
  line-height: var(--md-sys-typescale-title-medium-line-height);
  font-weight: 600;
  margin: 0 0 12px 0;
  color: rgb(var(--md-sys-color-on-surface));
}

label {
  font-size: var(--md-sys-typescale-label-large-size);
  font-weight: 500;
  color: rgb(var(--md-sys-color-on-surface-variant));
  display: block;
  margin-bottom: 0;
}

/* ==== FORM ELEMENTS ==== */
input[type="text"],
input[type="number"],
select {
  padding: 8px 12px;
  border-radius: var(--md-sys-shape-corner-small);
  border: 1px solid rgb(var(--md-sys-color-outline));
  background: rgb(var(--md-sys-color-surface));
  color: rgb(var(--md-sys-color-on-surface));
  font-family: var(--md-sys-typescale-body-medium-font);
  font-size: var(--md-sys-typescale-body-medium-size);
  width: 100%;
  transition: border-color 0.2s;
}

input[type="text"]:focus,
input[type="number"]:focus,
select:focus {
  outline: none;
  border-color: rgb(var(--md-sys-color-primary));
  border-width: 2px;
  padding: 7px 11px;
}

hr {
  border: none;
  border-top: 1px solid rgb(var(--md-sys-color-outline-variant));
  margin: 16px 0;
}

/* ==== CLASS LIST ==== */
.class-list {
  display: flex;
  flex-direction: column;
  gap: 8px;
  margin-top: 8px;
}

.class-item {
  display: flex;
  align-items: center;
  justify-content: space-between;
  padding: 12px;
  border-radius: var(--md-sys-shape-corner-medium);
  cursor: pointer;
  background: rgb(var(--md-sys-color-surface-variant), 0.3);
  transition: all 0.2s;
}

.class-item:hover {
  background: rgb(var(--md-sys-color-surface-variant));
  box-shadow: var(--md-sys-elevation-1);
}

.class-item.selected {
  background: rgb(var(--md-sys-color-primary-container));
  border: 2px solid rgb(var(--md-sys-color-primary));
  padding: 11px;
}

.class-name {
  flex-grow: 1;
  font-weight: 500;
  color: rgb(var(--md-sys-color-on-surface));
}

.class-item.selected .class-name {
  color: rgb(var(--md-sys-color-on-primary-container));
}

.class-actions {
  display: flex;
  gap: 4px;
}

.class-actions button {
  padding: 6px 12px;
  min-height: 32px;
}

/* ==== THUMBNAILS ==== */
#thumbs {
  display: grid;
  grid-template-columns: repeat(4, 1fr);
  gap: 8px;
  max-height: calc(3 * 68px + 2 * 8px);
  overflow-y: auto;
  padding-right: 4px;
}

.thumb {
  width: 68px;
  height: 68px;
  object-fit: cover;
  border-radius: 4px;
}

/* ==== VIDEO ==== */
.video-wrap {
  position: relative;
  border-radius: var(--md-sys-shape-corner-large);
  overflow: hidden;
  background: #000;
  height: calc(100vh - 48px);
  width: 100%;
  display: flex;
  align-items: center;
  justify-content: center;
  box-shadow: var(--md-sys-elevation-2);
}

#apply-view .video-wrap {
  height: calc(100vh - 60px);
}

video {
  width: 100%;
  height: 100%;
  object-fit: cover;
  transform: scaleX(-1); /* Mirror/flip video horizontally */
}

.overlay {
  position: absolute;
  right: 16px;
  top: 16px;
  display: flex;
  flex-direction: column;
  align-items: flex-end;
  gap: 8px;
  z-index: 2;
}

.overlay button {
  background: rgba(var(--md-sys-color-surface), 0.9);
  color: rgb(var(--md-sys-color-on-surface));
  backdrop-filter: blur(10px);
}

.overlay button:hover {
  background: rgb(var(--md-sys-color-surface));
}

.status {
  font-size: 13px;
  padding: 8px 16px;
  border-radius: var(--md-sys-shape-corner-small);
  background: rgba(var(--md-sys-color-surface), 0.9);
  color: rgb(var(--md-sys-color-on-surface));
  backdrop-filter: blur(10px);
  font-weight: 500;
}

.status.light {
  background: transparent;
  color: rgb(var(--md-sys-color-on-surface-variant));
}

/* ==== UNIFIED TAB STYLES ==== */
.tabs,
.model-details-tabs {
  display: flex;
  gap: 8px;
}

.tabs {
  position: absolute;
  top: 6px;
  left: 24px;
  padding: 10px 20px;
  right: 0;
  z-index: 5;
  margin: 0 auto;
  width: 100px;
  max-width: 900px;
}

.model-details-tabs {
  margin-bottom: 24px;
  background: rgb(var(--md-sys-color-surface-variant), 0.3);
  padding: 4px;
  border-radius: var(--md-sys-shape-corner-medium);
}

.tab,
.model-details-tab {
  padding: 10px 20px;
  cursor: pointer;
  border-radius: var(--md-sys-shape-corner-small);
  font-size: var(--md-sys-typescale-label-large-size);
  font-weight: 500;
  transition: all 0.2s;
  flex: 1;
  text-align: center;
  color: rgb(var(--md-sys-color-on-surface-variant));
}

.tab:hover,
.model-details-tab:hover {
  background: rgba(var(--md-sys-color-primary), 0.08);
}

.tab.active,
.model-details-tab.active {
  background: rgb(var(--md-sys-color-secondary-container));
  color: rgb(var(--md-sys-color-on-secondary-container));
}

.model-details-tab.active {
  font-weight: 600;
}

.tab-content,
.model-details-content {
  display: none;
}

.tab-content.active,
.model-details-content.active {
  display: block;
}

/* ==== PREDICTION ==== */
.prediction-result {
  margin-top: 12px;
  padding: 12px;
  background: rgb(var(--md-sys-color-surface-variant), 0.5);
  border-radius: var(--md-sys-shape-corner-medium);
}

.prediction-bar {
  height: 24px;
  background: rgb(var(--md-sys-color-surface-variant));
  border-radius: var(--md-sys-shape-corner-small);
  margin-top: 8px;
  overflow: hidden;
}

.prediction-fill {
  height: 100%;
  background: rgb(var(--md-sys-color-primary));
  transition: width 0.3s;
  border-radius: var(--md-sys-shape-corner-small);
}

.prediction-display {
  position: absolute;
  top: 80px;
  left: 24px;
  background: rgba(var(--md-sys-color-surface), 0.95);
  color: rgb(var(--md-sys-color-on-surface));
  padding: 12px 20px;
  border-radius: var(--md-sys-shape-corner-medium);
  font-size: 18px;
  font-weight: 600;
  display: none;
  z-index: 3;
  box-shadow: var(--md-sys-elevation-3);
  backdrop-filter: blur(10px);
}

#apply-prediction {
  z-index: 9999 !important;
}

/* ==== MODEL INFO ==== */
.model-info {
  margin-top: 12px;
  font-size: 13px;
  color: rgb(var(--md-sys-color-on-surface-variant));
}

.button-hint {
  font-size: 12px;
  color: rgb(var(--md-sys-color-on-surface-variant));
  margin-top: 6px;
  line-height: 16px;
}

/* ==== MENU ==== */
.menu-container {
  position: fixed;
  top: 16px;
  left: 16px;
  z-index: 100;
}

.menu-button {
  width: 48px;
  height: 48px;
  border-radius: 50%;
  background: rgb(var(--md-sys-color-surface));
  color: rgb(var(--md-sys-color-on-surface));
  border: none;
  box-shadow: var(--md-sys-elevation-2);
  cursor: pointer;
  display: flex;
  align-items: center;
  justify-content: center;
  padding: 0;
  min-height: unset;
  transition: all 0.2s;
}

.menu-button:hover {
  background: rgb(var(--md-sys-color-surface-variant));
  box-shadow: var(--md-sys-elevation-3);
}

.menu-button svg {
  width: 24px;
  height: 24px;
}

.menu-items {
  position: absolute;
  top: 56px;
  left: 0;
  background: rgb(var(--md-sys-color-surface));
  border-radius: var(--md-sys-shape-corner-medium);
  box-shadow: var(--md-sys-elevation-3);
  overflow: hidden;
  display: none;
  min-width: 200px;
}

.menu-items.open {
  display: block;
  animation: menuSlideIn 0.2s cubic-bezier(0.2, 0, 0, 1);
}

.menu-item {
  padding: 12px 24px;
  cursor: pointer;
  color: rgb(var(--md-sys-color-on-surface));
  font-size: var(--md-sys-typescale-label-large-size);
  font-weight: 500;
  transition: background 0.2s;
  display: block;
  text-align: left;
}

.menu-item:hover {
  background: rgba(var(--md-sys-color-primary), 0.08);
}

.menu-item.active {
  background: rgb(var(--md-sys-color-secondary-container));
  color: rgb(var(--md-sys-color-on-secondary-container));
}

/* ==== TRY OUT ==== */
.try-out-container {
  display: flex;
  flex-direction: column;
  height: 100%;
  gap: 20px;
}

.try-out-header {
  display: flex;
  justify-content: space-between;
  align-items: center;
  margin-bottom: 8px;
}

.try-out-status {
  display: flex;
  align-items: center;
  gap: 8px;
}

.status-indicator {
  width: 10px;
  height: 10px;
  border-radius: 50%;
  background: rgb(var(--md-sys-color-outline));
}

.status-indicator.connected {
  background: rgb(var(--md-sys-color-secondary-container));
  box-shadow: 0 0 8px rgba(var(--md-sys-color-secondary-container), 0.5);
}

/* ==== BLUETOOTH ==== */
.bluetooth-controls {
  display: flex;
  flex-direction: column;
  gap: 12px;
}

.bluetooth-controls button:hover {
  background: rgba(187, 239, 83, 0.9); /* Bright neon green on hover */
  color: rgb(var(--md-sys-color-on-primary));
}

.bluetooth-controls button:active {
  background: rgba(187, 239, 83, 1); /* Full bright neon green on click */
  color: rgb(var(--md-sys-color-on-primary));
}

.bluetooth-status {
  font-size: 0;
  color: rgb(var(--md-sys-color-on-surface-variant));
}

.bluetooth-device {
  padding: 12px;
  border: 1px solid rgb(var(--md-sys-color-outline-variant));
  border-radius: var(--md-sys-shape-corner-medium);
  margin-bottom: 8px;
  cursor: pointer;
  transition: all 0.2s;
}

.bluetooth-device:hover {
  background: rgb(var(--md-sys-color-surface-variant), 0.5);
  border-color: rgb(var(--md-sys-color-primary));
}

.bluetooth-device.selected {
  background: rgb(var(--md-sys-color-primary-container));
  border-color: rgb(var(--md-sys-color-primary));
}

/* ==== UNIFIED DIALOG STYLES ==== */
.import-dialog,
.model-details-dialog {
  position: fixed;
  top: 50%;
  left: 50%;
  transform: translate(-50%, -50%);
  background: rgb(var(--md-sys-color-surface));
  border-radius: var(--md-sys-shape-corner-extra-large);
  padding: 24px;
  box-shadow: var(--md-sys-elevation-3);
  z-index: 1000;
}

.import-dialog {
  max-width: 400px;
  width: 90%;
}

.model-details-dialog {
  max-width: 90%;
  width: 90%;
  max-height: 90%;
  overflow-y: auto;
}

.import-dialog h3,
.model-details-dialog h2 {
  margin-top: 0;
  font-weight: 600;
}

.import-dialog h3 {
  margin-bottom: 16px;
  font-size: var(--md-sys-typescale-title-medium-size);
}

.model-details-dialog h2 {
  margin-bottom: 20px;
  color: rgb(var(--md-sys-color-primary));
  font-size: 24px;
}

.import-dialog .class-option {
  padding: 12px;
  margin: 8px 0;
  border: 1px solid rgb(var(--md-sys-color-outline-variant));
  border-radius: var(--md-sys-shape-corner-medium);
  cursor: pointer;
  transition: all 0.2s;
}

.import-dialog .class-option:hover {
  background: rgb(var(--md-sys-color-surface-variant), 0.5);
  border-color: rgb(var(--md-sys-color-primary));
}

.import-dialog .class-option.selected {
  background: rgb(var(--md-sys-color-primary-container));
  border-color: rgb(var(--md-sys-color-primary));
  border-width: 2px;
  padding: 11px;
}

.import-dialog .buttons {
  display: flex;
  gap: 12px;
  margin-top: 20px;
  justify-content: flex-end;
}

.model-details-dialog .close-btn {
  position: absolute;
  top: 16px;
  right: 16px;
  background: transparent;
  color: rgb(var(--md-sys-color-on-surface-variant));
  border: none;
  font-size: 28px;
  cursor: pointer;
  padding: 8px;
  width: 40px;
  height: 40px;
  display: flex;
  align-items: center;
  justify-content: center;
  border-radius: 50%;
  min-height: unset;
  box-shadow: none;
}

.model-details-dialog .close-btn:hover {
  background: rgb(var(--md-sys-color-surface-variant), 0.5);
}

.dialog-overlay {
  position: fixed;
  inset: 0;
  background: rgba(0, 0, 0, 0.5);
  z-index: 999;
  backdrop-filter: blur(4px);
}

/* ==== NOTIFICATIONS ==== */
.model-load-notification {
  position: fixed;
  bottom: 24px;
  left: 50%;
  transform: translateX(-50%);
  background: rgb(var(--md-sys-color-tertiary));
  color: rgb(var(--md-sys-color-on-tertiary));
  padding: 16px 24px;
  border-radius: var(--md-sys-shape-corner-medium);
  box-shadow: var(--md-sys-elevation-3);
  z-index: 1000;
  display: none;
  animation: slideUp 0.3s cubic-bezier(0.2, 0, 0, 1);
  font-weight: 500;
}

#model-load-notification {
  color: black !important;
}

/* ==== PROJECT ==== */
.project-buttons {
  margin-top: auto;
  padding-top: 16px;
  border-top: 1px solid rgb(var(--md-sys-color-outline-variant));
  display: flex;
  flex-direction: column;
  gap: 10px;
}

/* ==== CHARTS ==== */
.chart-container {
  position: relative;
  height: 300px;
  margin-bottom: 24px;
  background: rgb(var(--md-sys-color-surface));
  padding: 16px;
  border-radius: var(--md-sys-shape-corner-medium);
}

.confusion-matrix {
  display: flex;
  flex-direction: column;
  align-items: center;
}

.confusion-matrix table {
  border-collapse: collapse;
  margin-top: 16px;
  box-shadow: var(--md-sys-elevation-1);
  border-radius: var(--md-sys-shape-corner-small);
  overflow: hidden;
}

.confusion-matrix th,
.confusion-matrix td {
  border: 1px solid rgb(var(--md-sys-color-outline-variant));
  padding: 12px;
  text-align: center;
  min-width: 60px;
  font-size: 13px;
}

.confusion-matrix th {
  background: rgb(var(--md-sys-color-surface-variant));
  font-weight: 600;
  color: rgb(var(--md-sys-color-on-surface));
}

.confusion-matrix .correct {
  background: rgba(var(--md-sys-color-primary), 0.15);
  font-weight: 600;
}

.confusion-matrix .incorrect {
  background: rgba(var(--md-sys-color-error), 0.15);
}

/* ==== STATS ==== */
.model-stats {
  display: grid;
  grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
  gap: 16px;
  margin-bottom: 24px;
}

.stat-card {
  background: rgb(var(--md-sys-color-surface-variant), 0.3);
  border-radius: var(--md-sys-shape-corner-medium);
  padding: 20px;
  text-align: center;
  box-shadow: var(--md-sys-elevation-1);
  transition: all 0.2s;
}

.stat-card:hover {
  box-shadow: var(--md-sys-elevation-2);
}

.stat-card .stat-value {
  font-size: 32px;
  font-weight: 700;
  color: rgb(var(--md-sys-color-primary));
  line-height: 1.2;
}

.stat-card .stat-label {
  font-size: 14px;
  color: rgb(var(--md-sys-color-on-surface-variant));
  margin-top: 8px;
  font-weight: 500;
}

.section-description {
  background: rgb(var(--md-sys-color-primary-container), 0.5);
  border-left: 4px solid rgb(var(--md-sys-color-primary));
  padding: 16px 20px;
  margin-bottom: 24px;
  border-radius: 0 var(--md-sys-shape-corner-medium) var(--md-sys-shape-corner-medium) 0;
  font-size: 14px;
  color: rgb(var(--md-sys-color-on-surface));
  line-height: 1.6;
}

.section-description strong {
  color: rgb(var(--md-sys-color-primary));
  font-weight: 600;
}

.value-guideline {
  display: inline-block;
  padding: 3px 8px;
  border-radius: var(--md-sys-shape-corner-small);
  font-size: 12px;
  font-weight: 600;
  margin: 0 2px;
}

.value-excellent {
  background: rgba(var(--md-sys-color-primary), 0.2);
  color: rgba(var(--md-sys-color-primary), 1);
}

.value-good {
  background: rgba(255, 193, 7, 0.2);
  color: hsl(83, 100%, 48%);
}

.value-needs-improvement {
  background: rgba(var(--md-sys-color-error), 0.2);
  color: rgb(var(--md-sys-color-error));
}

/* ==== MODEL LOADER OVERLAY ==== */
.model-loader-overlay {
  position: fixed;
  top: 80px;
  right: 24px;
  width: 360px;
  max-height: calc(100vh - 100px);
  background: #ffffff;
  border-radius: 16px;
  box-shadow: 0 8px 24px rgba(0, 0, 0, 0.15);
  z-index: 1000;
  overflow: hidden;
  transition: transform 0.3s ease, opacity 0.3s ease;
}

.model-loader-overlay.collapsed {
  max-height: 60px;
}

.model-loader-header {
  background: rgb(var(--md-sys-color-primary));
  color: white;
  padding: 16px 20px;
  cursor: pointer;
  display: flex;
  justify-content: space-between;
  align-items: center;
  user-select: none;
}

.model-loader-header h3 {
  margin: 0;
  font-size: 16px;
  font-weight: 600;
}

.model-loader-header .toggle-btn {
  background: transparent;
  border: none;
  color: white;
  cursor: pointer;
  padding: 4px;
  display: flex;
  align-items: center;
  justify-content: center;
  transition: transform 0.3s ease;
}

.model-loader-overlay.collapsed .toggle-btn {
  transform: rotate(-90deg);
}

.model-loader-content {
  padding: 20px;
  overflow-y: auto;
  max-height: calc(100vh - 160px);
  transition: max-height 0.3s ease, opacity 0.3s ease;
}

.model-loader-overlay.collapsed .model-loader-content {
  max-height: 0;
  padding: 0 20px;
  opacity: 0;
  overflow: hidden;
}

/* ==== HEADER ==== */
#main-header {
  background: #1b1c1d;
  position: fixed;
  top: 0;
  left: 0;
  width: 100%;
  z-index: 100000000;
  padding: 8px 24px;
}

.header-inner {
  width: 100%;
  padding: 0 24px;
  display: flex;
  align-items: center;
  justify-content: space-between;
}

.header-left {
  display: flex;
  align-items: center;
  gap: 12px;
}

#calliope-logo {
  height: 26px;
  width: auto;
}

.header-title {
  font-size: 18px;
  color: white;
  font-weight: 500;
}

.header-right {
  display: flex;
  align-items: center;
  gap: 12px;
}

.header-btn {
  padding: 8px 18px;
  border-radius: 20px;
  background-color: transparent;
  border: 1px solid transparent;
  color: rgba(255, 255, 255, 0.926);
  font-size: 14px;
  font-weight: 500;
  cursor: pointer;
  transition: background-color 0.2s, color 0.2s;
}

.header-btn:not(.active):hover {
  background-color: rgba(250, 250, 250, 0.6);
  color: black;
}

.header-btn.active {
  background-color: hsl(83, 100%, 48%);
  border-color: hsl(83, 100%, 48%);
  color: black;
  font-weight: 600;
}

.header-btn.active:hover {
  background-color: hsl(83, 100%, 58%);
  color: black;
}

/* ==== WELCOME OVERLAY ==== */
#welcome-overlay {
  position: fixed;
  inset: 0;
  background: rgba(0, 0, 0, 0.65);
  backdrop-filter: blur(4px);
  display: flex;
  align-items: center;
  justify-content: center;
  z-index: 999999;
}

#welcome-box {
  background: #ffffff;
  padding: 32px 40px;
  border-radius: 20px;
  max-width: 600px;
  width: 90%;
  text-align: center;
  box-shadow: 0 10px 25px rgba(0, 0, 0, 0.25);
  font-family: "Inter", system-ui, sans-serif;
  position: relative;
}

/* Settings container and button */
#settings-container {
  position: relative;
  display: flex;
  align-items: center;
  z-index: 100000000;
}

#settings-btn {
  padding: 8px 18px;
  border-radius: 20px;
  background-color: transparent;
  border: 1px solid transparent;
  color: rgba(255, 255, 255, 0.926);
  cursor: pointer;
  transition: background-color 0.2s, color 0.2s;
  display: flex;
  align-items: center;
  justify-content: center;
  font-size: 14px;
  font-weight: 500;
}

#settings-btn:hover {
  background-color: rgba(250, 250, 250, 0.6);
  color: black;
}

#settings-btn svg {
  width: 20px;
  height: 20px;
}

#settings-menu {
  position: absolute;
  top: 40px;
  right: 0;
  background: #ffffff;
  border: 1px solid #ddd;
  border-radius: 8px;
  box-shadow: 0 4px 12px rgba(0, 0, 0, 0.15);
  min-width: 180px;
  z-index: 100000001;
}

.settings-menu-item {
  padding: 12px 16px;
  cursor: pointer;
  transition: background-color 0.2s;
  font-size: 14px;
  color: #333;
}

.settings-menu-item:first-child {
  border-radius: 8px 8px 0 0;
}

.settings-menu-item:last-child {
  border-radius: 0 0 8px 8px;
}

.settings-menu-item:hover {
  background-color: #f5f5f5;
}

/* Language Selection Overlay */
#language-overlay {
  position: fixed;
  inset: 0;
  background: rgba(0, 0, 0, 0.65);
  backdrop-filter: blur(4px);
  display: flex;
  align-items: center;
  justify-content: center;
  z-index: 10000000;
}

#language-box {
  position: relative;
  background: #ffffff;
  padding: 32px 40px;
  border-radius: 20px;
  max-width: 500px;
  width: 90%;
  box-shadow: 0 10px 25px rgba(0, 0, 0, 0.25);
  font-family: "Inter", system-ui, sans-serif;
}

#language-box h2 {
  font-size: 24px;
  font-weight: 600;
  color: #000;
  margin-bottom: 24px;
  text-align: center;
}

#language-list {
  display: flex;
  flex-direction: column;
  gap: 8px;
}

.language-option {
  padding: 14px 20px;
  background: #f5f5f5;
  border: 2px solid transparent;
  border-radius: 8px;
  cursor: pointer;
  transition: all 0.2s;
  font-size: 16px;
  color: #333;
  text-align: center;
}

.language-option:hover {
  background: #e8e8e8;
  border-color: #1fb6ff;
}

.language-option.active {
  background: #e3f5ff;
  border-color: #1fb6ff;
  color: #1fb6ff;
  font-weight: 600;
}

#welcome-title {
  font-size: 34px;
  font-weight: 600;
  color: #000;
  margin-bottom: 20px;
  line-height: 1.3;
}

#welcome-title span {
  color: #1fb6ff;
}

#welcome-subtitle {
  font-size: 20px;
  color: #444;
  margin-top: 4px;
  line-height: 1.4;
}

#welcome-links {
  margin-top: 24px;
  display: flex;
  gap: 32px;
  justify-content: center;
  align-items: center;
}

#welcome-links a {
  font-size: 20px;
  color: #1fb6ff;
  text-decoration: none;
  font-weight: 500;
  border-bottom: 1px solid transparent;
  transition: border-bottom-color 0.2s;
}

#welcome-links a:hover {
  border-bottom-color: #1fb6ff;
}

.overlay-close-btn {
  position: absolute;
  top: 16px;
  right: 16px;
  background: transparent;
  color: rgb(var(--md-sys-color-on-surface-variant));
  border: none;
  font-size: 28px;
  cursor: pointer;
  padding: 8px;
  width: 40px;
  height: 40px;
  display: flex;
  align-items: center;
  justify-content: center;
  border-radius: 50%;
  min-height: unset;
  box-shadow: none;
  transition: background-color 0.2s;
  outline: none;
}

.overlay-close-btn:hover {
  background: rgb(var(--md-sys-color-surface-variant), 0.5);
}

/* AI Info Overlay */
#ai-info-overlay {
  position: fixed;
  inset: 0;
  background: rgba(0, 0, 0, 0.65);
  backdrop-filter: blur(4px);
  display: none;
  align-items: center;
  justify-content: center;
  z-index: 9999999;
}

#ai-info-box {
  position: relative;
  background: #ffffff;
  padding: 40px 48px;
  border-radius: 20px;
  max-width: 700px;
  max-height: 85vh;
  width: 90%;
  box-shadow: 0 10px 25px rgba(0, 0, 0, 0.25);
  font-family: "Inter", system-ui, sans-serif;
  overflow-y: auto;
}

#ai-info-title {
  font-size: 28px;
  font-weight: 600;
  color: #000;
  margin-bottom: 24px;
  text-align: center;
}

#ai-info-content {
  font-size: 15px;
  line-height: 1.7;
  color: #333;
  text-align: left;
}

#ai-info-content h3 {
  font-size: 18px;
  font-weight: 600;
  color: #000;
  margin-top: 24px;
  margin-bottom: 12px;
}

#ai-info-content h3:first-child {
  margin-top: 0;
}

#ai-info-content p {
  margin-bottom: 14px;
}

#ai-info-content ul {
  margin: 12px 0;
  padding-left: 24px;
}

#ai-info-content li {
  margin-bottom: 8px;
}

#ai-info-content strong {
  font-weight: 600;
  color: #000;
}

/* ==== ANIMATIONS ==== */
@keyframes menuSlideIn {
  from {
    opacity: 0;
    transform: translateY(-8px);
  }
  to {
    opacity: 1;
    transform: translateY(0);
  }
}

@keyframes slideUp {
  from {
    opacity: 0;
    transform: translateX(-50%) translateY(20px);
  }
  to {
    opacity: 1;
    transform: translateX(-50%) translateY(0);
  }
}

@keyframes fadeIn {
  from {
    opacity: 0;
    transform: translateY(10px);
  }
  to {
    opacity: 1;
    transform: translateY(0);
  }
}

/* ==== PROGRESSIVE REVEAL ==== */
.step-section {
  display: none;
  animation: fadeIn 0.4s ease-out;
}

.step-section.visible {
  display: block;
}

.step-section hr {
  margin: 16px 0;
}

/* ==== BUTTON CONTAINER ALIGNMENT ==== */
#capture-buttons-container {
  display: flex;
  gap: 6px;
  flex-wrap: wrap;
  justify-content: flex-start;
}

/* ==== HELP TEXT ==== */
.help-text {
  margin-top: 12px;
  padding-top: 8px;
  border-top: 2px solid #000000;
  font-size: 13px;
  line-height: 1.5;
  color: rgb(var(--md-sys-color-on-surface));
  animation: fadeIn 0.3s ease-out;
}

.help-text:empty {
  display: none;
  margin: 0;
  padding: 0;
  border: none;
}

/* Training Spinner Animation */
.training-spinner {
  display: inline-block;
  width: 14px;
  height: 14px;
  border: 2px solid rgba(0, 122, 204, 0.2);
  border-top-color: #007acc;
  border-radius: 50%;
  animation: spin 0.8s linear infinite;
  margin-right: 8px;
  vertical-align: middle;
}

@keyframes spin {
  to { transform: rotate(360deg); }
}

.status-with-spinner {
  display: flex;
  align-items: center;
  gap: 8px;
}
</style>
</head>
<body>

    <!-- Welcome Overlay -->
  <div id="welcome-overlay">
    <div id="welcome-box">
      <div id="welcome-title" data-i18n="welcome.title">
        Willkommen bei <br>
        Calliope <span>Teachable Machine</span>
      </div>
      <div id="welcome-subtitle" data-i18n="welcome.subtitle">
        Steuere deinen Calliope mini mit Gesten oder Farben.
      </div>
      <div id="welcome-links">
        <button class="ghost" onclick="closeWelcomeOverlay(event)" data-i18n="welcome.start">Starten</button>
      </div>
    </div>
  </div>

  <!-- Language Selection Overlay -->
  <div id="language-overlay" style="display:none;" onclick="closeLanguageSelection(event)">
    <div id="language-box" onclick="event.stopPropagation()">
      <button class="overlay-close-btn" onclick="closeLanguageSelection()">&times;</button>
      <h2 data-i18n="welcome.selectLanguage">Sprache auswählen</h2>
      <div id="language-list">
        <div class="language-option" onclick="selectLanguage('de')">
          <span>Deutsch (DE)</span>
        </div>
        <div class="language-option" onclick="selectLanguage('en')">
          <span>English (EN)</span>
        </div>
        <div class="language-option" onclick="selectLanguage('fr')">
          <span>Français (FR)</span>
        </div>
        <div class="language-option" onclick="selectLanguage('es')">
          <span>Español (ES)</span>
        </div>
        <div class="language-option" onclick="selectLanguage('it')">
          <span>Italiano (IT)</span>
        </div>
        <div class="language-option" onclick="selectLanguage('el')">
          <span>Ελληνικά (EL)</span>
        </div>
      </div>
    </div>
  </div>

  <!-- AI-Hinweise Overlay -->
  <div id="ai-info-overlay" onclick="closeAIInfoOverlay(event)">
    <div id="ai-info-box" onclick="event.stopPropagation()">
      <button class="overlay-close-btn" onclick="closeAIInfoOverlay()">&times;</button>
      <div id="ai-info-title">Hinweise</div>
      <div id="ai-info-content">

        <h3>Du arbeitest mit einem KI-System</h3>
        <p>Die Calliope Teachable Machine nutzt künstliche Intelligenz (KI), um aus deinen Beispielbildern zu lernen. Das bedeutet: Du trainierst ein Modell, das eigenständig Muster in Bildern erkennt – zum Beispiel unterschiedliche Handgesten oder Farben.</p>

        <h3>So funktioniert das System</h3>
        <p>Das Modell basiert auf einer Technik namens "Transfer Learning". Dabei nutzen wir ein bereits vortrainiertes neuronales Netz (MobileNet), das bereits viele Bildmerkmale kennt. Deine Beispielbilder werden verwendet, um dieses Wissen auf deine spezielle Aufgabe anzupassen – etwa die Unterscheidung deiner eigenen Gesten.</p>
        <p>Alle Berechnungen und das Training finden direkt in deinem Browser statt. Keine Daten werden an Server übertragen – alles bleibt lokal auf deinem Gerät.</p>

        <h3>Deine Daten bleiben bei dir</h3>
        <p>Alle Bilder, die du mit der Webcam aufnimmst, werden ausschließlich lokal verarbeitet. Sie verlassen deinen Computer nicht. Auch das trainierte Modell wird nur auf deinem Gerät gespeichert.</p>

        <h3>Grenzen und Einschränkungen</h3>
        <p>Dein trainiertes Modell ist nur so gut wie deine Trainingsdaten. Wenn du zum Beispiel nur Bilder bei Tageslicht aufnimmst, funktioniert das Modell bei schlechten Lichtverhältnissen möglicherweise nicht zuverlässig. Je vielfältiger deine Beispiele sind, desto robuster wird das Modell.</p>
        <p>Das System ist für <strong>Lern- und Experimentierprojekte</strong> gedacht. Es ist nicht geeignet für sicherheitskritische Anwendungen oder Entscheidungen, die Menschen beeinflussen könnten.</p>

        <h3>Fairness und Verantwortung</h3>
        <p>Du entscheidest, welche Bilder du zum Training verwendest! Achte darauf, dass deine Trainingsdaten ausgewogen sind und keine Vorurteile widerspiegeln. Wenn du beispielsweise nur Bilder von einer Person aufnimmst, wird das Modell bei anderen Personen möglicherweise schlechter funktionieren. Genauso wird ein Hintergrund auch trainiert. Das bedeutet, auch Gegenstände auf diesem können das Modell verfälschen, wenn diese auf allen Bildern enthalten sind.</p>

        <h3>Wofür ist dieses System geeignet?</h3>
        <p>Die Teachable Machine ist perfekt für kreative Projekte, Schulprojekte und spielerisches Lernen. Du kannst:</p>
        <ul>
          <li>Farben oder Objekte unterscheiden</li>
          <li>Handgesten erkennen, um deinen Calliope mini zu steuern</li>
          <li>Verstehen, wie maschinelles Lernen funktioniert</li>
          <li>Eigene interaktive Projekte entwickeln</li>
        </ul>

        <h3>Weitere Informationen</h3>
        <p>Falls du Fragen zu diesem Tool haben, kannst du dich natürlich gern bei uns melden. <br>
        Am einfachsten geht das per Mail: info@calliope.cc <br> Dieses Tool folgt den Transparenzanforderungen der EU-KI-Verordnung (EU) 2024/1689. Du hast jederzeit die Kontrolle über deine Daten und Modelle. Bei Fragen zur Funktionsweise kannst du die "Modell Details" nach dem Training einsehen – dort findest du technische Informationen über die Leistung deines Modells.</p>

      </div>
    </div>
  </div>

  <header id="main-header">
  <div class="header-inner">
    <div class="header-left">
      <!-- Original SVG von campus.calliope.cc -->
     <svg width="35px" height="35px" viewBox="0 0 27 26" version="1.1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" xml:space="preserve" xmlns:serif="http://www.serif.com/" style="fill-rule:evenodd;clip-rule:evenodd;stroke-linejoin:round;stroke-miterlimit:2;" class="logo-icon"><g transform="matrix(1,0,0,1,-168.819,-43.654)"><g transform="matrix(1,0,0,1,0,1)"><g transform="matrix(1,0,0,1,0,-1001.5)"><path d="M188.739,1046.34L193.961,1046.34L193.961,1052.77L188.739,1052.77L188.739,1046.34ZM182.705,1056.02L183.882,1052.23L185.841,1056.02L182.705,1056.02ZM179.473,1056.02L181.44,1052.26L182.609,1056.02L179.473,1056.02ZM180.501,1047.53L184.839,1047.53L184.839,1050.46C184.839,1051.41 184.072,1052.18 183.125,1052.18L182.215,1052.18C181.268,1052.18 180.501,1051.41 180.501,1050.46L180.501,1047.53ZM193.658,1044.68L189.041,1044.68C188.347,1044.68 187.784,1045.25 187.784,1045.94C187.784,1045.94 187.776,1049.88 187.776,1049.42C187.776,1046.52 185.42,1044.16 182.513,1044.16C179.606,1044.16 177.249,1046.52 177.249,1049.42L177.249,1055.21L171.006,1059.88C166.797,1063.1 169.069,1069.82 174.364,1069.82L175.618,1069.82C176.145,1065.94 177.356,1061.15 179.813,1058.25L185.528,1058.25C188.016,1061.19 189.074,1065.92 189.59,1069.82L191.358,1069.82C193.322,1069.82 194.915,1068.22 194.915,1066.26L194.915,1045.94C194.915,1045.25 194.353,1044.68 193.658,1044.68" style="fill:#ffffff;fill-rule:nonzero;"></path></g></g></g></svg>
<g transform="matrix(1,0,0,1,-168.819,-43.654)"><g transform="matrix(1,0,0,1,0,1)"><g transform="matrix(1,0,0,1,0,-1001.5)"><path d="M188.739,1046.34L193.961,1046.34L193.961,1052.77L188.739,1052.77L188.739,1046.34ZM182.705,1056.02L183.882,1052.23L185.841,1056.02L182.705,1056.02ZM179.473,1056.02L181.44,1052.26L182.609,1056.02L179.473,1056.02ZM180.501,1047.53L184.839,1047.53L184.839,1050.46C184.839,1051.41 184.072,1052.18 183.125,1052.18L182.215,1052.18C181.268,1052.18 180.501,1051.41 180.501,1050.46L180.501,1047.53ZM193.658,1044.68L189.041,1044.68C188.347,1044.68 187.784,1045.25 187.784,1045.94C187.784,1045.94 187.776,1049.88 187.776,1049.42C187.776,1046.52 185.42,1044.16 182.513,1044.16C179.606,1044.16 177.249,1046.52 177.249,1049.42L177.249,1055.21L171.006,1059.88C166.797,1063.1 169.069,1069.82 174.364,1069.82L175.618,1069.82C176.145,1065.94 177.356,1061.15 179.813,1058.25L185.528,1058.25C188.016,1061.19 189.074,1065.92 189.59,1069.82L191.358,1069.82C193.322,1069.82 194.915,1068.22 194.915,1066.26L194.915,1045.94C194.915,1045.25 194.353,1044.68 193.658,1044.68" style="fill:#ffffff;fill-rule:nonzero;"></path></g></g></g>

      <span class="header-title">Calliope Teachable Machine</span>
    </div>

    <div class="header-right">
      <!-- Navigation Buttons -->
      <button class="header-btn" data-view="training" data-i18n="header.training">Trainieren</button>
      <button class="header-btn" data-view="tryout" data-i18n="header.tryout">Programmieren</button>
      <button class="header-btn" data-view="apply" data-i18n="header.apply">Anwenden</button>

      <!-- Settings Button -->
      <div id="settings-container">
        <button id="settings-btn" onclick="toggleSettingsMenu(event)" aria-label="Settings">
          <svg width="24" height="24" viewBox="0 0 24 24" fill="none" xmlns="http://www.w3.org/2000/svg">
            <path d="M12 15C13.6569 15 15 13.6569 15 12C15 10.3431 13.6569 9 12 9C10.3431 9 9 10.3431 9 12C9 13.6569 10.3431 15 12 15Z" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
            <path d="M19.4 15C19.2669 15.3016 19.2272 15.6362 19.286 15.9606C19.3448 16.285 19.4995 16.5843 19.73 16.82L19.79 16.88C19.976 17.0657 20.1235 17.2863 20.2241 17.5291C20.3248 17.7719 20.3766 18.0322 20.3766 18.295C20.3766 18.5578 20.3248 18.8181 20.2241 19.0609C20.1235 19.3037 19.976 19.5243 19.79 19.71C19.6043 19.896 19.3837 20.0435 19.1409 20.1441C18.8981 20.2448 18.6378 20.2966 18.375 20.2966C18.1122 20.2966 17.8519 20.2448 17.6091 20.1441C17.3663 20.0435 17.1457 19.896 16.96 19.71L16.9 19.65C16.6643 19.4195 16.365 19.2648 16.0406 19.206C15.7162 19.1472 15.3816 19.1869 15.08 19.32C14.7842 19.4468 14.532 19.6572 14.3543 19.9255C14.1766 20.1938 14.0813 20.5082 14.08 20.83V21C14.08 21.5304 13.8693 22.0391 13.4942 22.4142C13.1191 22.7893 12.6104 23 12.08 23C11.5496 23 11.0409 22.7893 10.6658 22.4142C10.2907 22.0391 10.08 21.5304 10.08 21V20.91C10.0723 20.579 9.96512 20.258 9.77251 19.9887C9.5799 19.7194 9.31074 19.5143 9 19.4C8.69838 19.2669 8.36381 19.2272 8.03941 19.286C7.71502 19.3448 7.41568 19.4995 7.18 19.73L7.12 19.79C6.93425 19.976 6.71368 20.1235 6.47088 20.2241C6.22808 20.3248 5.96783 20.3766 5.705 20.3766C5.44217 20.3766 5.18192 20.3248 4.93912 20.2241C4.69632 20.1235 4.47575 19.976 4.29 19.79C4.10405 19.6043 3.95653 19.3837 3.85588 19.1409C3.75523 18.8981 3.70343 18.6378 3.70343 18.375C3.70343 18.1122 3.75523 17.8519 3.85588 17.6091C3.95653 17.3663 4.10405 17.1457 4.29 16.96L4.35 16.9C4.58054 16.6643 4.73519 16.365 4.794 16.0406C4.85282 15.7162 4.81312 15.3816 4.68 15.08C4.55324 14.7842 4.34276 14.532 4.07447 14.3543C3.80618 14.1766 3.49179 14.0813 3.17 14.08H3C2.46957 14.08 1.96086 13.8693 1.58579 13.4942C1.21071 13.1191 1 12.6104 1 12.08C1 11.5496 1.21071 11.0409 1.58579 10.6658C1.96086 10.2907 2.46957 10.08 3 10.08H3.09C3.42099 10.0723 3.742 9.96512 4.0113 9.77251C4.28059 9.5799 4.48572 9.31074 4.6 9C4.73312 8.69838 4.77282 8.36381 4.714 8.03941C4.65519 7.71502 4.50054 7.41568 4.27 7.18L4.21 7.12C4.02405 6.93425 3.87653 6.71368 3.77588 6.47088C3.67523 6.22808 3.62343 5.96783 3.62343 5.705C3.62343 5.44217 3.67523 5.18192 3.77588 4.93912C3.87653 4.69632 4.02405 4.47575 4.21 4.29C4.39575 4.10405 4.61632 3.95653 4.85912 3.85588C5.10192 3.75523 5.36217 3.70343 5.625 3.70343C5.88783 3.70343 6.14808 3.75523 6.39088 3.85588C6.63368 3.95653 6.85425 4.10405 7.04 4.29L7.1 4.35C7.33568 4.58054 7.63502 4.73519 7.95941 4.794C8.28381 4.85282 8.61838 4.81312 8.92 4.68H9C9.29577 4.55324 9.54802 4.34276 9.72569 4.07447C9.90337 3.80618 9.99872 3.49179 10 3.17V3C10 2.46957 10.2107 1.96086 10.5858 1.58579C10.9609 1.21071 11.4696 1 12 1C12.5304 1 13.0391 1.21071 13.4142 1.58579C13.7893 1.96086 14 2.46957 14 3V3.09C14.0013 3.41179 14.0966 3.72618 14.2743 3.99447C14.452 4.26276 14.7042 4.47324 15 4.6C15.3016 4.73312 15.6362 4.77282 15.9606 4.714C16.285 4.65519 16.5843 4.50054 16.82 4.27L16.88 4.21C17.0657 4.02405 17.2863 3.87653 17.5291 3.77588C17.7719 3.67523 18.0322 3.62343 18.295 3.62343C18.5578 3.62343 18.8181 3.67523 19.0609 3.77588C19.3037 3.87653 19.5243 4.02405 19.71 4.21C19.896 4.39575 20.0435 4.61632 20.1441 4.85912C20.2448 5.10192 20.2966 5.36217 20.2966 5.625C20.2966 5.88783 20.2448 6.14808 20.1441 6.39088C20.0435 6.63368 19.896 6.85425 19.71 7.04L19.65 7.1C19.4195 7.33568 19.2648 7.63502 19.206 7.95941C19.1472 8.28381 19.1869 8.61838 19.32 8.92V9C19.4468 9.29577 19.6572 9.54802 19.9255 9.72569C20.1938 9.90337 20.5082 9.99872 20.83 10H21C21.5304 10 22.0391 10.2107 22.4142 10.5858C22.7893 10.9609 23 11.4696 23 12C23 12.5304 22.7893 13.0391 22.4142 13.4142C22.0391 13.7893 21.5304 14 21 14H20.91C20.5882 14.0013 20.2738 14.0966 20.0055 14.2743C19.7372 14.452 19.5268 14.7042 19.4 15Z" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"/>
          </svg>
        </button>
        <div id="settings-menu" style="display:none;">
          <div class="settings-menu-item" onclick="openLanguageSelection(event)">
            <span data-i18n="welcome.languages">Sprachen</span>
          </div>
          <div class="settings-menu-item" onclick="openAIInfoFromMenu(event)">
            <span data-i18n="welcome.aiInfo">KI-Hinweise</span>
          </div>
        </div>
      </div>
    </div>
  </div>
</header>

<div class="app">
  <!-- TRAINING/TEST VIEW -->
  <div id="training-view" class="view">
    <!-- LEFT -->
    <div class="left-panel panel">
      <div>
        <label data-i18n="training.newClass">Neue Klasse:</label>
        <div style="display:flex;gap:8px;margin-top:4px;">
          <input id="new-class-name" type="text" data-i18n-placeholder="training.newClassPlaceholder" placeholder="z. B. Hand" />
          <button id="create-class" data-i18n="training.addClass">&nbsp;+&nbsp;</button>
        </div>
      </div>

      <!-- Step 1: Class List (shown after first class created) -->
      <div id="step-class-list" class="step-section" style="margin-top:10px;">
        <label data-i18n="training.classes">Klassen:</label>
        <div style="display:flex;justify-content:space-between;align-items:center;margin-bottom:4px;">
          <span style="font-size:12px;color:#666;" data-i18n="training.clickToSelect">Klick zum Auswählen</span>
          <button id="download-all" class="ghost" style="font-size:12px;padding:4px 8px;" data-i18n="training.downloadAll">Alle herunterladen</button>
        </div>
        <div id="class-list" class="class-list" style="margin-top:4px;"></div>
      </div>

      <!-- Step 2: Active Class Section (shown after first class created) -->
      <div id="step-active-class" class="step-section">
        <hr style="margin:12px 0;">

        <div>
          <label data-i18n="training.activeClass">Aktive Klasse:</label>
          <select id="active-class" style="margin-top:4px;"></select>
          <div id="capture-buttons-container" style="margin-top:8px;display:flex;gap:6px;flex-wrap:wrap;">
            <button id="capture" class="primary-action" data-i18n="training.startCapture">Aufnahme starten</button>
            <label class="file-label" for="file-input" data-i18n="training.files">
              Dateien
              <input id="file-input" type="file" accept="image/*,.zip" style="display:none" multiple>
            </label>
            <button id="clear-class" class="ghost" style="display:none;" data-i18n="training.clear">Leeren</button>
            <button id="delete-class-btn" class="ghost" style="display:none;" data-i18n="training.deleteClass">Löschen</button>
          </div>
          <div id="capture-hint" class="button-hint" data-i18n="training.captureHint">Halte die Taste gedrückt, um Bilder aufzunehmen (10 Bilder/Sekunde)</div>
          <div id="capture-count" style="margin-top:6px;font-size:13px;color:#555;"><span id="capture-count-number">0</span> <span data-i18n="training.imagesCount">Bilder</span></div>
          <div id="thumbs" class="thumbs"></div>
        </div>
      </div>

      <!-- Step 3: Training Section (shown after 3 classes created) -->
      <div id="step-training" class="step-section">
        <hr style="margin:12px 0;">

        <div>
          <label data-i18n="training.training">Training:</label>
          <div style="display:flex;gap:8px;margin-top:6px;">
            <input id="epochs" type="number" value="30" min="1" style="width:80px;">
            <button id="train" data-i18n="training.train">Modell Trainieren</button>
          </div>
          <div class="status light" id="train-status" style="margin-top:6px;fontcolor:#000000;">
            <span id="train-status-text" data-i18n="training.trainStatus">Bereit</span>
          </div>
        </div>
      </div>

      <!-- Step 3b: Model Details (shown after training completes) -->
      <div id="step-model-details" class="step-section">
        <div style="margin-top:8px;">
          <button id="model-details" class="ghost" data-i18n="training.modelDetails">Modell Details</button>
        </div>
      </div>

      <!-- Help text for states 1 and 2 (before Modell section) -->
      <div id="help-text-top" class="help-text"></div>

      <hr style="margin:12px 0;">

      <div>
        <label data-i18n="training.model">Modell:</label>
        <div style="display:flex;gap:8px;margin-top:6px;">
          <button id="save-model" class="ghost" style="display:none;" data-i18n="training.save">Speichern</button>
          <label class="file-label" for="load-model" data-i18n="training.load">
            Laden
            <input id="load-model" type="file" accept=".zip" style="display:none">
          </label>
        </div>
        <div id="model-info" class="model-info"></div>
      </div>

      <!-- Help text for state 3 (after Training section appears) -->
      <div id="help-text-middle" class="help-text"></div>

      <!-- Step 4: Project Download (shown after training completed) -->
      <div id="step-project-download" class="step-section">
        <div class="project-buttons">
          <button id="download-project" data-i18n="training.downloadProject">Projekt herunterladen</button>
        </div>
      </div>

      <!-- Always visible: Project Import -->
      <div class="project-buttons">
        <label class="file-label" for="import-project" data-i18n="training.importProject">
          Projekt importieren
          <input id="import-project" type="file" accept=".zip" style="display:none">
        </label>
      </div>
    </div>

    <!-- RIGHT -->
    <div class="right-panel">
      <div class="tabs">
      </div>
      
      <div id="train-tab" class="tab-content active">
        <div class="video-wrap">
          <video id="webcam" autoplay playsinline></video>
          <div class="overlay">
            <div id="status" class="status dark" data-i18n="training.status">Lädt…</div>
          </div>
        </div>
      </div>

      <div id="test-tab" class="tab-content">
        <div class="video-wrap">
          <video id="webcam-test" autoplay playsinline></video>
          <div class="overlay">
            <div id="test-status" class="status dark" data-i18n="training.testStatus">Bereit zum Testen</div>
            <button id="test-capture" class="ghost" data-i18n="training.testButton">Testen</button>
            <div id="test-hint" class="button-hint" style="color:#adf54c;" data-i18n="training.testHint">Klicke zum Starten/Stoppen der Echtzeit-Vorhersage</div>
          </div>
          <div id="prediction-display" class="prediction-display"></div>
        </div>
      </div>
    </div>
  </div>

  <!-- TRY OUT VIEW -->
  <!-- TRY OUT VIEW -->
<div id="tryout-view" class="view" style="display:none;">

  <!-- MAKECODE EDITOR - FULL WIDTH -->
  <div class="full-width-panel panel">
    <iframe
    id="calliope-editor"
    src="https://makecode.calliope.cc/?controller=1&nocookiebanner=1&ws=browser#pub:_VjjUK8cH6JCw"
    allow="usb; bluetooth; autoplay;"
    sandbox="allow-scripts allow-same-origin allow-forms allow-popups allow-modals"
    style="width: 100%; height: 100%; border: 0;border-radius:16px;margin:0;"
    allowfullscreen></iframe>
  </div>

</div> <!-- tryout-view -->
<!-- APPLY VIEW -->
<div id="apply-view" class="view" style="display:none;">

  <div class="right-panel" style="width:100%; padding-left:0;">

    <div class="video-wrap">
      <video id="webcam-apply" autoplay playsinline></video>
      <div id="apply-prediction" class="prediction-display" style="display: none;"></div>
    </div>

  </div>

  <!-- COLLAPSIBLE MODEL LOADER OVERLAY -->
  <div id="model-loader-overlay" class="model-loader-overlay collapsed">
    <div class="model-loader-header" onclick="toggleModelLoader()">
      <h3 data-i18n="tryout.loadModelTitle">Modell laden</h3>
      <button class="toggle-btn" id="model-loader-toggle">
        <svg width="20" height="20" viewBox="0 0 20 20" fill="currentColor">
          <path d="M5 7l5 5 5-5H5z"/>
        </svg>
      </button>
    </div>

    <div id="model-loader-content" class="model-loader-content">
      <div>
        <label data-i18n="tryout.trainedModel">Trainiertes Modell:</label>
        <div style="display:flex;gap:8px;margin-top:6px;">
          <label class="file-label" for="tryout-load-model" data-i18n="tryout.uploadModel">
            Modell hochladen
            <input id="tryout-load-model" type="file" accept=".zip" style="display:none">
          </label>
        </div>
        <div id="tryout-model-info" class="model-info"></div>
      </div>

      <hr style="margin:12px 0;">

      <h3 data-i18n="tryout.calliopeConnection">Calliope mini Verbindung</h3>
      <div class="try-out-status">
        <div id="bt-status-indicator" class="status-indicator"></div>
        <span id="bt-status-text" data-i18n="tryout.notConnected">Nicht verbunden</span>
      </div>

      <div class="bluetooth-controls">
        <button id="scan-bluetooth" data-i18n="tryout.connect">Verbinden</button>
        <button id="disconnect-bluetooth" style="display:none;" data-i18n="tryout.disconnect">Trennen</button>
        <div id="bluetooth-devices" style="margin-top:10px;"></div>
        <div id="bluetooth-status" class="bluetooth-status" data-i18n="tryout.readyToConnect">Bereit zur Verbindung</div>
        <label style="display:flex;align-items:center;gap:8px;margin-top:10px;">
          <input type="checkbox" id="send-every-prediction">
          <span data-i18n="tryout.sendEveryPrediction">Jede Klasse dauerhaft senden (ab 70% Wahrscheinlichkeit)</span>
        </label>
      </div>
    </div>
  </div>

</div>




<!-- Import Dialog (hidden by default) -->
<div id="dialog-overlay" class="dialog-overlay" style="display:none;"></div>
<div id="import-dialog" class="import-dialog" style="display:none;">
  <h3 data-i18n="dialogs.importTitle">Bilder importieren</h3>
  <p id="import-message" data-i18n="dialogs.importMessage">Wähle eine Klasse für die importierten Bilder:</p>
  <div id="import-class-options"></div>
  <div class="buttons">
    <button id="import-cancel" class="ghost" data-i18n="dialogs.cancel">Abbrechen</button>
    <button id="import-confirm" data-i18n="dialogs.import">Importieren</button>
  </div>
</div>

<!-- Model Details Dialog (hidden by default) -->
<div id="model-details-dialog" class="model-details-dialog" style="display:none;">
  <button class="close-btn" id="close-details">&times;</button>
  <h2 data-i18n="dialogs.modelDetailsTitle">Modell-Details</h2>

  <div class="model-details-tabs">
    <div class="model-details-tab active" data-tab="overview" data-i18n="dialogs.overviewTab">Übersicht</div>
    <div class="model-details-tab" data-tab="accuracy" data-i18n="dialogs.accuracyTab">Genauigkeit</div>
    <div class="model-details-tab" data-tab="confusion" data-i18n="dialogs.confusionTab">Verwechslungsmatrix</div>
  </div>
  
  <div id="overview-tab" class="model-details-content active">
    <div class="section-description">
      <strong>Modellübersicht</strong><br>
      <em>Begriffserklärung: Ein "Modell" ist das trainierte neuronale Netzwerk, das gelernt hat, die definierten Klassen zu erkennen. "Genauigkeit" beschreibt, wie oft das Modell richtig liegt, während der "Verlust" (Loss) angibt, wie weit die Vorhersagen vom korrekten Ergebnis entfernt sind. "Epochen" sind Trainingsrunden, in denen das Modell alle Trainingsdaten einmal durchläuft.</em><br><br>

      Diese Übersicht zeigt wichtige Metriken des trainierten Modells. Die Statistiken geben einen schnellen Einblick in die Leistungsfähigkeit, während der Graph die Entwicklung von Genauigkeit und Verlust über die Trainingsepochen hinweg visualisiert.<br><br>

      <strong>Wichtig:</strong> Die Genauigkeit wird auf 20% Validierungsdaten gemessen, die nicht fürs Training verwendet wurden. Dies gibt einen realistischen Eindruck, wie gut das Modell auf neuen, unbekannten Daten funktioniert.<br><br>

      <strong>Genauigkeitswerte:</strong><br>
      <span class="value-guideline value-excellent">>90%</span> Exzellent - Modell sehr zuverlässig<br>
      <span class="value-guideline value-good">70-90%</span> Gut - Modell für die meisten Anwendungsfälle geeignet<br>
      <span class="value-guideline value-needs-improvement"><70%</span> Verbesserungsbedürftig - Mehr Trainingsdaten oder Epochen benötigt<br><br>

      <strong>Verlustwerte:</strong><br>
      <span class="value-guideline value-excellent"><0.1</span> Sehr gut - Modell lernt effektiv<br>
      <span class="value-guideline value-good">0.1-0.5</span> Gut - Akzeptables Lernverhalten<br>
      <span class="value-guideline value-needs-improvement">>0.5</span> Hoch - Modell hat nicht ausreichend gelernt, mehr Training nötig<br><br>

      <strong>Trainingsepochen:</strong><br>
      Typischerweise 10-50 Epochen für kleine Datensätze. Wenn die Genauigkeit nach 20 Epochen nicht mehr steigt, ist das Modell wahrscheinlich ausreichend trainiert.<br><br>

      <strong>Trainingsdaten:</strong><br>
      Die angezeigte Anzahl entspricht den aufgenommenen Bildern. Durch Datenaugmentierung (zufällige Variationen wie Verschiebung und Skalierung) werden pro Bild 3 Trainingsbeispiele erstellt, um die Robustheit des Modells zu verbessern.
    </div>
    
    <div class="model-stats">
      <div class="stat-card">
        <div class="stat-value" id="overall-accuracy">-</div>
        <div class="stat-label" data-i18n="modelDetails.overallAccuracy">Gesamtgenauigkeit</div>
      </div>
      <div class="stat-card">
        <div class="stat-value" id="total-loss">-</div>
        <div class="stat-label" data-i18n="modelDetails.totalLoss">Gesamtverlust</div>
      </div>
      <div class="stat-card">
        <div class="stat-value" id="total-epochs">-</div>
        <div class="stat-label" data-i18n="modelDetails.trainingEpochs">Trainingsepochen</div>
      </div>
      <div class="stat-card">
        <div class="stat-value" id="total-examples">-</div>
        <div class="stat-label" data-i18n="modelDetails.trainingData">Trainingsdaten</div>
      </div>
    </div>
    
    <div class="chart-container">
      <canvas id="accuracy-loss-chart"></canvas>
    </div>
  </div>
  
  <div id="accuracy-tab" class="model-details-content">
    <div class="section-description">
      <strong>Genauigkeit pro Klasse</strong><br>
      <em>Begriffserklärung: Eine "Klasse" ist eine Kategorie, die definiert wurde (z.B. "Hand", "Gesicht", "Hintergrund"). Die "Genauigkeit pro Klasse" zeigt, wie zuverlässig das Modell jede einzelne der Klassen erkennt.</em><br><br>

      Dieses Balkendiagramm zeigt die Genauigkeit des Modells für jede einzelne Klasse. Es hilft zu erkennen, bei welchen Klassen das Modell gut funktioniert und bei welchen es Schwierigkeiten hat.<br><br>

      <strong>Interpretation der Werte:</strong><br>
      <span class="value-guideline value-excellent">>90%</span> Exzellent - Klasse wird sehr zuverlässig erkannt<br>
      <span class="value-guideline value-good">70-90%</span> Gut - Klasse wird meistens korrekt erkannt<br>
      <span class="value-guideline value-needs-improvement"><70%</span> Problematisch - Klasse benötigt mehr oder bessere Trainingsdaten<br><br>

      <strong>Mögliche Ursachen für niedrige Genauigkeit:</strong><br>
      • Zu wenige Trainingsbilder für diese Klasse<br>
      • Bilder sind zu ähnlich zu anderen Klassen<br>
      • Schlechte Lichtverhältnisse oder unscharfe Bilder<br>
      • Klasse hat zu viele Variationen (z.B. "verschiedene Objekte")<br><br>

      <strong>Verbesserungstipps:</strong><br>
      • Füge mindestens 40-50 Bilder pro Klasse hinzu<br>
      • Stelle sicher, dass die Bilder konsistent sind<br>
      • Vermeide ähnliche Objekte in verschiedenen Klassen
    </div>
    
    <div class="chart-container">
      <canvas id="accuracy-chart"></canvas>
    </div>
  </div>
  
  <div id="confusion-tab" class="model-details-content">
    <div class="section-description">
      <strong>Verwechslungsmatrix</strong><br>
      <em>Begriffserklärung: Die "Verwechslungsmatrix" (auch Konfusionsmatrix genannt) ist eine Tabelle, die zeigt, welche Klassen das Modell miteinander verwechselt. Sie hilft zu erkennen, ob das Modell systematisch bestimmte Klassen falsch zuordnet.</em><br><br>

      Die Verwechslungsmatrix visualisiert die Leistung des Modells, indem sie zeigt, welche Klassen miteinander verwechselt werden. Die Zeilen repräsentieren die tatsächlichen Klassen, während die Spalten die vom Modell vorhergesagten Klassen darstellen. Die Diagonale (von links oben nach rechts unten) zeigt die korrekt klassifizierten Beispiele. Werte außerhalb der Diagonale sind Fehlklassifizierungen. Eine perfekte Klassifikation hätte nur Werte auf der Diagonale.<br><br>

      <strong>Wie man die Matrix liest:</strong><br>
      • Diagonale Werte: Korrekt klassifizierte Beispiele<br>
      • Werte außerhalb der Diagonale: Fehlklassifizierungen<br>
      • Hohe Werte außerhalb der Diagonale: Systematische Verwechslung zwischen Klassen<br>
      • Niedrige Werte auf der Diagonale: Klasse wird oft falsch erkannt<br><br>

      <strong>Gute Anzeichen:</strong><br>
      • Die meisten Werte liegen auf der Diagonale<br>
      • Keine offensichtlichen Muster in den Fehlklassifizierungen<br>
      • Alle Klassen haben ähnliche Erkennungsraten
    </div>

    <div class="confusion-matrix">
      <h3 data-i18n="modelDetails.confusionMatrixTitle">Verwechslungsmatrix</h3>
      <div id="confusion-matrix-container"></div>
    </div>
  </div>
</div>

<!-- Model Load Notification -->
<div id="model-load-notification" class="model-load-notification"></div>

<script>

// Configuration constants
/*
 * ENHANCED MODEL CONFIGURATION FOR IMPROVED ACCURACY
 *
 * Key improvements implemented:
 * 1. Deeper neural network (2 hidden layers with 256 and 128 units)
 * 2. Batch normalization for training stability
 * 3. Enhanced data augmentation (rotation, brightness, flipping, more jitter/scale)
 * 4. More augmentation copies (5 instead of 3)
 * 5. Learning rate decay schedule for better convergence
 * 6. Early stopping to prevent overfitting
 * 7. More training epochs (30 instead of 20)
 * 8. Higher dropout rate (0.4) for better regularization
 *
 * These changes should significantly improve model accuracy compared to the baseline.
 */
const CONFIG = {
  IMAGE_SIZE: 224,
  CAPTURE_RATE_MS: 80,
  PREDICTION_RATE_MS: 100,
  SEND_INTERVAL_MS: 500,
  AUGMENT_COPIES: 5, // Increased from 3 for more training variety
  PREDICTION_BUFFER_SIZE: 5,
  MIN_PREDICTION_CONFIDENCE: 0.70,
  MIN_CONFIDENCE_MARGIN: 0.15, // Top prediction must be 15% higher than second place
  PREDICTION_SMOOTHING: true, // Average predictions over multiple frames
  SMOOTHING_WINDOW: 3, // Number of frames to average
  MOBILENET_EMBEDDING_SIZE: 1024,
  CLASSIFIER_HIDDEN_UNITS_1: 256, // First hidden layer (increased from 128)
  CLASSIFIER_HIDDEN_UNITS_2: 128, // Second hidden layer (new)
  CLASSIFIER_DROPOUT_RATE: 0.4, // Increased from 0.3 for better regularization
  CLASSIFIER_L2_REGULARIZATION: 5e-5, // Reduced slightly for less restriction
  CLASSIFIER_LEARNING_RATE: 0.001, // Increased initial rate (will decay)
  DEFAULT_EPOCHS: 30, // Increased from 20 for better convergence
  DEFAULT_BATCH_SIZE: 16,
  VALIDATION_SPLIT: 0.2,
  AUGMENT_JITTER_RANGE: 15, // Increased from 10 for more position variation
  AUGMENT_SCALE_RANGE: 0.15, // Increased from 0.08 for more scale variation
  AUGMENT_ROTATION_RANGE: 15, // New: rotation in degrees
  AUGMENT_BRIGHTNESS_RANGE: 0.2, // New: brightness variation
  AUGMENT_FLIP_HORIZONTAL: true // New: random horizontal flip
};

// Translations
// Detect browser language and set default
function detectBrowserLanguage() {
  const browserLang = navigator.language || navigator.userLanguage;
  const langCode = browserLang.split('-')[0].toLowerCase();

  // Supported languages
  const supportedLanguages = ['de', 'en', 'fr', 'es', 'it', 'el'];

  // Return detected language if supported, otherwise default to English
  return supportedLanguages.includes(langCode) ? langCode : 'en';
}

let currentLanguage = detectBrowserLanguage();

const translations = {
  de: {
    welcome: {
      title: 'Willkommen bei <br>Calliope <span>Teachable Machine</span>',
      subtitle: 'Steuere deinen Calliope mini mit Gesten oder Farben.',
      start: 'Starten',
      aiInfo: 'Hinweise',
      languages: 'Sprachen',
      selectLanguage: 'Sprache auswählen'
    },
    header: {
      training: 'Trainieren',
      tryout: 'Programmieren',
      apply: 'Anwenden'
    },
    training: {
      model: 'Modell:',
      save: 'Speichern',
      load: 'Laden',
      newClass: 'Neue Klasse:',
      newClassPlaceholder: 'z. B. Hand',
      addClass: '+',
      classes: 'Klassen:',
      clickToSelect: 'Klick zum Auswählen',
      downloadAll: 'Alle herunterladen',
      activeClass: 'Aktive Klasse:',
      startCapture: 'Aufnahme starten',
      stopCapture: 'Aufnahme stoppen',
      files: 'Dateien',
      clear: 'Leeren',
      deleteClass: 'Klasse löschen',
      confirmDeleteClass: 'Klasse wirklich löschen?',
      downloadImages: 'Bilder herunterladen',
      captureHint: 'Halte die Taste gedrückt, um Bilder aufzunehmen (10 Bilder/Sekunde)',
      imagesCount: 'Bilder',
      training: 'Training:',
      train: 'Modell Trainieren',
      trainStatus: 'Bereit',
      modelDetails: 'Modell Details',
      downloadProject: 'Projekt herunterladen',
      downloadProjectBtn: 'Für Calliope mini',
      importProject: 'Projekt importieren',
      status: 'Lädt…',
      testStatus: 'Bereit zum Testen',
      testButton: 'Testen',
      testHint: 'Klicke zum Starten/Stoppen der Echtzeit-Vorhersage'
    },
    status: {
      processingImages: 'Verarbeite Bilder...',
      trainingFailed: 'Training fehlgeschlagen',
      training: 'Trainiere...',
      trainingComplete: 'Fertig - nun kann das Modell genutzt werden!',
      modelReadyTest: 'Modell bereit zum Testen',
      modelReadyTryout: 'Modell bereit zum Ausprobieren',
      pleaseTrainModel: 'Bitte Modell trainieren',
      minTwoClasses: 'Mind. zwei Klassen nötig',
      trainingError: 'Fehler beim Training',
      projectLoaded: 'Projekt geladen',
      modelLoaded: 'Modell',
      selectClassFirst: 'Bitte wähle zuerst eine Klasse aus',
      epoch: 'Epoche',
      val: 'Val',
      uncertain: 'Unsicher'
    },
    tryout: {
      loadModelTitle: 'Modell laden',
      trainedModel: 'Trainiertes Modell:',
      uploadModel: 'Modell hochladen',
      ready: 'Bereit zum Ausprobieren',
      start: 'Starten',
      stop: 'Stoppen',
      hint: 'Klicke auf Starten zum Starten/Stoppen der Echtzeit-Vorhersage',
      calliopeConnection: 'Calliope mini Verbindung',
      notConnected: 'Nicht verbunden',
      connected: 'Verbunden',
      connect: 'Verbinden',
      disconnect: 'Trennen',
      disconnected: 'Verbindung getrennt',
      readyToConnect: 'Bereit zur Verbindung',
      sendEveryPrediction: 'Jede Klasse dauerhaft senden (ab 70% Wahrscheinlichkeit)'
    },
    dialogs: {
      importTitle: 'Bilder importieren',
      importMessage: 'Wähle eine Klasse für die importierten Bilder:',
      cancel: 'Abbrechen',
      import: 'Importieren',
      modelDetailsTitle: 'Modell-Details',
      overviewTab: 'Übersicht',
      accuracyTab: 'Genauigkeit',
      confusionTab: 'Verwechslungsmatrix'
    },
    modelDetails: {
      overallAccuracy: 'Gesamtgenauigkeit',
      totalLoss: 'Gesamtverlust',
      trainingEpochs: 'Trainingsepochen',
      trainingData: 'Trainingsdaten',
      overviewTitle: 'Modellübersicht',
      overviewTerms: 'Begriffserklärung: Ein "Modell" ist das trainierte neuronale Netzwerk, das gelernt hat, die definierten Klassen zu erkennen. "Genauigkeit" beschreibt, wie oft das Modell richtig liegt, während der "Verlust" (Loss) angibt, wie weit die Vorhersagen vom korrekten Ergebnis entfernt sind. "Epochen" sind Trainingsrunden, in denen das Modell alle Trainingsdaten einmal durchläuft.',
      overviewIntro: 'Diese Übersicht zeigt wichtige Metriken des trainierten Modells. Die Statistiken geben einen schnellen Einblick in die Leistungsfähigkeit, während der Graph die Entwicklung von Genauigkeit und Verlust über die Trainingsepochen hinweg visualisiert.',
      overviewValidation: '<strong>Wichtig:</strong> Die Genauigkeit wird auf 20% Validierungsdaten gemessen, die nicht fürs Training verwendet wurden. Dies gibt einen realistischen Eindruck, wie gut das Modell auf neuen, unbekannten Daten funktioniert.',
      accuracyValues: '<strong>Genauigkeitswerte:</strong><br><span class="value-guideline value-excellent">>90%</span> Exzellent - Modell sehr zuverlässig<br><span class="value-guideline value-good">70-90%</span> Gut - Modell für die meisten Anwendungsfälle geeignet<br><span class="value-guideline value-needs-improvement"><70%</span> Verbesserungsbedürftig - Mehr Trainingsdaten oder Epochen benötigt',
      lossValues: '<strong>Verlustwerte:</strong><br><span class="value-guideline value-excellent"><0.1</span> Sehr gut - Modell lernt effektiv<br><span class="value-guideline value-good">0.1-0.5</span> Gut - Akzeptables Lernverhalten<br><span class="value-guideline value-needs-improvement">>0.5</span> Hoch - Modell hat nicht ausreichend gelernt, mehr Training nötig',
      epochsInfo: '<strong>Trainingsepochen:</strong><br>Typischerweise 10-50 Epochen für kleine Datensätze. Wenn die Genauigkeit nach 20 Epochen nicht mehr steigt, ist das Modell wahrscheinlich ausreichend trainiert.',
      dataInfo: '<strong>Trainingsdaten:</strong><br>Die angezeigte Anzahl entspricht den aufgenommenen Bildern. Durch Datenaugmentierung (zufällige Variationen wie Verschiebung und Skalierung) werden pro Bild 3 Trainingsbeispiele erstellt, um die Robustheit des Modells zu verbessern.',
      accuracyPerClassTitle: 'Genauigkeit pro Klasse',
      accuracyPerClassTerms: 'Begriffserklärung: Eine "Klasse" ist eine Kategorie, die definiert wurde (z.B. "Hand", "Gesicht", "Hintergrund"). Die "Genauigkeit pro Klasse" zeigt, wie zuverlässig das Modell jede einzelne der Klassen erkennt.',
      accuracyPerClassIntro: 'Dieses Balkendiagramm zeigt die Genauigkeit des Modells für jede einzelne Klasse. Es hilft zu erkennen, bei welchen Klassen das Modell gut funktioniert und bei welchen es Schwierigkeiten hat.',
      interpretationTitle: '<strong>Interpretation der Werte:</strong><br><span class="value-guideline value-excellent">>90%</span> Exzellent - Klasse wird sehr zuverlässig erkannt<br><span class="value-guideline value-good">70-90%</span> Gut - Klasse wird meistens korrekt erkannt<br><span class="value-guideline value-needs-improvement"><70%</span> Problematisch - Klasse benötigt mehr oder bessere Trainingsdaten',
      lowAccuracyCauses: '<strong>Mögliche Ursachen für niedrige Genauigkeit:</strong><br>• Zu wenige Trainingsbilder für diese Klasse<br>• Bilder sind zu ähnlich zu anderen Klassen<br>• Schlechte Lichtverhältnisse oder unscharfe Bilder<br>• Klasse hat zu viele Variationen (z.B. "verschiedene Objekte")',
      improvementTips: '<strong>Verbesserungstipps:</strong><br>• Füge mindestens 40-50 Bilder pro Klasse hinzu<br>• Stelle sicher, dass die Bilder konsistent sind<br>• Vermeide ähnliche Objekte in verschiedenen Klassen',
      confusionMatrixTitle: 'Verwechslungsmatrix',
      confusionMatrixTerms: 'Begriffserklärung: Die "Verwechslungsmatrix" (auch Konfusionsmatrix genannt) ist eine Tabelle, die zeigt, welche Klassen das Modell miteinander verwechselt. Sie hilft zu erkennen, ob das Modell systematisch bestimmte Klassen falsch zuordnet.',
      confusionMatrixIntro: 'Die Verwechslungsmatrix visualisiert die Leistung des Modells, indem sie zeigt, welche Klassen miteinander verwechselt werden. Die Zeilen repräsentieren die tatsächlichen Klassen, während die Spalten die vom Modell vorhergesagten Klassen darstellen.',
      confusionMatrixReading: '<strong>So liest du die Matrix:</strong><br>• <strong>Diagonale (dunkelgrün):</strong> Korrekte Vorhersagen – hier sollten die höchsten Werte stehen<br>• <strong>Außerhalb der Diagonale:</strong> Fehler – das Modell hat eine Klasse mit einer anderen verwechselt<br>• <strong>Hellere Zellen:</strong> Niedrige Werte (wenige oder keine Verwechslungen)<br>• <strong>Dunklere Zellen:</strong> Höhere Werte (häufige Verwechslungen)',
      confusionMatrixExample: '<strong>Beispiel:</strong><br>Wenn in Zeile "Hand" und Spalte "Faust" ein hoher Wert steht, bedeutet dies, dass das Modell häufig "Hand" als "Faust" falsch klassifiziert.',
      confusionMatrixPerfect: '<strong>Perfektes Modell:</strong><br>Bei einem perfekten Modell würden nur die Diagonalwerte gefüllt sein (alle Vorhersagen sind korrekt), während alle anderen Zellen 0 wären.',
      confusionMatrixImprovement: '<strong>Verbesserungstipps bei häufigen Verwechslungen:</strong><br>• Füge mehr unterscheidende Trainingsbilder für verwechselte Klassen hinzu<br>• Stelle sicher, dass die Klassen visuell klar unterscheidbar sind<br>• Erwäge, sehr ähnliche Klassen zusammenzulegen',
      predicted: 'Vorhergesagt',
      actual: 'Tatsächlich',
      chartAccuracyLossTitle: 'Genauigkeit und Verlust pro Epoche',
      chartAccuracyLabel: 'Genauigkeit',
      chartLossLabel: 'Verlust',
      chartEpochLabel: 'Epoche',
      chartClassAccuracyTitle: 'Genauigkeit pro Klasse',
      chartClassAccuracyLabel: 'Klassengenauigkeit'
    },
    helpTexts: {
      text1: 'Benenne eine Klasse und speichere den Namen ab. Danach kannst du dieser Klasse Bilder hinzufügen.',
      text2: 'Alle Klassen benötigen Bilder. Je mehr Bilder eine Klasse hat, desto besser kann die jeweilige Klasse erkannt werden. Es sollten mindestens 60 Bilder pro Klasse sein!',
      text3: 'Es müssen mindestens drei Klassen mit Bildern erstellt werden, um das Modell trainieren zu können!'
    },
    aiInfo: {
      title: 'Hinweise',
      section1Title: 'Du arbeitest mit einem KI-System',
      section1Text: 'Die Calliope Teachable Machine nutzt künstliche Intelligenz (KI), um aus deinen Beispielbildern zu lernen. Das bedeutet: Du trainierst ein Modell, das eigenständig Muster in Bildern erkennt – zum Beispiel unterschiedliche Handgesten oder Farben.',
      section2Title: 'So funktioniert das System',
      section2Text1: 'Das Modell basiert auf einer Technik namens "Transfer Learning". Dabei nutzen wir ein bereits vortrainiertes neuronales Netz (MobileNet), das bereits viele Bildmerkmale kennt. Deine Beispielbilder werden verwendet, um dieses Wissen auf deine spezielle Aufgabe anzupassen – etwa die Unterscheidung deiner eigenen Gesten.',
      section2Text2: 'Alle Berechnungen und das Training finden direkt in deinem Browser statt. Keine Daten werden an Server übertragen – alles bleibt lokal auf deinem Gerät.',
      section3Title: 'Deine Daten bleiben bei dir',
      section3Text: 'Alle Bilder, die du mit der Webcam aufnimmst, werden ausschließlich lokal verarbeitet. Sie verlassen deinen Computer nicht. Auch das trainierte Modell wird nur auf deinem Gerät gespeichert.',
      section4Title: 'Grenzen und Einschränkungen',
      section4Text1: 'Dein trainiertes Modell ist nur so gut wie deine Trainingsdaten. Wenn du zum Beispiel nur Bilder bei Tageslicht aufnimmst, funktioniert das Modell bei schlechten Lichtverhältnissen möglicherweise nicht zuverlässig. Je vielfältiger deine Beispiele sind, desto robuster wird das Modell.',
      section4Text2: 'Das System ist für <strong>Lern- und Experimentierprojekte</strong> gedacht. Es ist nicht geeignet für sicherheitskritische Anwendungen oder Entscheidungen, die Menschen beeinflussen könnten.',
      section5Title: 'Fairness und Verantwortung',
      section5Text: 'Du entscheidest, welche Bilder du zum Training verwendest. Achte darauf, dass deine Trainingsdaten ausgewogen sind und keine Vorurteile widerspiegeln. Wenn du beispielsweise nur Bilder von einer Person aufnimmst, wird das Modell bei anderen Personen möglicherweise schlechter funktionieren.',
      section6Title: 'Wofür ist dieses System geeignet?',
      section6Text: 'Die Teachable Machine ist perfekt für kreative Projekte, Schulprojekte und spielerisches Lernen. Du kannst:',
      section6List: [
        'Farben oder Objekte unterscheiden',
        'Handgesten erkennen, um deinen Calliope mini zu steuern',
        'Verstehen, wie maschinelles Lernen funktioniert',
        'Eigene interaktive Projekte entwickeln'
      ],
      section7Title: 'Weitere Informationen',
      section7Text: 'Falls du Fragen zu diesem Tool haben, kannst du dich natürlich gern bei uns melden. <br>• Am einfachsten geht das per Mail: info@calliope.cc <br>• Dieses Tool folgt den Transparenzanforderungen der EU-KI-Verordnung (EU) 2024/1689. Du hast jederzeit die Kontrolle über deine Daten und Modelle. Bei Fragen zur Funktionsweise kannst du die "Modell Details" nach dem Training einsehen – dort findest du technische Informationen über die Leistung deines Modells.'
    }
  },
  en: {
    welcome: {
      title: 'Welcome to <br>Calliope <span>Teachable Machine</span>',
      subtitle: 'Control your Calliope mini with gestures or colors.',
      start: 'Start',
      aiInfo: 'AI Information',
      languages: 'Languages',
      selectLanguage: 'Select Language'
    },
    header: {
      training: 'Training',
      tryout: 'Programming',
      apply: 'Apply'
    },
    training: {
      model: 'Model:',
      save: 'Save',
      load: 'Load',
      newClass: 'New Class:',
      newClassPlaceholder: 'e.g. Hand',
      addClass: '+',
      classes: 'Classes:',
      clickToSelect: 'Click to select',
      downloadAll: 'Download all',
      activeClass: 'Active Class:',
      startCapture: 'Start Capture',
      stopCapture: 'Stop Capture',
      files: 'Files',
      clear: 'Clear',
      deleteClass: 'Delete class',
      confirmDeleteClass: 'Really delete class?',
      downloadImages: 'Download images',
      captureHint: 'Hold the button to capture images (10 images/second)',
      imagesCount: 'images',
      training: 'Training:',
      train: 'Train Model',
      trainStatus: 'Ready',
      modelDetails: 'Model Details',
      downloadProject: 'Download Project',
      downloadProjectBtn: 'For Calliope mini',
      importProject: 'Import Project',
      status: 'Loading…',
      testStatus: 'Ready to Test',
      testButton: 'Test',
      testHint: 'Click to start/stop real-time prediction'
    },
    status: {
      processingImages: 'Processing images...',
      trainingFailed: 'Training failed',
      training: 'Training...',
      trainingComplete: 'Done - the model can now be used!',
      modelReadyTest: 'Model ready for testing',
      modelReadyTryout: 'Model ready to try out',
      pleaseTrainModel: 'Please train model',
      minTwoClasses: 'At least two classes needed',
      trainingError: 'Training error',
      projectLoaded: 'Project loaded',
      modelLoaded: 'Model',
      selectClassFirst: 'Please select a class first',
      epoch: 'Epoch',
      val: 'Val',
      uncertain: 'Uncertain'
    },
    tryout: {
      loadModelTitle: 'Load Model',
      trainedModel: 'Trained Model:',
      uploadModel: 'Upload Model',
      ready: 'Ready to Try Out',
      start: 'Start',
      stop: 'Stop',
      hint: 'Click Start to start/stop real-time prediction',
      calliopeConnection: 'Calliope mini Connection',
      notConnected: 'Not connected',
      connected: 'Connected',
      connect: 'Connect',
      disconnect: 'Disconnect',
      disconnected: 'Disconnected',
      readyToConnect: 'Ready to connect',
      sendEveryPrediction: 'Send every class continuously (from 70% probability)'
    },
    dialogs: {
      importTitle: 'Import Images',
      importMessage: 'Select a class for the imported images:',
      cancel: 'Cancel',
      import: 'Import',
      modelDetailsTitle: 'Model Details',
      overviewTab: 'Overview',
      accuracyTab: 'Accuracy',
      confusionTab: 'Confusion Matrix'
    },
    modelDetails: {
      overallAccuracy: 'Overall Accuracy',
      totalLoss: 'Total Loss',
      trainingEpochs: 'Training Epochs',
      trainingData: 'Training Data',
      overviewTitle: 'Model Overview',
      overviewTerms: 'Term explanation: A "model" is the trained neural network that has learned to recognize the defined classes. "Accuracy" describes how often the model is correct, while "loss" indicates how far the predictions are from the correct result. "Epochs" are training rounds in which the model goes through all training data once.',
      overviewIntro: 'This overview shows important metrics of the trained model. The statistics provide a quick insight into performance, while the graph visualizes the development of accuracy and loss over training epochs.',
      overviewValidation: '<strong>Important:</strong> Accuracy is measured on 20% validation data that was not used for training. This gives a realistic impression of how well the model works on new, unknown data.',
      accuracyValues: '<strong>Accuracy values:</strong><br><span class="value-guideline value-excellent">>90%</span> Excellent - Model very reliable<br><span class="value-guideline value-good">70-90%</span> Good - Model suitable for most use cases<br><span class="value-guideline value-needs-improvement"><70%</span> Needs improvement - More training data or epochs needed',
      lossValues: '<strong>Loss values:</strong><br><span class="value-guideline value-excellent"><0.1</span> Very good - Model learns effectively<br><span class="value-guideline value-good">0.1-0.5</span> Good - Acceptable learning behavior<br><span class="value-guideline value-needs-improvement">>0.5</span> High - Model has not learned enough, more training needed',
      epochsInfo: '<strong>Training epochs:</strong><br>Typically 10-50 epochs for small datasets. If accuracy stops increasing after 20 epochs, the model is probably sufficiently trained.',
      dataInfo: '<strong>Training data:</strong><br>The displayed number corresponds to the captured images. Through data augmentation (random variations like shift and scale), 3 training examples are created per image to improve model robustness.',
      accuracyPerClassTitle: 'Accuracy per Class',
      accuracyPerClassTerms: 'Term explanation: A "class" is a category that has been defined (e.g. "Hand", "Face", "Background"). "Accuracy per class" shows how reliably the model recognizes each individual class.',
      accuracyPerClassIntro: 'This bar chart shows the model\'s accuracy for each individual class. It helps identify which classes the model works well with and which it struggles with.',
      interpretationTitle: '<strong>Interpretation of values:</strong><br><span class="value-guideline value-excellent">>90%</span> Excellent - Class is recognized very reliably<br><span class="value-guideline value-good">70-90%</span> Good - Class is mostly recognized correctly<br><span class="value-guideline value-needs-improvement"><70%</span> Problematic - Class needs more or better training data',
      lowAccuracyCauses: '<strong>Possible causes for low accuracy:</strong><br>• Too few training images for this class<br>• Images are too similar to other classes<br>• Poor lighting conditions or blurry images<br>• Class has too many variations (e.g. "different objects")',
      improvementTips: '<strong>Improvement tips:</strong><br>• Add at least 40-50 images per class<br>• Make sure the images are consistent<br>• Avoid similar objects in different classes',
      confusionMatrixTitle: 'Confusion Matrix',
      confusionMatrixTerms: 'Term explanation: The "confusion matrix" is a table that shows which classes the model confuses with each other. It helps identify whether the model systematically misclassifies certain classes.',
      confusionMatrixIntro: 'The confusion matrix visualizes the model\'s performance by showing which classes are confused with each other. Rows represent actual classes, while columns represent classes predicted by the model.',
      confusionMatrixReading: '<strong>How to read the matrix:</strong><br>• <strong>Diagonal (dark green):</strong> Correct predictions - highest values should be here<br>• <strong>Outside diagonal:</strong> Errors - model confused one class with another<br>• <strong>Lighter cells:</strong> Low values (few or no confusions)<br>• <strong>Darker cells:</strong> Higher values (frequent confusions)',
      confusionMatrixExample: '<strong>Example:</strong><br>If there is a high value in row "Hand" and column "Fist", this means the model frequently misclassifies "Hand" as "Fist".',
      confusionMatrixPerfect: '<strong>Perfect model:</strong><br>In a perfect model, only the diagonal values would be filled (all predictions are correct), while all other cells would be 0.',
      confusionMatrixImprovement: '<strong>Improvement tips for frequent confusions:</strong><br>• Add more distinctive training images for confused classes<br>• Ensure classes are visually clearly distinguishable<br>• Consider merging very similar classes',
      predicted: 'Predicted',
      actual: 'Actual',
      chartAccuracyLossTitle: 'Accuracy and Loss per Epoch',
      chartAccuracyLabel: 'Accuracy',
      chartLossLabel: 'Loss',
      chartEpochLabel: 'Epoch',
      chartClassAccuracyTitle: 'Accuracy per Class',
      chartClassAccuracyLabel: 'Class Accuracy'
    },
    helpTexts: {
      text1: 'Name a class and save the name. Then you can add images to this class.',
      text2: 'All classes need images. The more images a class has, the better that class can be recognized. There should be at least 60 images per class!',
      text3: 'At least three classes with images must be created to train the model!'
    },
    aiInfo: {
      title: 'AI Information',
      section1Title: 'You are working with an AI system',
      section1Text: 'The Calliope Teachable Machine uses artificial intelligence (AI) to learn from your sample images. This means: You train a model that independently recognizes patterns in images – for example, different hand gestures or colors.',
      section2Title: 'How the system works',
      section2Text1: 'The model is based on a technique called "Transfer Learning". We use a pre-trained neural network (MobileNet) that already knows many image features. Your sample images are used to adapt this knowledge to your specific task – such as distinguishing your own gestures.',
      section2Text2: 'All calculations and training take place directly in your browser. No data is transferred to servers – everything stays local on your device.',
      section3Title: 'Your data stays with you',
      section3Text: 'All images you capture with the webcam are processed exclusively locally. They never leave your computer. The trained model is also only stored on your device.',
      section4Title: 'Limits and restrictions',
      section4Text1: 'Your trained model is only as good as your training data. For example, if you only capture images in daylight, the model may not work reliably in poor lighting conditions. The more diverse your examples are, the more robust the model will be.',
      section4Text2: 'The system is intended for <strong>learning and experimental projects</strong>. It is not suitable for safety-critical applications or decisions that could affect people.',
      section5Title: 'Fairness and responsibility',
      section5Text: 'You decide which images to use for training. Make sure your training data is balanced and does not reflect biases. For example, if you only capture images of one person, the model may perform worse with other people.',
      section6Title: 'What is this system suitable for?',
      section6Text: 'The Teachable Machine is perfect for creative projects, school projects, and playful learning. You can:',
      section6List: [
        'Recognize hand gestures to control your Calliope mini',
        'Distinguish colors or objects',
        'Understand how machine learning works',
        'Develop your own interactive projects'
      ],
      section7Title: 'Further information',
      section7Text: 'This tool follows the transparency requirements of the EU AI Regulation (EU) 2024/1689. You always have control over your data and models. If you have questions about how it works, you can view the "Model Details" after training – there you will find technical information about your model\'s performance.'
    }
  },
  fr: {
    welcome: {
      title: 'Bienvenue à <br>Calliope <span>Teachable Machine</span>',
      subtitle: 'Contrôlez votre Calliope mini avec des gestes ou des couleurs.',
      start: 'Démarrer',
      aiInfo: 'Informations IA',
      languages: 'Langues',
      selectLanguage: 'Sélectionner la langue'
    },
    header: {
      training: 'Entraînement',
      tryout: 'Programmer',
      apply: 'Appliquer'
    },
    training: {
      model: 'Modèle:',
      save: 'Enregistrer',
      load: 'Charger',
      newClass: 'Nouvelle classe:',
      newClassPlaceholder: 'par ex. Main',
      addClass: '+',
      classes: 'Classes:',
      clickToSelect: 'Cliquez pour sélectionner',
      downloadAll: 'Télécharger tout',
      activeClass: 'Classe active:',
      startCapture: 'Démarrer la capture',
      stopCapture: 'Arrêter la capture',
      files: 'Fichiers',
      clear: 'Effacer',
      deleteClass: 'Supprimer la classe',
      confirmDeleteClass: 'Vraiment supprimer la classe ?',
      downloadImages: 'Télécharger les images',
      captureHint: 'Maintenez le bouton enfoncé pour capturer des images (10 images/seconde)',
      imagesCount: 'images',
      training: 'Entraînement:',
      train: 'Entraîner le modèle',
      trainStatus: 'Prêt',
      modelDetails: 'Détails du modèle',
      downloadProject: 'Télécharger le projet',
      downloadProjectBtn: 'Pour Calliope mini',
      importProject: 'Importer le projet',
      status: 'Chargement…',
      testStatus: 'Prêt à tester',
      testButton: 'Tester',
      testHint: 'Cliquez pour démarrer/arrêter la prédiction en temps réel'
    },
    status: {
      processingImages: 'Traitement des images...',
      trainingFailed: 'Échec de l\'entraînement',
      training: 'Entraînement...',
      trainingComplete: 'Terminé - le modèle peut maintenant être utilisé !',
      modelReadyTest: 'Modèle prêt pour les tests',
      modelReadyTryout: 'Modèle prêt à essayer',
      pleaseTrainModel: 'Veuillez entraîner le modèle',
      minTwoClasses: 'Au moins deux classes nécessaires',
      trainingError: 'Erreur d\'entraînement',
      projectLoaded: 'Projet chargé',
      modelLoaded: 'Modèle',
      selectClassFirst: 'Veuillez d\'abord sélectionner une classe',
      epoch: 'Époque',
      val: 'Val',
      uncertain: 'Incertain'
    },
    tryout: {
      loadModelTitle: 'Charger le modèle',
      trainedModel: 'Modèle entraîné:',
      uploadModel: 'Télécharger le modèle',
      ready: 'Prêt à essayer',
      start: 'Démarrer',
      stop: 'Arrêter',
      hint: 'Cliquez sur Démarrer pour démarrer/arrêter la prédiction en temps réel',
      calliopeConnection: 'Connexion Calliope mini',
      notConnected: 'Non connecté',
      connected: 'Connecté',
      connect: 'Connecter',
      disconnect: 'Déconnecter',
      disconnected: 'Déconnecté',
      readyToConnect: 'Prêt à se connecter',
      sendEveryPrediction: 'Envoyer chaque classe en continu (à partir de 70% de probabilité)'
    },
    dialogs: {
      importTitle: 'Importer des images',
      importMessage: 'Sélectionnez une classe pour les images importées:',
      cancel: 'Annuler',
      import: 'Importer',
      modelDetailsTitle: 'Détails du modèle',
      overviewTab: 'Aperçu',
      accuracyTab: 'Précision',
      confusionTab: 'Matrice de confusion'
    },
    modelDetails: {
      overallAccuracy: 'Précision globale',
      totalLoss: 'Perte totale',
      trainingEpochs: 'Époques d\'entraînement',
      trainingData: 'Données d\'entraînement',
      overviewTitle: 'Aperçu du modèle',
      overviewTerms: 'Explication des termes: Un "modèle" est le réseau neuronal entraîné qui a appris à reconnaître les classes définies. La "précision" décrit la fréquence à laquelle le modèle est correct, tandis que la "perte" indique à quel point les prédictions sont éloignées du résultat correct. Les "époques" sont des cycles d\'entraînement au cours desquels le modèle parcourt toutes les données d\'entraînement une fois.',
      overviewIntro: 'Cet aperçu montre des métriques importantes du modèle entraîné. Les statistiques donnent un aperçu rapide des performances, tandis que le graphique visualise l\'évolution de la précision et de la perte au fil des époques d\'entraînement.',
      overviewValidation: '<strong>Important:</strong> La précision est mesurée sur 20% des données de validation qui n\'ont pas été utilisées pour l\'entraînement. Cela donne une impression réaliste de la performance du modèle sur de nouvelles données inconnues.',
      accuracyValues: '<strong>Valeurs de précision:</strong><br><span class="value-guideline value-excellent">>90%</span> Excellent - Modèle très fiable<br><span class="value-guideline value-good">70-90%</span> Bon - Modèle adapté à la plupart des cas d\'utilisation<br><span class="value-guideline value-needs-improvement"><70%</span> À améliorer - Plus de données d\'entraînement ou d\'époques nécessaires',
      lossValues: '<strong>Valeurs de perte:</strong><br><span class="value-guideline value-excellent"><0.1</span> Très bon - Le modèle apprend efficacement<br><span class="value-guideline value-good">0.1-0.5</span> Bon - Comportement d\'apprentissage acceptable<br><span class="value-guideline value-needs-improvement">>0.5</span> Élevé - Le modèle n\'a pas suffisamment appris, plus d\'entraînement nécessaire',
      epochsInfo: '<strong>Époques d\'entraînement:</strong><br>Généralement 10-50 époques pour les petits ensembles de données. Si la précision cesse d\'augmenter après 20 époques, le modèle est probablement suffisamment entraîné.',
      dataInfo: '<strong>Données d\'entraînement:</strong><br>Le nombre affiché correspond aux images capturées. Grâce à l\'augmentation des données (variations aléatoires comme le décalage et l\'échelle), 3 exemples d\'entraînement sont créés par image pour améliorer la robustesse du modèle.',
      accuracyPerClassTitle: 'Précision par classe',
      accuracyPerClassTerms: 'Explication des termes: Une "classe" est une catégorie qui a été définie (par exemple "Main", "Visage", "Arrière-plan"). La "précision par classe" montre avec quelle fiabilité le modèle reconnaît chaque classe individuelle.',
      accuracyPerClassIntro: 'Ce diagramme à barres montre la précision du modèle pour chaque classe individuelle. Il aide à identifier les classes avec lesquelles le modèle fonctionne bien et celles avec lesquelles il a des difficultés.',
      interpretationTitle: '<strong>Interprétation des valeurs:</strong><br><span class="value-guideline value-excellent">>90%</span> Excellent - La classe est reconnue très fiablement<br><span class="value-guideline value-good">70-90%</span> Bon - La classe est généralement reconnue correctement<br><span class="value-guideline value-needs-improvement"><70%</span> Problématique - La classe a besoin de plus ou de meilleures données d\'entraînement',
      lowAccuracyCauses: '<strong>Causes possibles de faible précision:</strong><br>• Trop peu d\'images d\'entraînement pour cette classe<br>• Les images sont trop similaires à d\'autres classes<br>• Mauvaises conditions d\'éclairage ou images floues<br>• La classe a trop de variations (par ex. "objets différents")',
      improvementTips: '<strong>Conseils d\'amélioration:</strong><br>• Ajoutez au moins 40-50 images par classe<br>• Assurez-vous que les images sont cohérentes<br>• Évitez les objets similaires dans différentes classes',
      confusionMatrixTitle: 'Matrice de confusion',
      confusionMatrixTerms: 'Explication des termes: La "matrice de confusion" est un tableau qui montre quelles classes le modèle confond entre elles. Elle aide à identifier si le modèle classe systématiquement certaines classes de manière incorrecte.',
      confusionMatrixIntro: 'La matrice de confusion visualise les performances du modèle en montrant quelles classes sont confondues entre elles. Les lignes représentent les classes réelles, tandis que les colonnes représentent les classes prédites par le modèle.',
      confusionMatrixReading: '<strong>Comment lire la matrice:</strong><br>• <strong>Diagonale (vert foncé):</strong> Prédictions correctes - les valeurs les plus élevées devraient être ici<br>• <strong>Hors diagonale:</strong> Erreurs - le modèle a confondu une classe avec une autre<br>• <strong>Cellules plus claires:</strong> Valeurs faibles (peu ou pas de confusions)<br>• <strong>Cellules plus foncées:</strong> Valeurs plus élevées (confusions fréquentes)',
      confusionMatrixExample: '<strong>Exemple:</strong><br>S\'il y a une valeur élevée dans la ligne "Main" et la colonne "Poing", cela signifie que le modèle classe fréquemment "Main" comme "Poing" de manière incorrecte.',
      confusionMatrixPerfect: '<strong>Modèle parfait:</strong><br>Dans un modèle parfait, seules les valeurs diagonales seraient remplies (toutes les prédictions sont correctes), tandis que toutes les autres cellules seraient à 0.',
      confusionMatrixImprovement: '<strong>Conseils d\'amélioration pour les confusions fréquentes:</strong><br>• Ajoutez plus d\'images d\'entraînement distinctives pour les classes confondues<br>• Assurez-vous que les classes sont visuellement clairement distinguables<br>• Envisagez de fusionner des classes très similaires',
      predicted: 'Prédit',
      actual: 'Réel',
      chartAccuracyLossTitle: 'Précision et perte par époque',
      chartAccuracyLabel: 'Précision',
      chartLossLabel: 'Perte',
      chartEpochLabel: 'Époque',
      chartClassAccuracyTitle: 'Précision par classe',
      chartClassAccuracyLabel: 'Précision de classe'
    },
    helpTexts: {
      text1: 'Nommez une classe et enregistrez le nom. Ensuite, vous pouvez ajouter des images à cette classe.',
      text2: 'Toutes les classes ont besoin d\'images. Plus une classe a d\'images, mieux cette classe peut être reconnue. Il devrait y avoir au moins 60 images par classe!',
      text3: 'Au moins trois classes avec des images doivent être créées pour entraîner le modèle!'
    },
    aiInfo: {
      title: 'Informations IA',
      section1Title: 'Vous travaillez avec un système d\'IA',
      section1Text: 'La Calliope Teachable Machine utilise l\'intelligence artificielle (IA) pour apprendre de vos images d\'exemple. Cela signifie: Vous entraînez un modèle qui reconnaît de manière autonome des motifs dans les images – par exemple, différents gestes de la main ou couleurs.',
      section2Title: 'Comment fonctionne le système',
      section2Text1: 'Le modèle est basé sur une technique appelée "Transfer Learning". Nous utilisons un réseau neuronal pré-entraîné (MobileNet) qui connaît déjà de nombreuses caractéristiques d\'image. Vos images d\'exemple sont utilisées pour adapter ces connaissances à votre tâche spécifique – comme la distinction de vos propres gestes.',
      section2Text2: 'Tous les calculs et l\'entraînement ont lieu directement dans votre navigateur. Aucune donnée n\'est transférée aux serveurs – tout reste local sur votre appareil.',
      section3Title: 'Vos données restent avec vous',
      section3Text: 'Toutes les images que vous capturez avec la webcam sont traitées exclusivement localement. Elles ne quittent jamais votre ordinateur. Le modèle entraîné est également stocké uniquement sur votre appareil.',
      section4Title: 'Limites et restrictions',
      section4Text1: 'Votre modèle entraîné n\'est aussi bon que vos données d\'entraînement. Par exemple, si vous ne capturez des images qu\'à la lumière du jour, le modèle peut ne pas fonctionner de manière fiable dans de mauvaises conditions d\'éclairage. Plus vos exemples sont variés, plus le modèle sera robuste.',
      section4Text2: 'Le système est destiné aux <strong>projets d\'apprentissage et expérimentaux</strong>. Il ne convient pas aux applications critiques pour la sécurité ou aux décisions qui pourraient affecter les personnes.',
      section5Title: 'Équité et responsabilité',
      section5Text: 'Vous décidez quelles images utiliser pour l\'entraînement. Assurez-vous que vos données d\'entraînement sont équilibrées et ne reflètent pas de préjugés. Par exemple, si vous ne capturez que des images d\'une seule personne, le modèle peut moins bien fonctionner avec d\'autres personnes.',
      section6Title: 'À quoi sert ce système?',
      section6Text: 'La Teachable Machine est parfaite pour les projets créatifs, les projets scolaires et l\'apprentissage ludique. Vous pouvez:',
      section6List: [
        'Reconnaître les gestes de la main pour contrôler votre Calliope mini',
        'Distinguer les couleurs ou les objets',
        'Comprendre comment fonctionne l\'apprentissage automatique',
        'Développer vos propres projets interactifs'
      ],
      section7Title: 'Informations complémentaires',
      section7Text: 'Cet outil suit les exigences de transparence du règlement européen sur l\'IA (UE) 2024/1689. Vous avez toujours le contrôle sur vos données et modèles. Si vous avez des questions sur son fonctionnement, vous pouvez consulter les "Détails du modèle" après l\'entraînement – vous y trouverez des informations techniques sur les performances de votre modèle.'
    }
  },
  es: {
    welcome: {
      title: 'Bienvenido a <br>Calliope <span>Teachable Machine</span>',
      subtitle: 'Controla tu Calliope mini con gestos o colores.',
      start: 'Comenzar',
      aiInfo: 'Información de IA',
      languages: 'Idiomas',
      selectLanguage: 'Seleccionar idioma'
    },
    header: {
      training: 'Entrenamiento',
      tryout: 'Programar',
      apply: 'Aplicar'
    },
    training: {
      model: 'Modelo:',
      save: 'Guardar',
      load: 'Cargar',
      newClass: 'Nueva clase:',
      newClassPlaceholder: 'p. ej. Mano',
      addClass: '+',
      classes: 'Clases:',
      clickToSelect: 'Haz clic para seleccionar',
      downloadAll: 'Descargar todo',
      activeClass: 'Clase activa:',
      startCapture: 'Iniciar captura',
      stopCapture: 'Detener captura',
      files: 'Archivos',
      clear: 'Limpiar',
      deleteClass: 'Eliminar clase',
      confirmDeleteClass: '¿Realmente eliminar la clase?',
      downloadImages: 'Descargar imágenes',
      captureHint: 'Mantén presionado el botón para capturar imágenes (10 imágenes/segundo)',
      imagesCount: 'imágenes',
      training: 'Entrenamiento:',
      train: 'Entrenar modelo',
      trainStatus: 'Listo',
      modelDetails: 'Detalles del modelo',
      downloadProject: 'Descargar proyecto',
      downloadProjectBtn: 'Para Calliope mini',
      importProject: 'Importar proyecto',
      status: 'Cargando…',
      testStatus: 'Listo para probar',
      testButton: 'Probar',
      testHint: 'Haz clic para iniciar/detener la predicción en tiempo real'
    },
    status: {
      processingImages: 'Procesando imágenes...',
      trainingFailed: 'Entrenamiento fallido',
      training: 'Entrenando...',
      trainingComplete: '¡Listo - el modelo ya puede usarse!',
      modelReadyTest: 'Modelo listo para probar',
      modelReadyTryout: 'Modelo listo para usar',
      pleaseTrainModel: 'Por favor entrena el modelo',
      minTwoClasses: 'Se necesitan al menos dos clases',
      trainingError: 'Error de entrenamiento',
      projectLoaded: 'Proyecto cargado',
      modelLoaded: 'Modelo',
      selectClassFirst: 'Por favor selecciona primero una clase',
      epoch: 'Época',
      val: 'Val',
      uncertain: 'Incierto'
    },
    tryout: {
      loadModelTitle: 'Cargar modelo',
      trainedModel: 'Modelo entrenado:',
      uploadModel: 'Subir modelo',
      ready: 'Listo para probar',
      start: 'Iniciar',
      stop: 'Detener',
      hint: 'Haz clic en Iniciar para iniciar/detener la predicción en tiempo real',
      calliopeConnection: 'Conexión Calliope mini',
      notConnected: 'No conectado',
      connected: 'Conectado',
      connect: 'Conectar',
      disconnect: 'Desconectar',
      disconnected: 'Desconectado',
      readyToConnect: 'Listo para conectar',
      sendEveryPrediction: 'Enviar cada clase continuamente (desde 70% de probabilidad)'
    },
    dialogs: {
      importTitle: 'Importar imágenes',
      importMessage: 'Selecciona una clase para las imágenes importadas:',
      cancel: 'Cancelar',
      import: 'Importar',
      modelDetailsTitle: 'Detalles del modelo',
      overviewTab: 'Resumen',
      accuracyTab: 'Precisión',
      confusionTab: 'Matriz de confusión'
    },
    modelDetails: {
      overallAccuracy: 'Precisión global',
      totalLoss: 'Pérdida total',
      trainingEpochs: 'Épocas de entrenamiento',
      trainingData: 'Datos de entrenamiento',
      overviewTitle: 'Resumen del modelo',
      overviewTerms: 'Explicación de términos: Un "modelo" es la red neuronal entrenada que ha aprendido a reconocer las clases definidas. La "precisión" describe con qué frecuencia el modelo es correcto, mientras que la "pérdida" indica qué tan lejos están las predicciones del resultado correcto. Las "épocas" son rondas de entrenamiento en las que el modelo pasa por todos los datos de entrenamiento una vez.',
      overviewIntro: 'Este resumen muestra métricas importantes del modelo entrenado. Las estadísticas proporcionan una visión rápida del rendimiento, mientras que el gráfico visualiza el desarrollo de la precisión y la pérdida a lo largo de las épocas de entrenamiento.',
      overviewValidation: '<strong>Importante:</strong> La precisión se mide en un 20% de datos de validación que no se utilizaron para el entrenamiento. Esto da una impresión realista de qué tan bien funciona el modelo con datos nuevos y desconocidos.',
      accuracyValues: '<strong>Valores de precisión:</strong><br><span class="value-guideline value-excellent">>90%</span> Excelente - Modelo muy confiable<br><span class="value-guideline value-good">70-90%</span> Bueno - Modelo adecuado para la mayoría de los casos de uso<br><span class="value-guideline value-needs-improvement"><70%</span> Necesita mejorar - Se necesitan más datos de entrenamiento o épocas',
      lossValues: '<strong>Valores de pérdida:</strong><br><span class="value-guideline value-excellent"><0.1</span> Muy bueno - El modelo aprende eficazmente<br><span class="value-guideline value-good">0.1-0.5</span> Bueno - Comportamiento de aprendizaje aceptable<br><span class="value-guideline value-needs-improvement">>0.5</span> Alto - El modelo no ha aprendido lo suficiente, se necesita más entrenamiento',
      epochsInfo: '<strong>Épocas de entrenamiento:</strong><br>Típicamente 10-50 épocas para conjuntos de datos pequeños. Si la precisión deja de aumentar después de 20 épocas, el modelo probablemente esté suficientemente entrenado.',
      dataInfo: '<strong>Datos de entrenamiento:</strong><br>El número mostrado corresponde a las imágenes capturadas. Mediante el aumento de datos (variaciones aleatorias como desplazamiento y escala), se crean 3 ejemplos de entrenamiento por imagen para mejorar la robustez del modelo.',
      accuracyPerClassTitle: 'Precisión por clase',
      accuracyPerClassTerms: 'Explicación de términos: Una "clase" es una categoría que se ha definido (p. ej., "Mano", "Cara", "Fondo"). La "precisión por clase" muestra con qué fiabilidad el modelo reconoce cada clase individual.',
      accuracyPerClassIntro: 'Este gráfico de barras muestra la precisión del modelo para cada clase individual. Ayuda a identificar con qué clases el modelo funciona bien y con cuáles tiene dificultades.',
      interpretationTitle: '<strong>Interpretación de valores:</strong><br><span class="value-guideline value-excellent">>90%</span> Excelente - La clase se reconoce muy confiablemente<br><span class="value-guideline value-good">70-90%</span> Bueno - La clase se reconoce mayormente correctamente<br><span class="value-guideline value-needs-improvement"><70%</span> Problemático - La clase necesita más o mejores datos de entrenamiento',
      lowAccuracyCauses: '<strong>Posibles causas de baja precisión:</strong><br>• Muy pocas imágenes de entrenamiento para esta clase<br>• Las imágenes son demasiado similares a otras clases<br>• Malas condiciones de iluminación o imágenes borrosas<br>• La clase tiene demasiadas variaciones (p. ej., "objetos diferentes")',
      improvementTips: '<strong>Consejos de mejora:</strong><br>• Agrega al menos 40-50 imágenes por clase<br>• Asegúrate de que las imágenes sean consistentes<br>• Evita objetos similares en diferentes clases',
      confusionMatrixTitle: 'Matriz de confusión',
      confusionMatrixTerms: 'Explicación de términos: La "matriz de confusión" es una tabla que muestra qué clases confunde el modelo entre sí. Ayuda a identificar si el modelo clasifica sistemáticamente ciertas clases de manera incorrecta.',
      confusionMatrixIntro: 'La matriz de confusión visualiza el rendimiento del modelo mostrando qué clases se confunden entre sí. Las filas representan las clases reales, mientras que las columnas representan las clases predichas por el modelo.',
      confusionMatrixReading: '<strong>Cómo leer la matriz:</strong><br>• <strong>Diagonal (verde oscuro):</strong> Predicciones correctas - los valores más altos deberían estar aquí<br>• <strong>Fuera de la diagonal:</strong> Errores - el modelo confundió una clase con otra<br>• <strong>Celdas más claras:</strong> Valores bajos (pocas o ninguna confusión)<br>• <strong>Celdas más oscuras:</strong> Valores más altos (confusiones frecuentes)',
      confusionMatrixExample: '<strong>Ejemplo:</strong><br>Si hay un valor alto en la fila "Mano" y la columna "Puño", esto significa que el modelo frecuentemente clasifica incorrectamente "Mano" como "Puño".',
      confusionMatrixPerfect: '<strong>Modelo perfecto:</strong><br>En un modelo perfecto, solo los valores diagonales estarían llenos (todas las predicciones son correctas), mientras que todas las demás celdas serían 0.',
      confusionMatrixImprovement: '<strong>Consejos de mejora para confusiones frecuentes:</strong><br>• Agrega más imágenes de entrenamiento distintivas para las clases confundidas<br>• Asegúrate de que las clases sean visualmente claramente distinguibles<br>• Considera fusionar clases muy similares',
      predicted: 'Predicho',
      actual: 'Real',
      chartAccuracyLossTitle: 'Precisión y pérdida por época',
      chartAccuracyLabel: 'Precisión',
      chartLossLabel: 'Pérdida',
      chartEpochLabel: 'Época',
      chartClassAccuracyTitle: 'Precisión por clase',
      chartClassAccuracyLabel: 'Precisión de clase'
    },
    helpTexts: {
      text1: 'Nombra una clase y guarda el nombre. Luego puedes agregar imágenes a esta clase.',
      text2: 'Todas las clases necesitan imágenes. Cuantas más imágenes tenga una clase, mejor se puede reconocer esa clase. ¡Debería haber al menos 60 imágenes por clase!',
      text3: '¡Se deben crear al menos tres clases con imágenes para entrenar el modelo!'
    },
    aiInfo: {
      title: 'Información de IA',
      section1Title: 'Estás trabajando con un sistema de IA',
      section1Text: 'La Calliope Teachable Machine utiliza inteligencia artificial (IA) para aprender de tus imágenes de muestra. Esto significa: Entrenas un modelo que reconoce de forma independiente patrones en imágenes, por ejemplo, diferentes gestos de manos o colores.',
      section2Title: 'Cómo funciona el sistema',
      section2Text1: 'El modelo se basa en una técnica llamada "Transfer Learning". Utilizamos una red neuronal preentrenada (MobileNet) que ya conoce muchas características de imagen. Tus imágenes de muestra se utilizan para adaptar este conocimiento a tu tarea específica, como distinguir tus propios gestos.',
      section2Text2: 'Todos los cálculos y el entrenamiento se realizan directamente en tu navegador. No se transfieren datos a servidores: todo permanece local en tu dispositivo.',
      section3Title: 'Tus datos permanecen contigo',
      section3Text: 'Todas las imágenes que captures con la webcam se procesan exclusivamente de forma local. Nunca abandonan tu ordenador. El modelo entrenado también se almacena solo en tu dispositivo.',
      section4Title: 'Límites y restricciones',
      section4Text1: 'Tu modelo entrenado es tan bueno como tus datos de entrenamiento. Por ejemplo, si solo capturas imágenes a la luz del día, es posible que el modelo no funcione de manera confiable en condiciones de poca luz. Cuanto más diversos sean tus ejemplos, más robusto será el modelo.',
      section4Text2: 'El sistema está destinado a <strong>proyectos de aprendizaje y experimentales</strong>. No es adecuado para aplicaciones críticas de seguridad o decisiones que puedan afectar a las personas.',
      section5Title: 'Equidad y responsabilidad',
      section5Text: 'Tú decides qué imágenes usar para el entrenamiento. Asegúrate de que tus datos de entrenamiento estén equilibrados y no reflejen prejuicios. Por ejemplo, si solo capturas imágenes de una persona, el modelo puede funcionar peor con otras personas.',
      section6Title: '¿Para qué es adecuado este sistema?',
      section6Text: 'La Teachable Machine es perfecta para proyectos creativos, proyectos escolares y aprendizaje lúdico. Puedes:',
      section6List: [
        'Reconocer gestos de manos para controlar tu Calliope mini',
        'Distinguir colores u objetos',
        'Comprender cómo funciona el aprendizaje automático',
        'Desarrollar tus propios proyectos interactivos'
      ],
      section7Title: 'Más información',
      section7Text: 'Esta herramienta sigue los requisitos de transparencia del Reglamento de IA de la UE (UE) 2024/1689. Siempre tienes el control sobre tus datos y modelos. Si tienes preguntas sobre cómo funciona, puedes ver los "Detalles del modelo" después del entrenamiento: allí encontrarás información técnica sobre el rendimiento de tu modelo.'
    }
  },
  it: {
    welcome: {
      title: 'Benvenuto a <br>Calliope <span>Teachable Machine</span>',
      subtitle: 'Controlla il tuo Calliope mini con gesti o colori.',
      start: 'Inizia',
      aiInfo: 'Informazioni IA',
      languages: 'Lingue',
      selectLanguage: 'Seleziona lingua'
    },
    header: {
      training: 'Addestramento',
      tryout: 'Programmare',
      apply: 'Applicare'
    },
    training: {
      model: 'Modello:',
      save: 'Salva',
      load: 'Carica',
      newClass: 'Nuova classe:',
      newClassPlaceholder: 'es. Mano',
      addClass: '+',
      classes: 'Classi:',
      clickToSelect: 'Clicca per selezionare',
      downloadAll: 'Scarica tutto',
      activeClass: 'Classe attiva:',
      startCapture: 'Avvia acquisizione',
      stopCapture: 'Ferma acquisizione',
      files: 'File',
      clear: 'Cancella',
      deleteClass: 'Elimina classe',
      confirmDeleteClass: 'Eliminare davvero la classe?',
      downloadImages: 'Scarica immagini',
      captureHint: 'Tieni premuto il pulsante per acquisire immagini (10 immagini/secondo)',
      imagesCount: 'immagini',
      training: 'Addestramento:',
      train: 'Addestra modello',
      trainStatus: 'Pronto',
      modelDetails: 'Dettagli modello',
      downloadProject: 'Scarica progetto',
      downloadProjectBtn: 'Per Calliope mini',
      importProject: 'Importa progetto',
      status: 'Caricamento…',
      testStatus: 'Pronto per il test',
      testButton: 'Testa',
      testHint: 'Clicca per avviare/fermare la predizione in tempo reale'
    },
    status: {
      processingImages: 'Elaborazione immagini...',
      trainingFailed: 'Addestramento fallito',
      training: 'Addestramento...',
      trainingComplete: 'Fatto - il modello può ora essere utilizzato!',
      modelReadyTest: 'Modello pronto per il test',
      modelReadyTryout: 'Modello pronto per provare',
      pleaseTrainModel: 'Si prega di addestrare il modello',
      minTwoClasses: 'Sono necessarie almeno due classi',
      trainingError: 'Errore di addestramento',
      projectLoaded: 'Progetto caricato',
      modelLoaded: 'Modello',
      selectClassFirst: 'Si prega di selezionare prima una classe',
      epoch: 'Epoca',
      val: 'Val',
      uncertain: 'Incerto'
    },
    tryout: {
      loadModelTitle: 'Carica modello',
      trainedModel: 'Modello addestrato:',
      uploadModel: 'Carica modello',
      ready: 'Pronto per provare',
      start: 'Avvia',
      stop: 'Ferma',
      hint: 'Clicca su Avvia per avviare/fermare la predizione in tempo reale',
      calliopeConnection: 'Connessione Calliope mini',
      notConnected: 'Non connesso',
      connected: 'Connesso',
      connect: 'Connetti',
      disconnect: 'Disconnetti',
      disconnected: 'Disconnesso',
      readyToConnect: 'Pronto per connettersi',
      sendEveryPrediction: 'Invia ogni classe continuamente (dal 70% di probabilità)'
    },
    dialogs: {
      importTitle: 'Importa immagini',
      importMessage: 'Seleziona una classe per le immagini importate:',
      cancel: 'Annulla',
      import: 'Importa',
      modelDetailsTitle: 'Dettagli modello',
      overviewTab: 'Panoramica',
      accuracyTab: 'Precisione',
      confusionTab: 'Matrice di confusione'
    },
    modelDetails: {
      overallAccuracy: 'Precisione complessiva',
      totalLoss: 'Perdita totale',
      trainingEpochs: 'Epoche di addestramento',
      trainingData: 'Dati di addestramento',
      overviewTitle: 'Panoramica del modello',
      overviewTerms: 'Spiegazione dei termini: Un "modello" è la rete neurale addestrata che ha imparato a riconoscere le classi definite. La "precisione" descrive quanto spesso il modello è corretto, mentre la "perdita" indica quanto le previsioni sono lontane dal risultato corretto. Le "epoche" sono round di addestramento in cui il modello passa attraverso tutti i dati di addestramento una volta.',
      overviewIntro: 'Questa panoramica mostra metriche importanti del modello addestrato. Le statistiche forniscono una visione rapida delle prestazioni, mentre il grafico visualizza lo sviluppo di precisione e perdita durante le epoche di addestramento.',
      overviewValidation: '<strong>Importante:</strong> La precisione è misurata sul 20% dei dati di validazione che non sono stati utilizzati per l\'addestramento. Questo dà un\'impressione realistica di quanto bene il modello funziona su dati nuovi e sconosciuti.',
      accuracyValues: '<strong>Valori di precisione:</strong><br><span class="value-guideline value-excellent">>90%</span> Eccellente - Modello molto affidabile<br><span class="value-guideline value-good">70-90%</span> Buono - Modello adatto per la maggior parte dei casi d\'uso<br><span class="value-guideline value-needs-improvement"><70%</span> Necessita miglioramenti - Più dati di addestramento o epoche necessari',
      lossValues: '<strong>Valori di perdita:</strong><br><span class="value-guideline value-excellent"><0.1</span> Molto buono - Il modello impara efficacemente<br><span class="value-guideline value-good">0.1-0.5</span> Buono - Comportamento di apprendimento accettabile<br><span class="value-guideline value-needs-improvement">>0.5</span> Alto - Il modello non ha imparato abbastanza, più addestramento necessario',
      epochsInfo: '<strong>Epoche di addestramento:</strong><br>Tipicamente 10-50 epoche per piccoli dataset. Se la precisione smette di aumentare dopo 20 epoche, il modello è probabilmente sufficientemente addestrato.',
      dataInfo: '<strong>Dati di addestramento:</strong><br>Il numero visualizzato corrisponde alle immagini acquisite. Attraverso l\'aumento dei dati (variazioni casuali come spostamento e scala), vengono creati 3 esempi di addestramento per immagine per migliorare la robustezza del modello.',
      accuracyPerClassTitle: 'Precisione per classe',
      accuracyPerClassTerms: 'Spiegazione dei termini: Una "classe" è una categoria che è stata definita (es. "Mano", "Viso", "Sfondo"). La "precisione per classe" mostra quanto affidabilmente il modello riconosce ogni singola classe.',
      accuracyPerClassIntro: 'Questo grafico a barre mostra la precisione del modello per ogni singola classe. Aiuta a identificare con quali classi il modello funziona bene e con quali ha difficoltà.',
      interpretationTitle: '<strong>Interpretazione dei valori:</strong><br><span class="value-guideline value-excellent">>90%</span> Eccellente - La classe è riconosciuta molto affidabilmente<br><span class="value-guideline value-good">70-90%</span> Buono - La classe è riconosciuta per lo più correttamente<br><span class="value-guideline value-needs-improvement"><70%</span> Problematico - La classe necessita di più o migliori dati di addestramento',
      lowAccuracyCauses: '<strong>Possibili cause di bassa precisione:</strong><br>• Troppo poche immagini di addestramento per questa classe<br>• Le immagini sono troppo simili ad altre classi<br>• Cattive condizioni di illuminazione o immagini sfocate<br>• La classe ha troppe variazioni (es. "oggetti diversi")',
      improvementTips: '<strong>Suggerimenti per il miglioramento:</strong><br>• Aggiungi almeno 40-50 immagini per classe<br>• Assicurati che le immagini siano coerenti<br>• Evita oggetti simili in classi diverse',
      confusionMatrixTitle: 'Matrice di confusione',
      confusionMatrixTerms: 'Spiegazione dei termini: La "matrice di confusione" è una tabella che mostra quali classi il modello confonde tra loro. Aiuta a identificare se il modello classifica sistematicamente certe classi in modo errato.',
      confusionMatrixIntro: 'La matrice di confusione visualizza le prestazioni del modello mostrando quali classi vengono confuse tra loro. Le righe rappresentano le classi reali, mentre le colonne rappresentano le classi previste dal modello.',
      confusionMatrixReading: '<strong>Come leggere la matrice:</strong><br>• <strong>Diagonale (verde scuro):</strong> Previsioni corrette - i valori più alti dovrebbero essere qui<br>• <strong>Fuori dalla diagonale:</strong> Errori - il modello ha confuso una classe con un\'altra<br>• <strong>Celle più chiare:</strong> Valori bassi (poche o nessuna confusione)<br>• <strong>Celle più scure:</strong> Valori più alti (confusioni frequenti)',
      confusionMatrixExample: '<strong>Esempio:</strong><br>Se c\'è un valore alto nella riga "Mano" e nella colonna "Pugno", questo significa che il modello classifica frequentemente "Mano" come "Pugno" in modo errato.',
      confusionMatrixPerfect: '<strong>Modello perfetto:</strong><br>In un modello perfetto, solo i valori diagonali sarebbero riempiti (tutte le previsioni sono corrette), mentre tutte le altre celle sarebbero 0.',
      confusionMatrixImprovement: '<strong>Suggerimenti per il miglioramento per confusioni frequenti:</strong><br>• Aggiungi più immagini di addestramento distintive per le classi confuse<br>• Assicurati che le classi siano visivamente chiaramente distinguibili<br>• Considera di unire classi molto simili',
      predicted: 'Previsto',
      actual: 'Reale',
      chartAccuracyLossTitle: 'Precisione e perdita per epoca',
      chartAccuracyLabel: 'Precisione',
      chartLossLabel: 'Perdita',
      chartEpochLabel: 'Epoca',
      chartClassAccuracyTitle: 'Precisione per classe',
      chartClassAccuracyLabel: 'Precisione di classe'
    },
    helpTexts: {
      text1: 'Nomina una classe e salva il nome. Quindi puoi aggiungere immagini a questa classe.',
      text2: 'Tutte le classi hanno bisogno di immagini. Più immagini ha una classe, meglio quella classe può essere riconosciuta. Dovrebbero esserci almeno 60 immagini per classe!',
      text3: 'Devono essere create almeno tre classi con immagini per addestrare il modello!'
    },
    aiInfo: {
      title: 'Informazioni IA',
      section1Title: 'Stai lavorando con un sistema di IA',
      section1Text: 'La Calliope Teachable Machine utilizza l\'intelligenza artificiale (IA) per imparare dalle tue immagini di esempio. Ciò significa: addestri un modello che riconosce in modo indipendente i modelli nelle immagini, ad esempio diversi gesti delle mani o colori.',
      section2Title: 'Come funziona il sistema',
      section2Text1: 'Il modello si basa su una tecnica chiamata "Transfer Learning". Utilizziamo una rete neurale preaddestrata (MobileNet) che conosce già molte caratteristiche dell\'immagine. Le tue immagini di esempio vengono utilizzate per adattare questa conoscenza al tuo compito specifico, come distinguere i tuoi gesti.',
      section2Text2: 'Tutti i calcoli e l\'addestramento avvengono direttamente nel tuo browser. Nessun dato viene trasferito ai server: tutto rimane locale sul tuo dispositivo.',
      section3Title: 'I tuoi dati rimangono con te',
      section3Text: 'Tutte le immagini che acquisisci con la webcam vengono elaborate esclusivamente localmente. Non lasciano mai il tuo computer. Il modello addestrato viene anche memorizzato solo sul tuo dispositivo.',
      section4Title: 'Limiti e restrizioni',
      section4Text1: 'Il tuo modello addestrato è buono quanto i tuoi dati di addestramento. Ad esempio, se acquisisci solo immagini alla luce del giorno, il modello potrebbe non funzionare in modo affidabile in condizioni di scarsa illuminazione. Più diversi sono i tuoi esempi, più robusto sarà il modello.',
      section4Text2: 'Il sistema è destinato a <strong>progetti di apprendimento e sperimentali</strong>. Non è adatto per applicazioni critiche per la sicurezza o decisioni che potrebbero influenzare le persone.',
      section5Title: 'Equità e responsabilità',
      section5Text: 'Decidi tu quali immagini utilizzare per l\'addestramento. Assicurati che i tuoi dati di addestramento siano equilibrati e non riflettano pregiudizi. Ad esempio, se acquisisci solo immagini di una persona, il modello potrebbe funzionare peggio con altre persone.',
      section6Title: 'Per cosa è adatto questo sistema?',
      section6Text: 'La Teachable Machine è perfetta per progetti creativi, progetti scolastici e apprendimento ludico. Puoi:',
      section6List: [
        'Riconoscere i gesti delle mani per controllare il tuo Calliope mini',
        'Distinguere colori o oggetti',
        'Comprendere come funziona l\'apprendimento automatico',
        'Sviluppare i tuoi progetti interattivi'
      ],
      section7Title: 'Ulteriori informazioni',
      section7Text: 'Questo strumento segue i requisiti di trasparenza del Regolamento UE sull\'IA (UE) 2024/1689. Hai sempre il controllo sui tuoi dati e modelli. Se hai domande su come funziona, puoi visualizzare i "Dettagli del modello" dopo l\'addestramento: lì troverai informazioni tecniche sulle prestazioni del tuo modello.'
    }
  },
  el: {
    welcome: {
      title: 'Καλώς ήρθατε στο <br>Calliope <span>Teachable Machine</span>',
      subtitle: 'Ελέγξτε το Calliope mini σας με χειρονομίες ή χρώματα.',
      start: 'Έναρξη',
      aiInfo: 'Πληροφορίες AI',
      languages: 'Γλώσσες',
      selectLanguage: 'Επιλέξτε γλώσσα'
    },
    header: {
      training: 'Εκπαίδευση',
      tryout: 'Προγραμματισμός',
      apply: 'Εφαρμογή'
    },
    training: {
      model: 'Μοντέλο:',
      save: 'Αποθήκευση',
      load: 'Φόρτωση',
      newClass: 'Νέα κλάση:',
      newClassPlaceholder: 'π.χ. Χέρι',
      addClass: '+',
      classes: 'Κλάσεις:',
      clickToSelect: 'Κάντε κλικ για επιλογή',
      downloadAll: 'Λήψη όλων',
      activeClass: 'Ενεργή κλάση:',
      startCapture: 'Έναρξη λήψης',
      stopCapture: 'Διακοπή λήψης',
      files: 'Αρχεία',
      clear: 'Καθαρισμός',
      deleteClass: 'Διαγραφή κλάσης',
      confirmDeleteClass: 'Να διαγραφεί πραγματικά η κλάση;',
      downloadImages: 'Λήψη εικόνων',
      captureHint: 'Κρατήστε πατημένο το κουμπί για λήψη εικόνων (10 εικόνες/δευτερόλεπτο)',
      imagesCount: 'εικόνες',
      training: 'Εκπαίδευση:',
      train: 'Εκπαίδευση μοντέλου',
      trainStatus: 'Έτοιμο',
      modelDetails: 'Λεπτομέρειες μοντέλου',
      downloadProject: 'Λήψη έργου',
      downloadProjectBtn: 'Για Calliope mini',
      importProject: 'Εισαγωγή έργου',
      status: 'Φόρτωση…',
      testStatus: 'Έτοιμο για δοκιμή',
      testButton: 'Δοκιμή',
      testHint: 'Κάντε κλικ για έναρξη/διακοπή της πρόβλεψης σε πραγματικό χρόνο'
    },
    status: {
      processingImages: 'Επεξεργασία εικόνων...',
      trainingFailed: 'Η εκπαίδευση απέτυχε',
      training: 'Εκπαίδευση...',
      trainingComplete: 'Ολοκληρώθηκε - το μοντέλο μπορεί τώρα να χρησιμοποιηθεί!',
      modelReadyTest: 'Μοντέλο έτοιμο για δοκιμή',
      modelReadyTryout: 'Μοντέλο έτοιμο για χρήση',
      pleaseTrainModel: 'Παρακαλώ εκπαιδεύστε το μοντέλο',
      minTwoClasses: 'Απαιτούνται τουλάχιστον δύο κλάσεις',
      trainingError: 'Σφάλμα εκπαίδευσης',
      projectLoaded: 'Έργο φορτώθηκε',
      modelLoaded: 'Μοντέλο',
      selectClassFirst: 'Παρακαλώ επιλέξτε πρώτα μια κλάση',
      epoch: 'Εποχή',
      val: 'Επικύρωση',
      uncertain: 'Αβέβαιο'
    },
    tryout: {
      loadModelTitle: 'Φόρτωση μοντέλου',
      trainedModel: 'Εκπαιδευμένο μοντέλο:',
      uploadModel: 'Ανέβασμα μοντέλου',
      ready: 'Έτοιμο για δοκιμή',
      start: 'Έναρξη',
      stop: 'Διακοπή',
      hint: 'Κάντε κλικ στην Έναρξη για έναρξη/διακοπή της πρόβλεψης σε πραγματικό χρόνο',
      calliopeConnection: 'Σύνδεση Calliope mini',
      notConnected: 'Μη συνδεδεμένο',
      connected: 'Συνδεδεμένο',
      connect: 'Σύνδεση',
      disconnect: 'Αποσύνδεση',
      disconnected: 'Αποσυνδέθηκε',
      readyToConnect: 'Έτοιμο για σύνδεση',
      sendEveryPrediction: 'Αποστολή κάθε κλάσης συνεχώς (από 70% πιθανότητα)'
    },
    dialogs: {
      importTitle: 'Εισαγωγή εικόνων',
      importMessage: 'Επιλέξτε μια κλάση για τις εισαγόμενες εικόνες:',
      cancel: 'Ακύρωση',
      import: 'Εισαγωγή',
      modelDetailsTitle: 'Λεπτομέρειες μοντέλου',
      overviewTab: 'Επισκόπηση',
      accuracyTab: 'Ακρίβεια',
      confusionTab: 'Πίνακας σύγχυσης'
    },
    modelDetails: {
      overallAccuracy: 'Συνολική ακρίβεια',
      totalLoss: 'Συνολική απώλεια',
      trainingEpochs: 'Εποχές εκπαίδευσης',
      trainingData: 'Δεδομένα εκπαίδευσης',
      overviewTitle: 'Επισκόπηση μοντέλου',
      overviewTerms: 'Επεξήγηση όρων: Ένα "μοντέλο" είναι το εκπαιδευμένο νευρωνικό δίκτυο που έχει μάθει να αναγνωρίζει τις καθορισμένες κλάσεις. Η "ακρίβεια" περιγράφει πόσο συχνά το μοντέλο είναι σωστό, ενώ η "απώλεια" υποδεικνύει πόσο μακριά είναι οι προβλέψεις από το σωστό αποτέλεσμα. Οι "εποχές" είναι γύροι εκπαίδευσης στους οποίους το μοντέλο διέρχεται από όλα τα δεδομένα εκπαίδευσης μία φορά.',
      overviewIntro: 'Αυτή η επισκόπηση δείχνει σημαντικές μετρήσεις του εκπαιδευμένου μοντέλου. Τα στατιστικά παρέχουν μια γρήγορη ματιά στην απόδοση, ενώ το γράφημα απεικονίζει την εξέλιξη της ακρίβειας και της απώλειας κατά τη διάρκεια των εποχών εκπαίδευσης.',
      overviewValidation: '<strong>Σημαντικό:</strong> Η ακρίβεια μετράται σε 20% δεδομένα επικύρωσης που δεν χρησιμοποιήθηκαν για εκπαίδευση. Αυτό δίνει μια ρεαλιστική εντύπωση για το πόσο καλά λειτουργεί το μοντέλο σε νέα, άγνωστα δεδομένα.',
      accuracyValues: '<strong>Τιμές ακρίβειας:</strong><br><span class="value-guideline value-excellent">>90%</span> Εξαιρετικό - Μοντέλο πολύ αξιόπιστο<br><span class="value-guideline value-good">70-90%</span> Καλό - Μοντέλο κατάλληλο για τις περισσότερες περιπτώσεις χρήσης<br><span class="value-guideline value-needs-improvement"><70%</span> Χρειάζεται βελτίωση - Περισσότερα δεδομένα εκπαίδευσης ή εποχές απαιτούνται',
      lossValues: '<strong>Τιμές απώλειας:</strong><br><span class="value-guideline value-excellent"><0.1</span> Πολύ καλό - Το μοντέλο μαθαίνει αποτελεσματικά<br><span class="value-guideline value-good">0.1-0.5</span> Καλό - Αποδεκτή συμπεριφορά μάθησης<br><span class="value-guideline value-needs-improvement">>0.5</span> Υψηλό - Το μοντέλο δεν έχει μάθει αρκετά, χρειάζεται περισσότερη εκπαίδευση',
      epochsInfo: '<strong>Εποχές εκπαίδευσης:</strong><br>Συνήθως 10-50 εποχές για μικρά σύνολα δεδομένων. Εάν η ακρίβεια σταματήσει να αυξάνεται μετά από 20 εποχές, το μοντέλο είναι πιθανώς επαρκώς εκπαιδευμένο.',
      dataInfo: '<strong>Δεδομένα εκπαίδευσης:</strong><br>Ο αριθμός που εμφανίζεται αντιστοιχεί στις ληφθείσες εικόνες. Μέσω της αύξησης δεδομένων (τυχαίες παραλλαγές όπως μετατόπιση και κλίμακα), δημιουργούνται 3 παραδείγματα εκπαίδευσης ανά εικόνα για τη βελτίωση της ευρωστίας του μοντέλου.',
      accuracyPerClassTitle: 'Ακρίβεια ανά κλάση',
      accuracyPerClassTerms: 'Επεξήγηση όρων: Μια "κλάση" είναι μια κατηγορία που έχει οριστεί (π.χ. "Χέρι", "Πρόσωπο", "Φόντο"). Η "ακρίβεια ανά κλάση" δείχνει πόσο αξιόπιστα το μοντέλο αναγνωρίζει κάθε μεμονωμένη κλάση.',
      accuracyPerClassIntro: 'Αυτό το γράφημα ράβδων δείχνει την ακρίβεια του μοντέλου για κάθε μεμονωμένη κλάση. Βοηθά να εντοπιστούν με ποιες κλάσεις το μοντέλο λειτουργεί καλά και με ποιες έχει δυσκολίες.',
      interpretationTitle: '<strong>Ερμηνεία τιμών:</strong><br><span class="value-guideline value-excellent">>90%</span> Εξαιρετικό - Η κλάση αναγνωρίζεται πολύ αξιόπιστα<br><span class="value-guideline value-good">70-90%</span> Καλό - Η κλάση αναγνωρίζεται ως επί το πλείστον σωστά<br><span class="value-guideline value-needs-improvement"><70%</span> Προβληματικό - Η κλάση χρειάζεται περισσότερα ή καλύτερα δεδομένα εκπαίδευσης',
      lowAccuracyCauses: '<strong>Πιθανές αιτίες χαμηλής ακρίβειας:</strong><br>• Πολύ λίγες εικόνες εκπαίδευσης για αυτή την κλάση<br>• Οι εικόνες είναι πολύ παρόμοιες με άλλες κλάσεις<br>• Κακές συνθήκες φωτισμού ή θολές εικόνες<br>• Η κλάση έχει πάρα πολλές παραλλαγές (π.χ. "διαφορετικά αντικείμενα")',
      improvementTips: '<strong>Συμβουλές βελτίωσης:</strong><br>• Προσθέστε τουλάχιστον 40-50 εικόνες ανά κλάση<br>• Βεβαιωθείτε ότι οι εικόνες είναι συνεπείς<br>• Αποφύγετε παρόμοια αντικείμενα σε διαφορετικές κλάσεις',
      confusionMatrixTitle: 'Πίνακας σύγχυσης',
      confusionMatrixTerms: 'Επεξήγηση όρων: Ο "πίνακας σύγχυσης" είναι ένας πίνακας που δείχνει ποιες κλάσεις συγχέει το μοντέλο μεταξύ τους. Βοηθά να εντοπιστεί αν το μοντέλο ταξινομεί συστηματικά ορισμένες κλάσεις λανθασμένα.',
      confusionMatrixIntro: 'Ο πίνακας σύγχυσης απεικονίζει την απόδοση του μοντέλου δείχνοντας ποιες κλάσεις συγχέονται μεταξύ τους. Οι γραμμές αντιπροσωπεύουν τις πραγματικές κλάσεις, ενώ οι στήλες αντιπροσωπεύουν τις κλάσεις που προβλέπονται από το μοντέλο.',
      confusionMatrixReading: '<strong>Πώς να διαβάσετε τον πίνακα:</strong><br>• <strong>Διαγώνιος (σκούρο πράσινο):</strong> Σωστές προβλέψεις - οι υψηλότερες τιμές πρέπει να είναι εδώ<br>• <strong>Εκτός διαγωνίου:</strong> Λάθη - το μοντέλο συνέχισε μια κλάση με μια άλλη<br>• <strong>Ανοιχτόχρωμα κελιά:</strong> Χαμηλές τιμές (λίγες ή καμία σύγχυση)<br>• <strong>Σκουρόχρωμα κελιά:</strong> Υψηλότερες τιμές (συχνές συγχύσεις)',
      confusionMatrixExample: '<strong>Παράδειγμα:</strong><br>Εάν υπάρχει υψηλή τιμή στη γραμμή "Χέρι" και τη στήλη "Γροθιά", αυτό σημαίνει ότι το μοντέλο ταξινομεί συχνά λανθασμένα το "Χέρι" ως "Γροθιά".',
      confusionMatrixPerfect: '<strong>Τέλειο μοντέλο:</strong><br>Σε ένα τέλειο μοντέλο, μόνο οι διαγώνιες τιμές θα ήταν γεμάτες (όλες οι προβλέψεις είναι σωστές), ενώ όλα τα άλλα κελιά θα ήταν 0.',
      confusionMatrixImprovement: '<strong>Συμβουλές βελτίωσης για συχνές συγχύσεις:</strong><br>• Προσθέστε περισσότερες διακριτικές εικόνες εκπαίδευσης για τις συγχεόμενες κλάσεις<br>• Βεβαιωθείτε ότι οι κλάσεις είναι οπτικά σαφώς διακριτές<br>• Σκεφτείτε να συγχωνεύσετε πολύ παρόμοιες κλάσεις',
      predicted: 'Προβλεφθέν',
      actual: 'Πραγματικό',
      chartAccuracyLossTitle: 'Ακρίβεια και απώλεια ανά εποχή',
      chartAccuracyLabel: 'Ακρίβεια',
      chartLossLabel: 'Απώλεια',
      chartEpochLabel: 'Εποχή',
      chartClassAccuracyTitle: 'Ακρίβεια ανά κλάση',
      chartClassAccuracyLabel: 'Ακρίβεια κλάσης'
    },
    helpTexts: {
      text1: 'Ονομάστε μια κλάση και αποθηκεύστε το όνομα. Στη συνέχεια, μπορείτε να προσθέσετε εικόνες σε αυτήν την κλάση.',
      text2: 'Όλες οι κλάσεις χρειάζονται εικόνες. Όσο περισσότερες εικόνες έχει μια κλάση, τόσο καλύτερα μπορεί να αναγνωριστεί αυτή η κλάση. Πρέπει να υπάρχουν τουλάχιστον 60 εικόνες ανά κλάση!',
      text3: 'Πρέπει να δημιουργηθούν τουλάχιστον τρεις κλάσεις με εικόνες για την εκπαίδευση του μοντέλου!'
    },
    aiInfo: {
      title: 'Πληροφορίες AI',
      section1Title: 'Εργάζεστε με ένα σύστημα AI',
      section1Text: 'Το Calliope Teachable Machine χρησιμοποιεί τεχνητή νοημοσύνη (AI) για να μάθει από τις εικόνες του δείγματός σας. Αυτό σημαίνει: Εκπαιδεύετε ένα μοντέλο που αναγνωρίζει ανεξάρτητα μοτίβα σε εικόνες - για παράδειγμα, διαφορετικές χειρονομίες των χεριών ή χρώματα.',
      section2Title: 'Πώς λειτουργεί το σύστημα',
      section2Text1: 'Το μοντέλο βασίζεται σε μια τεχνική που ονομάζεται "Transfer Learning". Χρησιμοποιούμε ένα προεκπαιδευμένο νευρωνικό δίκτυο (MobileNet) που γνωρίζει ήδη πολλά χαρακτηριστικά εικόνας. Οι εικόνες του δείγματός σας χρησιμοποιούνται για να προσαρμόσουν αυτή τη γνώση στη συγκεκριμένη εργασία σας - όπως η διάκριση των δικών σας χειρονομιών.',
      section2Text2: 'Όλοι οι υπολογισμοί και η εκπαίδευση πραγματοποιούνται απευθείας στο πρόγραμμα περιήγησής σας. Δεν μεταφέρονται δεδομένα σε διακομιστές - όλα παραμένουν τοπικά στη συσκευή σας.',
      section3Title: 'Τα δεδομένα σας παραμένουν μαζί σας',
      section3Text: 'Όλες οι εικόνες που καταγράφετε με την κάμερα web επεξεργάζονται αποκλειστικά τοπικά. Δεν εγκαταλείπουν ποτέ τον υπολογιστή σας. Το εκπαιδευμένο μοντέλο αποθηκεύεται επίσης μόνο στη συσκευή σας.',
      section4Title: 'Όρια και περιορισμοί',
      section4Text1: 'Το εκπαιδευμένο μοντέλο σας είναι τόσο καλό όσο τα δεδομένα εκπαίδευσής σας. Για παράδειγμα, εάν καταγράφετε εικόνες μόνο κατά τη διάρκεια της ημέρας, το μοντέλο μπορεί να μην λειτουργεί αξιόπιστα σε συνθήκες χαμηλού φωτισμού. Όσο πιο ποικίλα είναι τα παραδείγματά σας, τόσο πιο ισχυρό θα είναι το μοντέλο.',
      section4Text2: 'Το σύστημα προορίζεται για <strong>μαθησιακά και πειραματικά έργα</strong>. Δεν είναι κατάλληλο για εφαρμογές κρίσιμες για την ασφάλεια ή αποφάσεις που θα μπορούσαν να επηρεάσουν τους ανθρώπους.',
      section5Title: 'Δικαιοσύνη και ευθύνη',
      section5Text: 'Εσείς αποφασίζετε ποιες εικόνες να χρησιμοποιήσετε για εκπαίδευση. Βεβαιωθείτε ότι τα δεδομένα εκπαίδευσής σας είναι ισορροπημένα και δεν αντικατοπτρίζουν προκαταλήψεις. Για παράδειγμα, εάν καταγράψετε εικόνες μόνο από ένα άτομο, το μοντέλο μπορεί να λειτουργήσει χειρότερα με άλλα άτομα.',
      section6Title: 'Για τι είναι κατάλληλο αυτό το σύστημα;',
      section6Text: 'Το Teachable Machine είναι ιδανικό για δημιουργικά έργα, σχολικά έργα και παιχνιδιάρικη μάθηση. Μπορείτε:',
      section6List: [
        'Να αναγνωρίζετε χειρονομίες των χεριών για να ελέγχετε το Calliope mini σας',
        'Να διακρίνετε χρώματα ή αντικείμενα',
        'Να κατανοήσετε πώς λειτουργεί η μηχανική μάθηση',
        'Να αναπτύξετε τα δικά σας διαδραστικά έργα'
      ],
      section7Title: 'Περισσότερες πληροφορίες',
      section7Text: 'Αυτό το εργαλείο ακολουθεί τις απαιτήσεις διαφάνειας του Κανονισμού της ΕΕ για την AI (EU) 2024/1689. Έχετε πάντα τον έλεγχο των δεδομένων και των μοντέλων σας. Εάν έχετε ερωτήσεις σχετικά με τον τρόπο λειτουργίας, μπορείτε να δείτε τις "Λεπτομέρειες μοντέλου" μετά την εκπαίδευση - εκεί θα βρείτε τεχνικές πληροφορίες σχετικά με την απόδοση του μοντέλου σας.'
    }
  }
};

let mobilenetModel;
let classifierModel = null;
const examples = {};
let classes = [];
let activeClass = null;
let captureInterval = null;
let testInterval = null;
let tryoutInterval = null;
let model = null;
const captureRate = CONFIG.CAPTURE_RATE_MS;
const testRate = CONFIG.PREDICTION_RATE_MS;
let modelMetadata = {
  name: "Teachable Machine Model",
  date: new Date().toISOString(),
  version: "1.0",
  classes: []
};

// Cache frequently accessed DOM elements for performance optimization
const cachedElements = {
  webcamTest: null,
  webcamApply: null,
  predictionDisplay: null,
  applyPrediction: null
};

// Initialize cached elements
function initCachedElements() {
  cachedElements.webcamTest = document.getElementById('webcam-test');
  cachedElements.webcamApply = document.getElementById('webcam-apply');
  cachedElements.predictionDisplay = document.getElementById('prediction-display');
  cachedElements.applyPrediction = document.getElementById('apply-prediction');
}
let isTestActive = false;
let isTryoutActive = false;
let pendingZipImages = [];
let pendingZipClass = null;
let lastSendTime = 0;
const SEND_INTERVAL_MS = CONFIG.SEND_INTERVAL_MS;

// Training history for graphs
let trainingHistory = {
  epochs: [],
  accuracy: [],
  loss: []
};

// Last confusion matrix for re-rendering on language change
let lastConfusionMatrix = null;

// Bluetooth variables - updated to match working implementation
const UART_SERVICE_UUID = "6e400001-b5a3-f393-e0a9-e50e24dcca9e";
const UART_TX_CHARACTERISTIC_UUID = "6e400002-b5a3-f393-e0a9-e50e24dcca9e";
const UART_RX_CHARACTERISTIC_UUID = "6e400003-b5a3-f393-e0a9-e50e24dcca9e";

let uBitDevice;
let rxCharacteristic;
let queue = Promise.resolve();

// Variables for throttling Bluetooth transmission
// State management for class change detection
let lastDetectedClass = null;
let isFirstPrediction = true;

// Chart instances
let accuracyLossChart = null;
let accuracyChart = null;

// Progressive reveal state
function updateProgressiveUI() {
  const numClasses = classes.length;

  // Step 1: Show "Klassen" list after first class is created
  const classListSection = document.getElementById('step-class-list');
  if (numClasses >= 1) {
    classListSection.classList.add('visible');
  } else {
    classListSection.classList.remove('visible');
  }

  // Step 2: Show "Aktive Klasse" section after first class is created
  const activeClassSection = document.getElementById('step-active-class');
  if (numClasses >= 1) {
    activeClassSection.classList.add('visible');
  } else {
    activeClassSection.classList.remove('visible');
  }

  // Step 3: Show "Training" section after 3 classes all have images
  // Count classes with images
  let classesWithImages = 0;
  for (const className of classes) {
    if ((examples[className] || []).length > 0) {
      classesWithImages++;
    }
  }

  const trainingSection = document.getElementById('step-training');
  if (classesWithImages >= 3) {
    trainingSection.classList.add('visible');
  } else {
    trainingSection.classList.remove('visible');
  }

  // Step 4: "Projekt herunterladen" is shown after training (handled in training completion)
}

// Help text management
function updateHelpText() {
  const helpTextTop = document.getElementById('help-text-top');
  const helpTextMiddle = document.getElementById('help-text-middle');
  if (!helpTextTop || !helpTextMiddle) return;

  const numClasses = classes.length;

  // Count total images across all classes
  let totalImages = 0;
  for (const className of classes) {
    totalImages += (examples[className] || []).length;
  }

  // Count classes with images
  let classesWithImages = 0;
  for (const className of classes) {
    if ((examples[className] || []).length > 0) {
      classesWithImages++;
    }
  }

  // Clear both help texts by default
  let topText = '';
  let middleText = '';

  if (numClasses === 0) {
    // State 1: No classes created yet - show above Modell
    topText = translate('helpTexts.text1');
  } else if (numClasses >= 1 && totalImages === 0) {
    // State 2: Class(es) created but no images yet - show above Modell
    topText = translate('helpTexts.text2');
  } else if (totalImages > 0 && classesWithImages < 3) {
    // State 3: Some images recorded but less than 3 classes have images - show in middle
    middleText = translate('helpTexts.text3');
  }
  // State 4: 3+ classes with images - both texts are empty (hidden), Training block appears

  helpTextTop.textContent = topText;
  helpTextMiddle.textContent = middleText;
}

// View management
function switchView(viewName) {
  // Show/hide views
  document.querySelectorAll('.view').forEach(view => {
    view.style.display = 'none';
  });
  document.getElementById(`${viewName}-view`).style.display = 'flex';

  // Show editor ONLY in tryout view
  let makecodeEditor = document.getElementById('makecode-editor-container');
  if (makecodeEditor) {
    makecodeEditor.style.display = (viewName === 'tryout') ? 'block' : 'none';
  }

  // Update navigation buttons
  document.querySelectorAll('.nav-button').forEach(btn => {
    btn.classList.remove('active');
    if (btn.getAttribute('data-view') === viewName) {
      btn.classList.add('active');
    }
  });

  // Initialize view-specific features
  // Camera is only needed in training, tryout and apply views
  if (viewName === 'training' || viewName === 'tryout' || viewName === 'apply') {
    initSharedCamera();
  }

  // Im ANWENDEN-View Vorhersage automatisch aktivieren
  if (viewName === 'apply') {
    if (!isTryoutActive && classifierModel) {
      isTryoutActive = true;
      tryoutInterval = setInterval(tryoutModel, testRate);
    }
  } else if (viewName !== 'apply') {
    // Stop predictions when leaving apply view
    if (isTryoutActive) {
      isTryoutActive = false;
      clearInterval(tryoutInterval);
    }
  }
}

// Welcome and AI Info overlay functions
function closeWelcomeOverlay(event) {
  if (event) {
    event.preventDefault();
    event.stopPropagation();
  }
  document.getElementById('welcome-overlay').style.display = 'none';

  // Immediately request camera access for training view
  initSharedCamera();
}

function toggleSettingsMenu(event) {
  event.preventDefault();
  event.stopPropagation();
  const menu = document.getElementById('settings-menu');
  if (menu.style.display === 'none' || menu.style.display === '') {
    menu.style.display = 'block';
  } else {
    menu.style.display = 'none';
  }
}

// Close settings menu when clicking outside
document.addEventListener('click', function(event) {
  const settingsContainer = document.getElementById('settings-container');
  const settingsMenu = document.getElementById('settings-menu');
  if (settingsContainer && settingsMenu && !settingsContainer.contains(event.target)) {
    settingsMenu.style.display = 'none';
  }
});

function openLanguageSelection(event) {
  event.preventDefault();
  event.stopPropagation();
  // Close settings menu
  document.getElementById('settings-menu').style.display = 'none';
  // Open language selection overlay
  document.getElementById('language-overlay').style.display = 'flex';
  // Mark current language as active
  updateLanguageOptions();
}

function closeLanguageSelection(event) {
  if (event) {
    event.preventDefault();
    event.stopPropagation();
  }
  document.getElementById('language-overlay').style.display = 'none';
}

function selectLanguage(lang) {
  changeLanguage(lang);
  closeLanguageSelection();
}

// Model Loader Overlay toggle
function toggleModelLoader() {
  const overlay = document.getElementById('model-loader-overlay');
  overlay.classList.toggle('collapsed');
}

function updateLanguageOptions() {
  document.querySelectorAll('.language-option').forEach(option => {
    option.classList.remove('active');
  });
  // Find and mark the current language as active
  const languageOptions = document.querySelectorAll('.language-option');
  const langMap = { 'de': 0, 'en': 1, 'fr': 2, 'es': 3, 'it': 4, 'el': 5 };
  const index = langMap[currentLanguage];
  if (index !== undefined && languageOptions[index]) {
    languageOptions[index].classList.add('active');
  }
}

function openAIInfoFromMenu(event) {
  event.preventDefault();
  event.stopPropagation();
  // Close settings menu
  document.getElementById('settings-menu').style.display = 'none';
  // Close welcome overlay
  document.getElementById('welcome-overlay').style.display = 'none';
  // Open AI info overlay
  document.getElementById('ai-info-overlay').style.display = 'flex';
}

function openAIInfo(event) {
  event.preventDefault();
  event.stopPropagation();
  // Close welcome overlay
  document.getElementById('welcome-overlay').style.display = 'none';
  // Open AI info overlay
  document.getElementById('ai-info-overlay').style.display = 'flex';
}

function closeAIInfoOverlay(event) {
  if (event) {
    event.preventDefault();
    event.stopPropagation();
  }
  document.getElementById('ai-info-overlay').style.display = 'none';
}

// Translation system
// Translation cache for performance optimization
const translationCache = {};

function translate(key) {
  // Check cache first (memory optimization)
  const cacheKey = `${currentLanguage}:${key}`;
  if (translationCache[cacheKey]) {
    return translationCache[cacheKey];
  }

  const keys = key.split('.');
  let value = translations[currentLanguage];

  for (const k of keys) {
    if (value && value[k] !== undefined) {
      value = value[k];
    } else {
      console.warn(`Translation missing for key: ${key} in language: ${currentLanguage}`);
      return key;
    }
  }

  // Cache the result
  translationCache[cacheKey] = value;
  return value;
}

function changeLanguage(lang) {
  currentLanguage = lang;

  // Clear translation cache when language changes
  for (let key in translationCache) {
    delete translationCache[key];
  }

  // Update language dropdown selected value
  const languageSelect = document.getElementById('language-select');
  if (languageSelect && languageSelect.value !== lang) {
    languageSelect.value = lang;
  }

  // Update all elements with data-i18n attribute
  document.querySelectorAll('[data-i18n]').forEach(element => {
    const key = element.getAttribute('data-i18n');
    const translation = translate(key);

    if (element.id === 'welcome-title') {
      // Special handling for welcome title with HTML
      element.innerHTML = translation;
    } else if (element.tagName === 'LABEL' && element.classList.contains('file-label')) {
      // File labels need special handling to preserve input element
      const input = element.querySelector('input');
      element.textContent = translation;
      if (input) {
        element.appendChild(input);
      }
    } else if (element.tagName === 'A' || element.tagName === 'BUTTON' || element.tagName === 'LABEL') {
      element.textContent = translation;
    } else {
      element.textContent = translation;
    }
  });

  // Update placeholders
  document.querySelectorAll('[data-i18n-placeholder]').forEach(element => {
    const key = element.getAttribute('data-i18n-placeholder');
    const translation = translate(key);
    element.placeholder = translation;
  });

  // Update help texts
  updateHelpText();

  // Update AI info content
  updateAIInfoContent();

  // Update Model Details content
  updateModelDetailsContent();
}

function updateAIInfoContent() {
  const aiInfo = translate('aiInfo');
  const aiInfoContent = document.getElementById('ai-info-content');

  if (!aiInfoContent) return;

  aiInfoContent.innerHTML = `
    <h3>${aiInfo.section1Title}</h3>
    <p>${aiInfo.section1Text}</p>

    <h3>${aiInfo.section2Title}</h3>
    <p>${aiInfo.section2Text1}</p>
    <p>${aiInfo.section2Text2}</p>

    <h3>${aiInfo.section3Title}</h3>
    <p>${aiInfo.section3Text}</p>

    <h3>${aiInfo.section4Title}</h3>
    <p>${aiInfo.section4Text1}</p>
    <p>${aiInfo.section4Text2}</p>

    <h3>${aiInfo.section5Title}</h3>
    <p>${aiInfo.section5Text}</p>

    <h3>${aiInfo.section6Title}</h3>
    <p>${aiInfo.section6Text}</p>
    <ul>
      ${aiInfo.section6List.map(item => `<li>${item}</li>`).join('')}
    </ul>

    <h3>${aiInfo.section7Title}</h3>
    <p>${aiInfo.section7Text}</p>
  `;

  // Update AI info title
  const aiInfoTitle = document.getElementById('ai-info-title');
  if (aiInfoTitle) {
    aiInfoTitle.textContent = aiInfo.title;
  }
}

function updateModelDetailsContent() {
  const md = translate('modelDetails');

  // Update Overview tab content
  const overviewTab = document.getElementById('overview-tab');
  if (overviewTab) {
    const sectionDesc = overviewTab.querySelector('.section-description');
    if (sectionDesc) {
      sectionDesc.innerHTML = `
        <strong>${md.overviewTitle}</strong><br>
        <em>${md.overviewTerms}</em><br><br>
        ${md.overviewIntro}<br><br>
        ${md.overviewValidation}<br><br>
        ${md.accuracyValues}<br><br>
        ${md.lossValues}<br><br>
        ${md.epochsInfo}<br><br>
        ${md.dataInfo}
      `;
    }
  }

  // Update Accuracy tab content
  const accuracyTab = document.getElementById('accuracy-tab');
  if (accuracyTab) {
    const sectionDesc = accuracyTab.querySelector('.section-description');
    if (sectionDesc) {
      sectionDesc.innerHTML = `
        <strong>${md.accuracyPerClassTitle}</strong><br>
        <em>${md.accuracyPerClassTerms}</em><br><br>
        ${md.accuracyPerClassIntro}<br><br>
        ${md.interpretationTitle}<br><br>
        ${md.lowAccuracyCauses}<br><br>
        ${md.improvementTips}
      `;
    }
  }

  // Update Confusion Matrix tab content
  const confusionTab = document.getElementById('confusion-tab');
  if (confusionTab) {
    const sectionDesc = confusionTab.querySelector('.section-description');
    if (sectionDesc) {
      sectionDesc.innerHTML = `
        <strong>${md.confusionMatrixTitle}</strong><br>
        <em>${md.confusionMatrixTerms}</em><br><br>
        ${md.confusionMatrixIntro}<br><br>
        ${md.confusionMatrixReading}<br><br>
        ${md.confusionMatrixExample}<br><br>
        ${md.confusionMatrixPerfect}<br><br>
        ${md.confusionMatrixImprovement}
      `;
    }
  }

  // Re-render confusion matrix if it exists
  if (lastConfusionMatrix) {
    renderConfusionMatrix(lastConfusionMatrix);
  }

  // Update chart labels
  if (accuracyLossChart) {
    const md = translate('modelDetails');
    accuracyLossChart.options.plugins.title.text = md.chartAccuracyLossTitle;
    accuracyLossChart.data.datasets[0].label = md.chartAccuracyLabel;
    accuracyLossChart.data.datasets[1].label = md.chartLossLabel;
    accuracyLossChart.options.scales.y.title.text = md.chartAccuracyLabel;
    accuracyLossChart.options.scales.y1.title.text = md.chartLossLabel;
    accuracyLossChart.options.scales.x.title.text = md.chartEpochLabel;
    accuracyLossChart.update();
  }

  if (accuracyChart) {
    const md = translate('modelDetails');
    accuracyChart.options.plugins.title.text = md.chartClassAccuracyTitle;
    accuracyChart.data.datasets[0].label = md.chartClassAccuracyLabel;
    accuracyChart.update();
  }
}

// Gemeinsame Webcam für alle Video-Elemente
let globalStream = null;

// Cleanup function for camera stream (memory optimization)
function stopGlobalCamera() {
  if (globalStream) {
    globalStream.getTracks().forEach(track => track.stop());
    globalStream = null;

    // Clear video elements
    const videoIds = ["webcam", "webcam-test", "webcam-tryout", "webcam-apply"];
    videoIds.forEach(id => {
      const v = document.getElementById(id);
      if (v) v.srcObject = null;
    });
  }
}

async function initSharedCamera() {
  try {
    // Falls noch kein Stream existiert → jetzt Kamera anfordern
    if (!globalStream) {
      globalStream = await navigator.mediaDevices.getUserMedia({ video: true });
    }

    // Liste aller Video-Elemente, die den Stream nutzen sollen
    const videoIds = ["webcam", "webcam-test", "webcam-tryout", "webcam-apply"];

    for (const id of videoIds) {
      const v = document.getElementById(id);
      if (!v) continue;

      // Den globalen Stream zuweisen
      if (v.srcObject !== globalStream) {
        v.srcObject = globalStream;
      }

      // Sicherstellen, dass das Video abgespielt wird
      v.onloadedmetadata = () => {
        v.play().catch(err => console.warn("Video play blocked:", err));
      };
    }
  } catch (err) {
    console.error("Kamera-Initialisierung fehlgeschlagen:", err);
    alert("Zugriff auf die Kamera ist nicht möglich.");
  }
}


async function init() {
  console.log('Initializing application...');

  try {
    // Load MobileNet first (doesn't require camera)
    console.log('Loading MobileNet...');
    mobilenetModel = await mobilenet.load();
    console.log('MobileNet loaded successfully');

    // UI-Statusmeldungen
    document.getElementById('status').textContent = 'Bereit';
    document.getElementById('test-status').textContent = 'Bereit zum Testen';

  } catch (error) {
    console.error('Initialization error:', error);
    alert('Failed to load MobileNet model: ' + error.message);
  }
}

// Show notification 
function showNotification(message, duration = 3000) {
  const notification = document.getElementById('model-load-notification');
  notification.textContent = message;
  notification.style.display = 'block';
  
  setTimeout(() => {
    notification.style.display = 'none';
  }, duration);
}

//makecode ready
let makecodeReady = false;

window.addEventListener("message", ev => {
    const msg = ev.data;

    if (msg?.type === "pxteditor" && msg?.action === "editorloaded") {
        console.log("MakeCode Calliope bereit ✓");
        makecodeReady = true;
    }
});
// Klassenverwaltung
function addClass(name) {
  if (!name || classes.includes(name)) return;
  classes.push(name);
  examples[name] = [];
  modelMetadata.classes.push(name);
  renderClassList();
  setActiveClass(name);

  // Update progressive UI after adding class
  updateProgressiveUI();
  updateHelpText();
}

function deleteClass(name) {
  // Confirm deletion
  const confirmMsg = translate('training.confirmDeleteClass') || `Klasse "${name}" wirklich löschen?`;
  if (!confirm(confirmMsg)) return;

  // Remove class from arrays
  const index = classes.indexOf(name);
  if (index > -1) {
    classes.splice(index, 1);
  }

  // Remove examples
  delete examples[name];

  // Remove from metadata
  const metaIndex = modelMetadata.classes.indexOf(name);
  if (metaIndex > -1) {
    modelMetadata.classes.splice(metaIndex, 1);
  }

  // Set active class to first available or null
  if (activeClass === name) {
    activeClass = classes.length > 0 ? classes[0] : null;
  }

  // Update UI
  renderClassList();
  renderThumbs();
  updateProgressiveUI();
  updateHelpText();

  console.log(`Deleted class: ${name}`);
}

function renderClassList() {
  const list = document.getElementById('class-list');
  list.innerHTML = '';
  for (const c of classes) {
    const div = document.createElement('div');
    div.className = 'class-item';
    if (c === activeClass) {
      div.classList.add('selected');
    }

    const nameSpan = document.createElement('span');
    nameSpan.className = 'class-name';
    nameSpan.textContent = c + ' (' + (examples[c].length || 0) + ')';

    const actionsDiv = document.createElement('div');
    actionsDiv.className = 'class-actions';

    const downloadBtn = document.createElement('button');
    downloadBtn.className = 'ghost';
    downloadBtn.textContent = '↓';
    downloadBtn.title = translate('training.downloadImages') || 'Bilder herunterladen';
    downloadBtn.onclick = (e) => {
      e.stopPropagation();
      downloadClassImages(c);
    };

    const deleteBtn = document.createElement('button');
    deleteBtn.className = 'ghost';
    deleteBtn.textContent = '×';
    deleteBtn.title = translate('training.deleteClass') || 'Klasse löschen';
    deleteBtn.style.color = 'rgb(var(--md-sys-color-error))';
    deleteBtn.onclick = (e) => {
      e.stopPropagation();
      deleteClass(c);
    };

    actionsDiv.appendChild(downloadBtn);
    actionsDiv.appendChild(deleteBtn);
    div.appendChild(nameSpan);
    div.appendChild(actionsDiv);

    div.onclick = () => setActiveClass(c);
    list.appendChild(div);
  }

  const sel = document.getElementById('active-class');
  sel.innerHTML = '';
  for (const c of classes) {
    const opt = document.createElement('option');
    opt.value = c;
    opt.textContent = c;
    sel.appendChild(opt);
  }
  // Dropdown immer auf die aktuell aktive Klasse setzen
  if (activeClass && classes.includes(activeClass)) {
    sel.value = activeClass;
  }

  // Update progressive UI when class list changes
  updateProgressiveUI();
  updateHelpText();
}

function setActiveClass(name) {
  activeClass = name;
  document.getElementById('active-class').value = name;
  renderClassList();
  renderThumbs();
}

function renderThumbs() {
  const t = document.getElementById('thumbs');
  t.innerHTML = '';
  const arr = examples[activeClass] ? [...examples[activeClass]].reverse() : [];
  for (const e of arr) {
    const img = new Image();
    img.src = e.data;
    img.className = 'thumb';
    t.appendChild(img);
  }
  document.getElementById('capture-count').textContent = arr.length + ' Bilder';

  // Show/hide "Leeren" button based on whether images exist
  const clearBtn = document.getElementById('clear-class');
  if (clearBtn) {
    clearBtn.style.display = arr.length > 0 ? 'inline-flex' : 'none';
  }

  // Show/hide "Löschen" button based on whether class is active
  const deleteBtn = document.getElementById('delete-class-btn');
  if (deleteBtn) {
    deleteBtn.style.display = activeClass ? 'inline-flex' : 'none';
  }

  // Update help text when images change
  updateHelpText();
}

// Model Details Dialog 
function showModelDetails() {
  if (!classifierModel) {
    alert('Bitte zuerst ein Modell trainieren');
    return;
  }
  
  document.getElementById('model-details-dialog').style.display = 'block';
  document.getElementById('dialog-overlay').style.display = 'block';
  
  // Update overview stats
  updateModelStats();
  
  // Initialize charts if not already done
  if (!accuracyLossChart) {
    initAccuracyLossChart();
  }
  if (!accuracyChart) {
    initAccuracyChart();
  }
  
  // Update charts with training history
  updateCharts();
  
  // Calculate and display confusion matrix
  calculateConfusionMatrix();
}

function hideModelDetails() {
  document.getElementById('model-details-dialog').style.display = 'none';
  document.getElementById('dialog-overlay').style.display = 'none';

  // Clean up chart instances to prevent memory leaks
  if (accuracyLossChart) {
    accuracyLossChart.destroy();
    accuracyLossChart = null;
  }
  if (accuracyChart) {
    accuracyChart.destroy();
    accuracyChart = null;
  }
}

function updateModelStats() {
  // Calculate total examples
  let totalExamples = 0;
  for (const className of classes) {
    totalExamples += examples[className].length;
  }
  
  // Update stats
  document.getElementById('total-epochs').textContent = trainingHistory.epochs.length;
  document.getElementById('total-examples').textContent = totalExamples;
  
  if (trainingHistory.accuracy.length > 0) {
    const lastAccuracy = trainingHistory.accuracy[trainingHistory.accuracy.length - 1];
    const lastLoss = trainingHistory.loss[trainingHistory.loss.length - 1];
    
    document.getElementById('overall-accuracy').textContent = (lastAccuracy * 100).toFixed(1) + '%';
    document.getElementById('total-loss').textContent = lastLoss.toFixed(4);
  }
}

function initAccuracyLossChart() {
  const ctx = document.getElementById('accuracy-loss-chart').getContext('2d');
  accuracyLossChart = new Chart(ctx, {
    type: 'line',
    data: {
      labels: [],
      datasets: [
        {
          label: translate('modelDetails.chartAccuracyLabel'),
          data: [],
          borderColor: '#4CAF50',
          backgroundColor: 'rgba(76, 175, 80, 0.1)',
          fill: true,
          tension: 0.4
        },
        {
          label: translate('modelDetails.chartLossLabel'),
          data: [],
          borderColor: '#F44336',
          backgroundColor: 'rgba(244, 67, 54, 0.1)',
          fill: true,
          tension: 0.4,
          yAxisID: 'y1'
        }
      ]
    },
    options: {
      responsive: true,
      maintainAspectRatio: false,
      plugins: {
        title: {
          display: true,
          text: translate('modelDetails.chartAccuracyLossTitle')
        },
        tooltip: {
          mode: 'index',
          intersect: false
        }
      },
      scales: {
        y: {
          beginAtZero: true,
          max: 1,
          title: {
            display: true,
            text: translate('modelDetails.chartAccuracyLabel')
          }
        },
        y1: {
          beginAtZero: true,
          position: 'right',
          grid: {
            drawOnChartArea: false
          },
          title: {
            display: true,
            text: translate('modelDetails.chartLossLabel')
          }
        },
        x: {
          title: {
            display: true,
            text: translate('modelDetails.chartEpochLabel')
          }
        }
      }
    }
  });
}

function initAccuracyChart() {
  const ctx = document.getElementById('accuracy-chart').getContext('2d');
  accuracyChart = new Chart(ctx, {
    type: 'bar',
    data: {
      labels: classes,
      datasets: [{
        label: translate('modelDetails.chartClassAccuracyLabel'),
        data: new Array(classes.length).fill(0),
        backgroundColor: [
          'rgba(255, 99, 132, 0.5)',
          'rgba(54, 162, 235, 0.5)',
          'rgba(255, 206, 86, 0.5)',
          'rgba(75, 192, 192, 0.5)',
          'rgba(153, 102, 255, 0.5)',
          'rgba(255, 159, 64, 0.5)'
        ],
        borderColor: [
          'rgba(255, 99, 132, 1)',
          'rgba(54, 162, 235, 1)',
          'rgba(255, 206, 86, 1)',
          'rgba(75, 192, 192, 1)',
          'rgba(153, 102, 255, 1)',
          'rgba(255, 159, 64, 1)'
        ],
        borderWidth: 1
      }]
    },
    options: {
      responsive: true,
      maintainAspectRatio: false,
      plugins: {
        title: {
          display: true,
          text: translate('modelDetails.chartClassAccuracyTitle')
        }
      },
      scales: {
        y: {
          beginAtZero: true,
          max: 1,
          title: {
            display: true,
            text: 'Genauigkeit'
          }
        }
      }
    }
  });
}

function updateCharts() {
  // Update accuracy/loss chart
  if (accuracyLossChart) {
    accuracyLossChart.data.labels = trainingHistory.epochs;
    accuracyLossChart.data.datasets[0].data = trainingHistory.accuracy;
    accuracyLossChart.data.datasets[1].data = trainingHistory.loss;
    accuracyLossChart.update();
  }
  
  // Update accuracy per class chart
  if (accuracyChart && classes.length > 0) {
    accuracyChart.data.labels = classes;
    accuracyChart.data.datasets[0].data = new Array(classes.length).fill(0);
    accuracyChart.update();
  }
}

async function calculateConfusionMatrix() {
  if (!classifierModel || classes.length === 0) return;
  
  // Create confusion matrix
  const matrixSize = classes.length;
  const confusionMatrix = Array(matrixSize).fill().map(() => Array(matrixSize).fill(0));
  const classAccuracy = new Array(classes.length).fill(0);
  const classCounts = new Array(classes.length).fill(0);
  
  // Test each example
  for (let classIndex = 0; classIndex < classes.length; classIndex++) {
    const className = classes[classIndex];
    const classExamples = examples[className];
    
    for (const example of classExamples) {
      // Create image tensor from example
      const img = new Image();
      img.src = example.data;
      await new Promise(r => img.onload = r);
      
      const input = tf.browser.fromPixels(img).toFloat().div(127.5).sub(1).resizeBilinear([224,224]).expandDims(0);
      const emb = mobilenetModel.infer(input, true);
      const prediction = await classifierModel.predict(emb).data();

      // Find predicted class
      let maxProb = 0;
      let predictedIndex = 0;
      for (let i = 0; i < classes.length; i++) {
        if (prediction[i] > maxProb) {
          maxProb = prediction[i];
          predictedIndex = i;
        }
      }
      
      // Update confusion matrix
      confusionMatrix[classIndex][predictedIndex]++;
      classCounts[classIndex]++;
      
      // Update class accuracy
      if (predictedIndex === classIndex) {
        classAccuracy[classIndex]++;
      }
      
      // Clean up tensors
      input.dispose();
      emb.dispose();
    }
  }
  
  // Calculate final accuracy percentages
  for (let i = 0; i < classes.length; i++) {
    if (classCounts[i] > 0) {
      classAccuracy[i] = classAccuracy[i] / classCounts[i];
    }
  }
  
  // Update accuracy chart
  if (accuracyChart) {
    accuracyChart.data.datasets[0].data = classAccuracy;
    accuracyChart.update();
  }
  
  // Render confusion matrix
  renderConfusionMatrix(confusionMatrix);
}

function renderConfusionMatrix(matrix) {
  // Store the matrix for re-rendering on language change
  lastConfusionMatrix = matrix;

  const container = document.getElementById('confusion-matrix-container');
  container.innerHTML = '';

  const table = document.createElement('table');

  const headerRow = document.createElement('tr');
  headerRow.appendChild(document.createElement('th')); // Leere Fläche

  for (let i = 0; i < classes.length; i++) {
    const th = document.createElement('th');
    th.textContent = `${translate('modelDetails.predicted')}: ${classes[i]}`;
    headerRow.appendChild(th);        // Korrekt
  }
  table.appendChild(headerRow);

  for (let i = 0; i < classes.length; i++) {
    const row = document.createElement('tr');
    const rowHeader = document.createElement('th');
    rowHeader.textContent = `${translate('modelDetails.actual')}: ${classes[i]}`;
    row.appendChild(rowHeader);

    for (let j = 0; j < classes.length; j++) {
      const cell = document.createElement('td');
      cell.textContent = matrix[i][j];
      if (i === j) cell.classList.add('correct');
      else if (matrix[i][j] > 0) cell.classList.add('incorrect');
      row.appendChild(cell);
    }
    table.appendChild(row);
  }

  container.appendChild(table);
}


// Import-Dialogfunktionen
function showImportDialog(zipImages, detectedClass = null) {
  pendingZipImages = zipImages;
  pendingZipClass = detectedClass;
  
  const dialog = document.getElementById('import-dialog');
  const overlay = document.getElementById('dialog-overlay');
  const optionsContainer = document.getElementById('import-class-options');
  const message = document.getElementById('import-message');
  
  // Clear previous options
  optionsContainer.innerHTML = '';
  
  // Set message based on whether we detected a class
  if (detectedClass) {
    message.textContent = `${zipImages.length} Bilder aus Klasse "${detectedClass}" gefunden. Wähle eine Klasse für den Import:`;
  } else {
    message.textContent = `${zipImages.length} Bilder gefunden. Wähle eine Klasse für den Import:`;
  }
  
  // Add option for each existing class
  classes.forEach(className => {
    const option = document.createElement('div');
    option.className = 'class-option';
    if (className === activeClass) {
      option.classList.add('selected');
    }
    option.textContent = className + ' (hat bereits ' + examples[className].length + ' Bilder)';
    option.onclick = () => {
      document.querySelectorAll('.class-option').forEach(opt => opt.classList.remove('selected'));
      option.classList.add('selected');
      pendingZipClass = className;
    };
    optionsContainer.appendChild(option);
  });
  
  // Add option to create new class
  const newOption = document.createElement('div');
  newOption.className = 'class-option';
  newOption.textContent = 'Neue Klasse erstellen...';
  newOption.onclick = () => {
    const newName = prompt('Name für neue Klasse:', detectedClass || 'Importierte Klasse');
    if (newName && !classes.includes(newName)) {
      addClass(newName);
      document.querySelectorAll('.class-option').forEach(opt => opt.classList.remove('selected'));
      newOption.textContent = newName + ' (neu)';
      newOption.classList.add('selected');
      pendingZipClass = newName;
    }
  };
  optionsContainer.appendChild(newOption);
  
  // Show dialog
  dialog.style.display = 'block';
  overlay.style.display = 'block';
  
  // Set initial selection
  if (detectedClass && classes.includes(detectedClass)) {
    pendingZipClass = detectedClass;
  } else if (activeClass) {
    pendingZipClass = activeClass;
  }
}

function hideImportDialog() {
  document.getElementById('import-dialog').style.display = 'none';
  document.getElementById('dialog-overlay').style.display = 'none';
  pendingZipImages = [];
  pendingZipClass = null;
}

function confirmImport() {
  if (!pendingZipClass || !pendingZipImages.length) {
    hideImportDialog();
    return;
  }
  
  // Add images to selected class
  pendingZipImages.forEach(imageData => {
    examples[pendingZipClass].push({ data: imageData });
  });
  
  // Update UI
  setActiveClass(pendingZipClass);
  renderClassList();
  renderThumbs();
  
  console.log(`Imported ${pendingZipImages.length} images to class "${pendingZipClass}"`);
  hideImportDialog();
}

// Process zip file for image import 
async function processZipFile(file) {
  try {
    const arrayBuffer = await file.arrayBuffer();
    const zip = new JSZip();
    const zipContent = await zip.loadAsync(arrayBuffer);
    
    const imageFiles = [];
    let detectedClass = null;
    
    // Check if this is a single class zip or multi-class zip
    const folders = Object.keys(zipContent.files).filter(path => {
      const file = zipContent.files[path];
      return file.dir && path !== '/' && path !== '__MACOSX/';
    });
    
    if (folders.length > 0) {
      // Multi-class zip - let user choose which class to import
      // For now, we'll import from the first folder that has images
      for (const folder of folders) {
        const folderName = folder.replace(/\/$/, '');
        const filesInFolder = Object.keys(zipContent.files).filter(path => 
          path.startsWith(folder) && 
          !zipContent.files[path].dir && 
          (path.endsWith('.png') || path.endsWith('.jpg') || path.endsWith('.jpeg'))
        );
        
        if (filesInFolder.length > 0) {
          detectedClass = folderName;
          // Extract images from this folder
          for (const filePath of filesInFolder) {
            const imageFile = zipContent.files[filePath];
            const base64 = await imageFile.async('base64');
            const mimeType = filePath.endsWith('.png') ? 'image/png' : 'image/jpeg';
            imageFiles.push(`data:${mimeType};base64,${base64}`);
          }
          break; // Only process first folder with images for now
        }
      }
    } else {
      // Single class zip - extract all images
      const files = Object.keys(zipContent.files).filter(path => 
        !zipContent.files[path].dir && 
        (path.endsWith('.png') || path.endsWith('.jpg') || path.endsWith('.jpeg'))
      );
      
      for (const filePath of files) {
        const imageFile = zipContent.files[filePath];
        const base64 = await imageFile.async('base64');
        const mimeType = filePath.endsWith('.png') ? 'image/png' : 'image/jpeg';
        imageFiles.push(`data:${mimeType};base64,${base64}`);
      }
      
      // Try to detect class name from metadata
      if (zipContent.file('metadata.json')) {
        const metadata = await zipContent.file('metadata.json').async('string');
        const metadataObj = JSON.parse(metadata);
        detectedClass = metadataObj.className || null;
      }
    }
    
    if (imageFiles.length > 0) {
      showImportDialog(imageFiles, detectedClass);
    } else {
      alert('Keine Bilddateien im Zip-Archiv gefunden');
    }
  } catch (error) {
    console.error('Fehler beim Verarbeiten der Zip-Datei:', error);
    alert('Fehler beim Verarbeiten der Zip-Datei: ' + error.message);
  }
}

// Download class images 
async function downloadClassImages(className) {
  const classExamples = examples[className] || [];
  if (classExamples.length === 0) {
    alert('Keine Bilder zum Herunterladen');
    return;
  }
  
  try {
    const zip = new JSZip();
    const imgFolder = zip.folder(className);
    
    // Add each image to the zip
    for (let i = 0; i < classExamples.length; i++) {
      const base64Data = classExamples[i].data;
      // Extract the base64 part (remove data:image/png;base64, prefix)
      const base64 = base64Data.split(',')[1];
      imgFolder.file(`${className}_${i + 1}.png`, base64, {base64: true});
    }
    
    // Create a metadata file with class information
    const metadata = {
      className: className,
      imageCount: classExamples.length,
      date: new Date().toISOString(),
      version: "1.0"
    };
    imgFolder.file('metadata.json', JSON.stringify(metadata, null, 2));
    
    // Generate and download the zip file
    const content = await zip.generateAsync({type: 'blob'});
    saveAs(content, `${className}_images_${Date.now()}.zip`);
    
    console.log(`Downloaded ${classExamples.length} images for class "${className}"`);
  } catch (error) {
    console.error('Fehler beim Herunterladen der Bilder:', error);
    alert('Fehler beim Herunterladen: ' + error.message);
  }
}

// Download all class images 
async function downloadAllClassImages() {
  if (classes.length === 0) {
    alert('Keine Klassen zum Herunterladen');
    return;
  }
  
  try {
    const zip = new JSZip();
    let totalImages = 0;
    
    // Create a folder for each class
    for (const className of classes) {
      const classExamples = examples[className] || [];
      if (classExamples.length === 0) continue;
      
      const imgFolder = zip.folder(className);
      
      // Add each image to the class folder
      for (let i = 0; i < classExamples.length; i++) {
        const base64Data = classExamples[i].data;
        const base64 = base64Data.split(',')[1];
        imgFolder.file(`${className}_${i + 1}.png`, base64, {base64: true});
        totalImages++;
      }
      
      // Create metadata for each class
      const metadata = {
        className: className,
        imageCount: classExamples.length,
        date: new Date().toISOString()
      };
      imgFolder.file('metadata.json', JSON.stringify(metadata, null, 2));
    }
    
    // Create a main metadata file
    const mainMetadata = {
      projectName: "Teachable Machine Dataset",
      totalClasses: classes.length,
      totalImages: totalImages,
      classes: classes.map(c => ({
        name: c,
        count: examples[c].length
      })),
      date: new Date().toISOString(),
      version: "1.0"
    };
    zip.file('dataset_metadata.json', JSON.stringify(mainMetadata, null, 2));
    
    // Generate and download the zip file
    const content = await zip.generateAsync({type: 'blob'});
    saveAs(content, `teachable_machine_dataset_${Date.now()}.zip`);
    
    console.log(`Downloaded ${totalImages} images from ${classes.length} classes`);
  } catch (error) {
    console.error('Fehler beim Herunterladen aller Bilder:', error);
    alert('Fehler beim Herunterladen: ' + error.message);
  }
}

// Download complete project 
async function downloadProject() {
  if (classes.length === 0) {
    alert('Keine Klassen zum Herunterladen');
    return;
  }
  
  document.getElementById('model-info').textContent = 'Speichere Projekt...';
  
  try {
    const zip = new JSZip();
    let totalImages = 0;
    
    // Create folders for images
    const imagesFolder = zip.folder('images');
    
    // Add all images with their class structure
    for (const className of classes) {
      const classExamples = examples[className] || [];
      if (classExamples.length === 0) continue;
      
      const classFolder = imagesFolder.folder(className);
      
      // Add each image to the class folder
      for (let i = 0; i < classExamples.length; i++) {
        const base64Data = classExamples[i].data;
        const base64 = base64Data.split(',')[1];
        classFolder.file(`${className}_${i + 1}.png`, base64, {base64: true});
        totalImages++;
      }
      
      // Create metadata for each class
      const metadata = {
        className: className,
        imageCount: classExamples.length,
        date: new Date().toISOString()
      };
      classFolder.file('metadata.json', JSON.stringify(metadata, null, 2));
    }
    
    // Save model if it exists
    if (classifierModel) {
      const modelFolder = zip.folder('model');
      
      // Use TensorFlow.js built-in save functionality to get model artifacts
      await classifierModel.save(tf.io.withSaveHandler(async (artifacts) => {
        // Save model topology
        modelFolder.file('model.json', new Blob([JSON.stringify(artifacts.modelTopology)], {type: 'application/json'}));
        
        // Save weight specs
        modelFolder.file('weights.json', new Blob([JSON.stringify(artifacts.weightSpecs)], {type: 'application/json'}));
        
        // Save weight data
        modelFolder.file('weights.bin', new Blob([artifacts.weightData], {type: 'application/octet-stream'}));
        
        // Return a dummy model info since we're handling the actual saving
        return {modelArtifactsInfo: {dateSaved: new Date()}};
      }));
    }
    
    // Create project metadata
    const projectMetadata = {
      projectName: "Teachable Machine Project",
      version: "1.0",
      date: new Date().toISOString(),
      totalClasses: classes.length,
      totalImages: totalImages,
      hasModel: !!classifierModel,
      classes: classes.map(c => ({
        name: c,
        count: examples[c].length
      })),
      modelMetadata: modelMetadata,
      trainingHistory: trainingHistory
    };
    zip.file('project.json', JSON.stringify(projectMetadata, null, 2));
    
    // Generate and download the zip file
    const content = await zip.generateAsync({type: 'blob'});
    saveAs(content, `teachable_machine_project_${Date.now()}.zip`);
    
    document.getElementById('model-info').textContent = 'Projekt erfolgreich gespeichert';
    console.log(`Downloaded project with ${totalImages} images from ${classes.length} classes`);
  } catch (error) {
    console.error('Fehler beim Herunterladen des Projekts:', error);
    document.getElementById('model-info').textContent = 'Fehler beim Speichern: ' + error.message;
  }
}

// Import complete project 
async function importProject(file) {
  document.getElementById('model-info').textContent = 'Lade Projekt...';
  
  try {
    const arrayBuffer = await file.arrayBuffer();
    const zip = new JSZip();
    const zipContent = await zip.loadAsync(arrayBuffer);
    
    // Check if this is a valid project file
    if (!zipContent.file('project.json')) {
      throw new Error('Keine gültige Projekt-Datei');
    }
    
    // Load project metadata
    const projectFile = await zipContent.file('project.json').async('string');
    const projectMetadata = JSON.parse(projectFile);
    
    // Clear current project
    classes = [];
    for (const className in examples) {
      delete examples[className];
    }
    classifierModel = null;
    
    // Load training history if available
    if (projectMetadata.trainingHistory) {
      trainingHistory = projectMetadata.trainingHistory;
    } else {
      // Reset training history
      trainingHistory = {
        epochs: [],
        accuracy: [],
        loss: []
      };
    }
    
    // Load classes and images
    if (zipContent.folder('images')) {
      const imagesFolder = zipContent.folder('images');
      const classFolders = Object.keys(imagesFolder.files).filter(path => {
        const file = imagesFolder.files[path];
        return file.dir && path !== 'images/' && path !== 'images/__MACOSX/' && !path.includes('model');
      }).map(path => path.replace(/^images\//, '').replace(/\/$/, ''));
      
      for (const className of classFolders) {
        classes.push(className);
        examples[className] = [];
        
        const classPath = 'images/' + className + '/';
        const imageFiles = Object.keys(imagesFolder.files).filter(path => 
          path.startsWith(classPath) && 
          !imagesFolder.files[path].dir && 
          (path.endsWith('.png') || path.endsWith('.jpg') || path.endsWith('.jpeg'))
        );
        
        for (const imagePath of imageFiles) {
          const imageFile = imagesFolder.files[imagePath];
          const base64 = await imageFile.async('base64');
          const mimeType = imagePath.endsWith('.png') ? 'image/png' : 'image/jpeg';
          examples[className].push({ data: `data:${mimeType};base64,${base64}` });
        }
      }
    }
    
    // Load model if it exists
    if (projectMetadata.hasModel && zipContent.folder('model')) {
      const modelFolder = zipContent.folder('model');
      
      // Check if all required model files exist
      if (!modelFolder.file('model.json') || !modelFolder.file('weights.json') || !modelFolder.file('weights.bin')) {
        console.warn('Modell-Dateien unvollständig, überspringe Modell-Laden');
      } else {
        // Load model topology
        const modelFile = await modelFolder.file('model.json').async('string');
        const modelTopology = JSON.parse(modelFile);
        
        // Load weight specs
        const weightSpecsFile = await modelFolder.file('weights.json').async('string');
        const weightSpecs = JSON.parse(weightSpecsFile);
        
        // Load weights
        const weightsFile = await modelFolder.file('weights.bin').async('blob');
        const weightData = await weightsFile.arrayBuffer();
        
        // Create model artifacts
        const modelArtifacts = {
          modelTopology: modelTopology,
          weightSpecs: weightSpecs,
          weightData: new Uint8Array(weightData)
        };
        
        // Load model from artifacts
        classifierModel = await tf.loadLayersModel(tf.io.fromMemory(modelArtifacts));
      }
    }
    
    // Update model metadata
    if (projectMetadata.modelMetadata) {
      modelMetadata = projectMetadata.modelMetadata;
    }
    
    // Update UI
    renderClassList();
    if (classes.length > 0) {
      setActiveClass(classes[0]);
    }

    // Show model details and project download buttons if model was loaded
    if (classifierModel) {
      const modelDetailsSection = document.getElementById('step-model-details');
      if (modelDetailsSection) {
        modelDetailsSection.classList.add('visible');
      }

      const projectDownloadSection = document.getElementById('step-project-download');
      if (projectDownloadSection) {
        projectDownloadSection.classList.add('visible');
      }
    }

    // Show notification
    showNotification(`Projekt "${projectMetadata.projectName}" mit ${classes.length} Klassen und ${projectMetadata.totalImages} Bildern importiert`);

    document.getElementById('model-info').textContent = `${translate('status.projectLoaded')} (${new Date(projectMetadata.date).toLocaleString(currentLanguage)})`;
    document.getElementById('test-status').textContent = classifierModel ? translate('status.modelReadyTest') : translate('status.pleaseTrainModel');

    // Update tryout status if element exists (not in Apply view)
    const tryoutStatus = document.getElementById('tryout-status');
    if (tryoutStatus) {
      tryoutStatus.textContent = classifierModel ? translate('status.modelReadyTryout') : translate('status.pleaseTrainModel');
    }

    // MobileNet is already loaded in init(), no need to reload
    console.log('Project imported successfully');
  } catch (error) {
    console.error('Fehler beim Importieren des Projekts:', error);
    document.getElementById('model-info').textContent = 'Fehler beim Importieren: ' + error.message;
  }
}

// Prüfen, ob dies eine größere Stabilität bringt
let predictionBuffer = [];
function smoothPrediction(predictions) {
  predictionBuffer.push(predictions);
  if (predictionBuffer.length > CONFIG.PREDICTION_BUFFER_SIZE) {
    const removed = predictionBuffer.shift();
    // Dispose old tensor to prevent memory leak
    if (removed && removed.dispose) {
      removed.dispose();
    }
  }
  const result = tf.tidy(() => {
    return tf.mean(predictionBuffer, 0).dataSync();
  });
  return result;
}

// Aufnahme - nur wenn Taste gedrückt 
function startCapture() {
  if (!activeClass) return alert('Klasse wählen');
  captureInterval = setInterval(captureFrame, captureRate);
}

function stopCapture() {
  clearInterval(captureInterval);
}

function captureFrame() {
  if (!activeClass) return;
  const video = document.getElementById('webcam');
  const canvas = document.createElement('canvas');
  canvas.width = CONFIG.IMAGE_SIZE;
  canvas.height = CONFIG.IMAGE_SIZE;
  const ctx = canvas.getContext('2d');
  ctx.drawImage(video, 0, 0, canvas.width, canvas.height);
  const data = canvas.toDataURL('image/png');
  examples[activeClass].push({ data });
  renderClassList();
  renderThumbs();
}

// Testen - toggle on/off 
function toggleTest() {
  if (!classifierModel) {
    document.getElementById('test-status').textContent = 'Bitte zuerst ein Modell trainieren oder laden';
    return;
  }
  
  isTestActive = !isTestActive;
  const testBtn = document.getElementById('test-capture');
  
  if (isTestActive) {
    testBtn.textContent = 'Stop';
    testBtn.classList.add('active');
    testInterval = setInterval(testModel, testRate);
  } else {
    clearInterval(testInterval);
    testBtn.textContent = 'Testen';
    testBtn.classList.remove('active');
    document.getElementById('prediction-display').style.display = 'none';
  }
}

async function testModel() {
  if (!classifierModel) return;

  try {
    // Use cached element for performance optimization
    const video = cachedElements.webcamTest || document.getElementById('webcam-test');
    if (!video) return;

    const canvas = document.createElement('canvas');
    canvas.width = CONFIG.IMAGE_SIZE;
    canvas.height = CONFIG.IMAGE_SIZE;
    const ctx = canvas.getContext('2d');
    ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

    const input = tf.browser.fromPixels(canvas).toFloat().div(127.5).sub(1).expandDims(0);
    const emb = mobilenetModel.infer(input, true);
    const rawPrediction = await classifierModel.predict(emb).data();

    // Apply smoothing if enabled
    const prediction = CONFIG.PREDICTION_SMOOTHING ? smoothPrediction(rawPrediction) : rawPrediction;

    // Find the top two classes with highest probability
    let maxProb = 0;
    let maxIndex = 0;
    let secondMaxProb = 0;
    for (let i = 0; i < classes.length; i++) {
      if (prediction[i] > maxProb) {
        secondMaxProb = maxProb;
        maxProb = prediction[i];
        maxIndex = i;
      } else if (prediction[i] > secondMaxProb) {
        secondMaxProb = prediction[i];
      }
    }

    // Calculate confidence margin between top two predictions
    const confidenceMargin = maxProb - secondMaxProb;
    const isConfident = maxProb >= CONFIG.MIN_PREDICTION_CONFIDENCE &&
                        confidenceMargin >= CONFIG.MIN_CONFIDENCE_MARGIN;

    // Display the prediction with confidence threshold - use cached element
    const predDisplay = cachedElements.predictionDisplay || document.getElementById('prediction-display');
    if (predDisplay) {
      if (isConfident) {
        // High confidence and clear winner - show the prediction
        const predictionText = `${classes[maxIndex]}: ${(maxProb * 100).toFixed(1)}%`;
        predDisplay.textContent = predictionText;
        predDisplay.style.backgroundColor = 'rgba(187, 239, 83, 0.9)'; // Bright neon green
      } else {
        // Low confidence or ambiguous predictions - show "uncertain"
        predDisplay.textContent = translate('status.uncertain') || 'Unsicher';
        predDisplay.style.backgroundColor = 'rgba(158, 158, 158, 0.9)'; // Gray
      }
      predDisplay.style.display = 'block';
    }

    // Clean up tensors
    input.dispose();
    emb.dispose();
  } catch (error) {
    console.error('Error during prediction:', error);
    // Stop testing on error to prevent continuous failures
    if (isTestActive) {
      toggleTest();
    }
    document.getElementById('test-status').textContent = 'Fehler bei der Vorhersage - bitte Modell neu laden';
  }
}
// Tryout - toggle on/off 
function toggleTryout() {
  if (!classifierModel) {
    console.log('No model loaded for tryout');
    return;
  }

  isTryoutActive = !isTryoutActive;

  if (isTryoutActive) {
    console.log('Starting tryout interval');
    tryoutInterval = setInterval(tryoutModel, testRate);
  } else {
    console.log('Stopping tryout interval');
    clearInterval(tryoutInterval);

    // Hide prediction displays
    const applyPred = document.getElementById('apply-prediction');
    if (applyPred) applyPred.style.display = 'none';
  }
}

let makeCodeIsReady = false;

window.addEventListener("message", (event) => {
    const msg = event.data;

    if (msg.type === "pxteditor" && msg.action === "editorloaded") {
        console.log("MakeCode Editor ist bereit");
        makeCodeIsReady = true;
    }
});


async function tryoutModel() {
  if (!classifierModel) return;
  if (!mobilenetModel) return;

  try {
    // Use cached webcam element (performance optimization)
    const video = cachedElements.webcamApply || document.getElementById('webcam-apply');
    if (!video) return;

    const canvas = document.createElement('canvas');
    canvas.width = CONFIG.IMAGE_SIZE;
    canvas.height = CONFIG.IMAGE_SIZE;
    const ctx = canvas.getContext('2d');
    ctx.drawImage(video, 0, 0, canvas.width, canvas.height);

    const input = tf.browser.fromPixels(canvas).toFloat().div(127.5).sub(1).expandDims(0);
    const emb = mobilenetModel.infer(input, true);
    const rawPrediction = await classifierModel.predict(emb).data();

    // Apply smoothing if enabled
    const prediction = CONFIG.PREDICTION_SMOOTHING ? smoothPrediction(rawPrediction) : rawPrediction;

    // Find the top two classes with highest probability
    let maxProb = 0;
    let maxIndex = 0;
    let secondMaxProb = 0;
    for (let i = 0; i < classes.length; i++) {
      if (prediction[i] > maxProb) {
        secondMaxProb = maxProb;
        maxProb = prediction[i];
        maxIndex = i;
      } else if (prediction[i] > secondMaxProb) {
        secondMaxProb = prediction[i];
      }
    }

    // Calculate confidence margin between top two predictions
    const confidenceMargin = maxProb - secondMaxProb;
    const isConfident = maxProb >= CONFIG.MIN_PREDICTION_CONFIDENCE &&
                        confidenceMargin >= CONFIG.MIN_CONFIDENCE_MARGIN;

    // Only display prediction if confidence is above threshold
    const applyPred = cachedElements.applyPrediction || document.getElementById('apply-prediction');
    if (applyPred) {
      if (isConfident) {
        // High confidence and clear winner - show the prediction
        const predictionText = `${classes[maxIndex]}: ${(maxProb * 100).toFixed(1)}%`;
        applyPred.textContent = predictionText;
        applyPred.style.backgroundColor = 'rgba(187, 239, 83, 0.9)'; // Bright neon green
      } else {
        // Low confidence or ambiguous predictions - show "uncertain"
        applyPred.textContent = translate('status.uncertain') || 'Unsicher';
        applyPred.style.backgroundColor = 'rgba(158, 158, 158, 0.9)'; // Gray
      }
      applyPred.style.display = 'block';
    }

    // Bluetooth - only send prediction if confident
    if (rxCharacteristic && isConfident) {
      sendPrediction(classes[maxIndex], maxProb);
    }

    // Tensors bereinigen
    input.dispose();
    emb.dispose();
  } catch (error) {
    console.error('Error during tryout prediction:', error);
    // Stop tryout on error to prevent continuous failures
    if (isTryoutActive) {
      toggleTryout();
    }
    // Update tryout status if element exists (not in Apply view)
    const tryoutStatus = document.getElementById('tryout-status');
    if (tryoutStatus) {
      tryoutStatus.textContent = 'Fehler bei der Vorhersage - bitte Modell neu laden';
    }
  }
}


// Bluetooth-Funktionen – aktualisiert, um der funktionierenden Implementierung zu entsprechen 
async function connectButtonPressed() {
  try {
    console.log("Requesting Bluetooth Device...");
    uBitDevice = await navigator.bluetooth.requestDevice({
      filters: [{ namePrefix: "Calliope mini" }],
      optionalServices: [UART_SERVICE_UUID]
    });

    uBitDevice.addEventListener('gattserverdisconnected', onDisconnected);

    console.log("Connecting to GATT Server...");
    const server = await uBitDevice.gatt.connect();

    console.log("Getting Service...");
    const service = await server.getPrimaryService(UART_SERVICE_UUID);

    console.log("Getting Characteristics...");
    const txCharacteristic = await service.getCharacteristic(
      UART_TX_CHARACTERISTIC_UUID
    );
    txCharacteristic.startNotifications();
    txCharacteristic.addEventListener(
      "characteristicvaluechanged",
      onTxCharacteristicValueChanged
    );
    rxCharacteristic = await service.getCharacteristic(
      UART_RX_CHARACTERISTIC_UUID
    );
    
    // Update UI
    document.getElementById('bluetooth-status').textContent = `Verbunden mit ${uBitDevice.name}`;
    document.getElementById('bt-status-indicator').classList.add('connected');
    document.getElementById('bt-status-text').textContent = `Verbunden mit ${uBitDevice.name}`;
    document.getElementById('scan-bluetooth').style.display = 'none';
    document.getElementById('disconnect-bluetooth').style.display = 'block';
  } catch (error) {
    console.log(error);
    document.getElementById('bluetooth-status').textContent = 'Verbindung fehlgeschlagen';
  }
}

function disconnectButtonPressed() {
  console.log("Disconnect button pressed");

  if (!uBitDevice) {
    console.log("No device to disconnect");
    return;
  }

  // Try to disconnect
  try {
    if (uBitDevice.gatt && uBitDevice.gatt.connected) {
      console.log("Disconnecting Bluetooth device...");
      uBitDevice.gatt.disconnect();
    }
  } catch (error) {
    console.error("Error during disconnect:", error);
  }

  // Force cleanup regardless of connection state
  setTimeout(() => {
    console.log("Forcing cleanup after disconnect");

    // Clear references
    rxCharacteristic = null;
    const oldDevice = uBitDevice;
    uBitDevice = null;

    // Update UI
    const statusIndicator = document.getElementById('bt-status-indicator');
    const statusText = document.getElementById('bt-status-text');
    const bluetoothStatus = document.getElementById('bluetooth-status');
    const scanBtn = document.getElementById('scan-bluetooth');
    const disconnectBtn = document.getElementById('disconnect-bluetooth');

    if (statusIndicator) statusIndicator.classList.remove('connected');
    if (statusText) statusText.textContent = translate('tryout.notConnected');
    if (bluetoothStatus) bluetoothStatus.textContent = translate('tryout.readyToConnect');
    if (scanBtn) scanBtn.style.display = 'block';
    if (disconnectBtn) disconnectBtn.style.display = 'none';

    console.log("Disconnect complete");
  }, 300);
}

function onDisconnected(event) {
  let device = event.target;
  console.log(`Device ${device.name} is disconnected.`);

  // Clean up Bluetooth references
  rxCharacteristic = null;
  uBitDevice = null;

  // Don't stop predictions - they can continue showing on screen
  // The sendPrediction function already checks if Bluetooth is connected
  console.log('Bluetooth disconnected, but predictions continue (without sending to device)');

  // Update UI with translations
  const bluetoothStatus = document.getElementById('bluetooth-status');
  const statusIndicator = document.getElementById('bt-status-indicator');
  const statusText = document.getElementById('bt-status-text');
  const scanBtn = document.getElementById('scan-bluetooth');
  const disconnectBtn = document.getElementById('disconnect-bluetooth');

  if (bluetoothStatus) bluetoothStatus.textContent = translate('tryout.disconnected');
  if (statusIndicator) statusIndicator.classList.remove('connected');
  if (statusText) statusText.textContent = translate('tryout.notConnected');
  if (scanBtn) scanBtn.style.display = 'block';
  if (disconnectBtn) disconnectBtn.style.display = 'none';
}

async function sendUART(text) {
  // Check if Bluetooth is still connected
  if (!rxCharacteristic || !uBitDevice || !uBitDevice.gatt.connected) {
    console.log('Bluetooth not connected, skipping send');
    return;
  }

  let encoder = new TextEncoder();
  // Sicherstellen, dass der Text mit einem Zeilenumbruchzeichen endet, damit er auf dem Calliope mini korrekt analysiert werden kann.
  const message = text + "\n";
  queueGattOperation(() => rxCharacteristic.writeValue(encoder.encode(message))
      .then(() => console.log(`Sent: "${message}"`))
      .catch(error => {
        console.error('Fehler beim Senden der Daten:', error);
        // If send fails, device might be disconnected
        if (!uBitDevice.gatt.connected) {
          console.log('Device disconnected during send');
        }
      }));
}



// Zustandsverwaltungsfunktionen für die Erkennung von Klassenänderungen


function startPredictionTest() {
    lastDetectedClass = null;
    isFirstPrediction = true;
    console.log("%c[PREDICTION] Test started - Ready to send first prediction", "color:#4da6ff;font-weight:bold;");
}

function stopPredictionTest() {
    lastDetectedClass = null;
    isFirstPrediction = true;
    console.log("%c[PREDICTION] Test stopped", "color:#4da6ff;font-weight:bold;");
}

function sendPrediction(detectedClass, certainty) {
    // Early exit if Bluetooth not connected
    if (!rxCharacteristic || !uBitDevice || !uBitDevice.gatt.connected) {
      return;
    }

    const alwaysSend = document.getElementById("send-every-prediction")?.checked ?? false;

    // Sendeintervall begrenzen
    const now = Date.now();
    if (now - lastSendTime < SEND_INTERVAL_MS) return;
    
    // Beide Modi haben unterschiedliche Bedingungen
    if (alwaysSend) {
        if (certainty >= CONFIG.MIN_PREDICTION_CONFIDENCE) {
            sendUART(detectedClass);
            lastSendTime = now;
            console.log("[SEND] ALWAYS mode:", detectedClass);
        }
        return;
    }

    // Normalmodus: nur bei Änderung + >70%
    const classChanged = detectedClass !== lastDetectedClass;

    if ((isFirstPrediction || classChanged) && certainty >= CONFIG.MIN_PREDICTION_CONFIDENCE) {
        sendUART(detectedClass);
        lastDetectedClass = detectedClass;
        isFirstPrediction = false;
        lastSendTime = now;

        console.log("[SEND] CHANGE mode:", detectedClass);
    }
}


function queueGattOperation(operation) {
   queue = queue.then(operation, operation);
   return queue;
}

function onTxCharacteristicValueChanged(event) {
  let receivedData = [];
  for (var i = 0; i < event.target.value.byteLength; i++) {
    receivedData[i] = event.target.value.getUint8(i);
  }

  const receivedString = String.fromCharCode.apply(null, receivedData);
  console.log(receivedString);
  if (receivedString === "S") {
    console.log("Shaken!");
  }
}

// Modell speichern
async function saveModel() {
  if (!classifierModel) {
    alert('Kein trainiertes Modell vorhanden');
    return;
  }
  
  document.getElementById('model-info').textContent = 'Speichere Modell...';
  
  try {
    // ZIP-Datei erstellen
    const zip = new JSZip();
    
    // Metadaten sichern
    modelMetadata.date = new Date().toISOString();
    modelMetadata.classes = classes;
    zip.file('metadata.json', new Blob([JSON.stringify(modelMetadata)], {type: 'application/json'}));
    
    // Integrierte Speicherfunktion von TensorFlow.js nutzen, um Modellartefakte abzurufen.
    const modelArtifacts = await classifierModel.save(tf.io.withSaveHandler(async (artifacts) => {
      //Modelltopologie speichern
      zip.file('model.json', new Blob([JSON.stringify(artifacts.modelTopology)], {type: 'application/json'}));
      
      // Gewichtsspezifikationen speichern
      zip.file('weights.json', new Blob([JSON.stringify(artifacts.weightSpecs)], {type: 'application/json'}));
      
      // Gewichtsdaten speichern
      zip.file('weights.bin', new Blob([artifacts.weightData], {type: 'application/octet-stream'}));
      
      // Dummy-Modellinformation zurückgeben, da wir uns um das eigentliche Speichern kümmern.
      return {modelArtifactsInfo: {dateSaved: new Date()}};
    }));
    
    // Zip-Datei erstellen und herunterladen
    const content = await zip.generateAsync({type: 'blob'});
    saveAs(content, `teachable_machine_model_${Date.now()}.zip`);
    
    document.getElementById('model-info').textContent = 'Modell erfolgreich gespeichert';
  } catch (error) {
    console.error('Fehler beim Speichern des Modells:', error);
    document.getElementById('model-info').textContent = 'Fehler beim Speichern: ' + error.message;
  }
}

// Modell laden
async function loadModel(file) {
  document.getElementById('model-info').textContent = 'Lade Modell...';
  
  try {
    // Read the file as an ArrayBuffer first
    const arrayBuffer = await file.arrayBuffer();
    
    const zip = new JSZip();
    const zipContent = await zip.loadAsync(arrayBuffer);
    
    // Check if all required files exist
    if (!zipContent.file('model.json') || !zipContent.file('weights.json') || !zipContent.file('weights.bin')) {
      throw new Error('Modell-Datei ist ungültig oder beschädigt');
    }
    
    // Load metadata
    let loadedClasses = [];
    if (zipContent.file('metadata.json')) {
      const metadataFile = await zipContent.file('metadata.json').async('string');
      modelMetadata = JSON.parse(metadataFile);
      loadedClasses = modelMetadata.classes || [];
    }
    
    // Load model topology
    const modelFile = await zipContent.file('model.json').async('string');
    const modelTopology = JSON.parse(modelFile);
    
    // Load weight specs
    const weightSpecsFile = await zipContent.file('weights.json').async('string');
    const weightSpecs = JSON.parse(weightSpecsFile);
    
    // Load weights
    const weightsFile = await zipContent.file('weights.bin').async('blob');
    const weightData = await weightsFile.arrayBuffer();
    
    // Create model artifacts
    const modelArtifacts = {
      modelTopology: modelTopology,
      weightSpecs: weightSpecs,
      weightData: new Uint8Array(weightData)
    };
    
    // Load model from artifacts using TensorFlow.js built-in method
    classifierModel = await tf.loadLayersModel(tf.io.fromMemory(modelArtifacts));
    
    // Clear current classes and examples
    classes = [];
    for (const className in examples) {
      delete examples[className];
    }
    
    // Initialize examples object for each loaded class
    loadedClasses.forEach(className => {
      classes.push(className);
      examples[className] = [];
    });
    
    // Reset training history
    trainingHistory = {
      epochs: [],
      accuracy: [],
      loss: []
    };
    
    // Update UI
    renderClassList();
    if (classes.length > 0) {
      setActiveClass(classes[0]);
    }
    
    // Show model details button since we have a trained model
    const modelDetailsSection = document.getElementById('step-model-details');
    if (modelDetailsSection) {
      modelDetailsSection.classList.add('visible');
    }

    // Show project download button since we have a trained model
    const projectDownloadSection = document.getElementById('step-project-download');
    if (projectDownloadSection) {
      projectDownloadSection.classList.add('visible');
    }

    // Show notification about loaded classes
    showNotification(`Modell mit ${loadedClasses.length} Klassen geladen: ${loadedClasses.join(', ')}`);

    document.getElementById('model-info').textContent = `${translate('status.modelLoaded')} "${modelMetadata.name}" ${translate('status.projectLoaded').toLowerCase()} (${new Date(modelMetadata.date).toLocaleString(currentLanguage)})`;
    document.getElementById('test-status').textContent = translate('status.modelReadyTest');
    console.log('Model loaded successfully');
    // Training abgeschlossen → Hinweis ---
    showNotification('Training abgeschlossen – das Modell ist nun im Bereich „Ausprobieren" verfügbar.');

  } catch (error) {
    console.error('Fehler beim Laden des Modells:', error);
    document.getElementById('model-info').textContent = 'Fehler beim Laden: ' + error.message;
  }
}

// Tryout Modell laden 
async function loadTryoutModel(file) {
  document.getElementById('tryout-model-info').textContent = 'Lade Modell...';
  
  try {
    // Read the file as an ArrayBuffer first
    const arrayBuffer = await file.arrayBuffer();
    
    const zip = new JSZip();
    const zipContent = await zip.loadAsync(arrayBuffer);
    
    // Check if all required files exist
    if (!zipContent.file('model.json') || !zipContent.file('weights.json') || !zipContent.file('weights.bin')) {
      throw new Error('Modell-Datei ist ungültig oder beschädigt');
    }
    
    // Load metadata
    let loadedClasses = [];
    if (zipContent.file('metadata.json')) {
      const metadataFile = await zipContent.file('metadata.json').async('string');
      modelMetadata = JSON.parse(metadataFile);
      loadedClasses = modelMetadata.classes || [];
    }
    
    // Load model topology
    const modelFile = await zipContent.file('model.json').async('string');
    const modelTopology = JSON.parse(modelFile);
    
    // Load weight specs
    const weightSpecsFile = await zipContent.file('weights.json').async('string');
    const weightSpecs = JSON.parse(weightSpecsFile);
    
    // Load weights
    const weightsFile = await zipContent.file('weights.bin').async('blob');
    const weightData = await weightsFile.arrayBuffer();
    
    // Create model artifacts
    const modelArtifacts = {
      modelTopology: modelTopology,
      weightSpecs: weightSpecs,
      weightData: new Uint8Array(weightData)
    };
    
    // Load model from artifacts using TensorFlow.js built-in method
    classifierModel = await tf.loadLayersModel(tf.io.fromMemory(modelArtifacts));
    
    // Clear current classes and examples
    classes = [];
    for (const className in examples) {
      delete examples[className];
    }
    
    // Initialize examples object for each loaded class
    loadedClasses.forEach(className => {
      classes.push(className);
      examples[className] = [];
    });
    
    // Reset training history
    trainingHistory = {
      epochs: [],
      accuracy: [],
      loss: []
    };
    
    // Update UI
    renderClassList();
    if (classes.length > 0) {
      setActiveClass(classes[0]);
    }
    
    // Enable details button
    document.getElementById('model-details').disabled = false;
    
    // Show notification about loaded classes
    showNotification(`Modell mit ${loadedClasses.length} Klassen geladen: ${loadedClasses.join(', ')}`);

    document.getElementById('tryout-model-info').textContent = `${translate('status.modelLoaded')} "${modelMetadata.name}" ${translate('status.projectLoaded').toLowerCase()} (${new Date(modelMetadata.date).toLocaleString(currentLanguage)})`;

    // Update tryout status if element exists (not in Apply view)
    const tryoutStatus = document.getElementById('tryout-status');
    if (tryoutStatus) {
      tryoutStatus.textContent = translate('status.modelReadyTryout');
    }

    // Start tryout automatically in Apply view
    const currentView = document.getElementById('apply-view');
    if (currentView && currentView.style.display !== 'none') {
      // We're in the Apply view, start predictions automatically
      if (!isTryoutActive && classifierModel) {
        isTryoutActive = true;
        tryoutInterval = setInterval(tryoutModel, testRate);
        console.log('Auto-started tryout after model load in Apply view');
      }
    }

    console.log('Model loaded successfully');
  } catch (error) {
    console.error('Fehler beim Laden des Modells:', error);
    document.getElementById('tryout-model-info').textContent = 'Fehler beim Laden: ' + error.message;
  }
}

// Shared canvas for dataset preparation (reused for performance)
let sharedCanvas = null;
let sharedCtx = null;

// Dataset vorbereiten
async function prepareDataset() {
  console.log('Preparing dataset...');

  if (!mobilenetModel) {
    throw new Error('MobileNet model is not loaded yet!');
  }

  const promises = [];
  const labelToIndex = {};

  classes.forEach((c, idx) => {
    labelToIndex[c] = idx;
  });

  console.log(`Processing ${classes.length} classes`);

  // Reuse canvas instead of creating new one each time
  if (!sharedCanvas) {
    sharedCanvas = document.createElement("canvas");
    sharedCtx = sharedCanvas.getContext("2d");
    sharedCanvas.width = CONFIG.IMAGE_SIZE;
    sharedCanvas.height = CONFIG.IMAGE_SIZE;
  }
  const canvas = sharedCanvas;
  const ctx = sharedCtx;

  const AUGMENT_COPIES = CONFIG.AUGMENT_COPIES;

  // Sammle ALLE Promises für alle Bilder
  for (const cls of classes) {
    const idx = labelToIndex[cls];
    const oneHot = new Array(classes.length).fill(0);
    oneHot[idx] = 1;

    console.log(`Processing class: ${cls} with ${examples[cls].length} examples`);

    for (const ex of examples[cls]) {
      const promise = new Promise((resolve) => {
        const img = new Image();
        img.src = ex.data;
        img.crossOrigin = "anonymous"; // für Canvas-Sicherheit

        img.onload = () => {
          const tensors = [];

          for (let k = 0; k < AUGMENT_COPIES; k++) {
            ctx.save();

            // Enhanced Augmentation: Jitter, Scale, Rotation, Flip, Brightness
            const jitterX = (Math.random() - 0.5) * CONFIG.AUGMENT_JITTER_RANGE;
            const jitterY = (Math.random() - 0.5) * CONFIG.AUGMENT_JITTER_RANGE;
            const scale = 1 + (Math.random() - 0.5) * CONFIG.AUGMENT_SCALE_RANGE;
            const rotation = (Math.random() - 0.5) * CONFIG.AUGMENT_ROTATION_RANGE * (Math.PI / 180);
            const flipH = CONFIG.AUGMENT_FLIP_HORIZONTAL && Math.random() > 0.5;
            const brightness = 1 + (Math.random() - 0.5) * CONFIG.AUGMENT_BRIGHTNESS_RANGE;

            ctx.clearRect(0, 0, CONFIG.IMAGE_SIZE, CONFIG.IMAGE_SIZE);

            // Apply transformations from center
            ctx.translate(CONFIG.IMAGE_SIZE / 2, CONFIG.IMAGE_SIZE / 2);
            ctx.rotate(rotation);
            if (flipH) ctx.scale(-1, 1);
            ctx.scale(scale, scale);
            ctx.translate(-CONFIG.IMAGE_SIZE / 2 + jitterX, -CONFIG.IMAGE_SIZE / 2 + jitterY);

            // Apply brightness by using globalAlpha and composite operations
            ctx.globalAlpha = Math.min(1, Math.max(0.5, brightness));
            ctx.drawImage(img, 0, 0, CONFIG.IMAGE_SIZE, CONFIG.IMAGE_SIZE);
            ctx.restore();

            // MobileNet Features extrahieren
            const imgTensor = tf.tidy(() => {
              let t = tf.browser.fromPixels(canvas)
                .resizeNearestNeighbor([CONFIG.IMAGE_SIZE, CONFIG.IMAGE_SIZE])
                .toFloat();

              // Apply brightness adjustment
              if (brightness !== 1) {
                t = t.mul(brightness).clipByValue(0, 255);
              }

              // Normalize for MobileNet
              t = t.div(127.5).sub(1).expandDims(0);

              return mobilenetModel.infer(t, true);
            });

            tensors.push(imgTensor);
          }

          resolve({ tensors, oneHot });
        };

        img.onerror = () => {
          console.error('Failed to load image');
          resolve(null);
        };
      });

      promises.push(promise);
    }
  }

  // Warte auf ALLE Bilder
  const results = await Promise.all(promises);

  // Filtere fehlgeschlagene Bilder und sammle Tensors/Labels
  const xs = [];
  const ys = [];

  for (const result of results) {
    if (!result) continue; // skip fehlgeschlagene

    // Alle Augmentierungen dieser Instanz zu xs/ys hinzufügen
    for (const tensor of result.tensors) {
      xs.push(tensor);
      ys.push(result.oneHot);
    }
  }

  if (xs.length === 0) {
    throw new Error("Keine gültigen Trainingsbilder gefunden!");
  }

  const xsTensor = tf.concat(xs, 0);
  const ysTensor = tf.tensor2d(ys);

  console.log(`Training mit ${xsTensor.shape[0]} Samples, ${classes.length} Klassen`);

  return { xs: xsTensor, ys: ysTensor, labelToIndex };
}


function createClassifier(numClasses, inputShape) {
  const model = tf.sequential();

  // First hidden layer with batch normalization
  model.add(tf.layers.dense({
    units: CONFIG.CLASSIFIER_HIDDEN_UNITS_1,
    inputShape: [inputShape],
    kernelRegularizer: tf.regularizers.l2({ l2: CONFIG.CLASSIFIER_L2_REGULARIZATION })
  }));
  model.add(tf.layers.batchNormalization());
  model.add(tf.layers.activation({ activation: 'relu' }));
  model.add(tf.layers.dropout({ rate: CONFIG.CLASSIFIER_DROPOUT_RATE }));

  // Second hidden layer with batch normalization
  model.add(tf.layers.dense({
    units: CONFIG.CLASSIFIER_HIDDEN_UNITS_2,
    kernelRegularizer: tf.regularizers.l2({ l2: CONFIG.CLASSIFIER_L2_REGULARIZATION })
  }));
  model.add(tf.layers.batchNormalization());
  model.add(tf.layers.activation({ activation: 'relu' }));
  model.add(tf.layers.dropout({ rate: CONFIG.CLASSIFIER_DROPOUT_RATE * 0.5 }));

  // Output layer
  model.add(tf.layers.dense({
    units: numClasses,
    activation: "softmax"
  }));

  model.compile({
    optimizer: tf.train.adam(CONFIG.CLASSIFIER_LEARNING_RATE),
    loss: "categoricalCrossentropy",
    metrics: ["accuracy"]
  });

  return model;
}

// Helper functions for training status with spinner
function showTrainingSpinner(statusElement, message) {
  statusElement.innerHTML = `<div class="status-with-spinner"><span class="training-spinner"></span><span>${message}</span></div>`;
  statusElement.style.color = '#007acc';
}

function hideTrainingSpinner(statusElement, message, color = '#4CAF50') {
  statusElement.innerHTML = `<span id="train-status-text">${message}</span>`;
  statusElement.style.color = color;
}

async function trainModel() {
  try {
    const status = document.getElementById("train-status");

    // Check if MobileNet is loaded
    if (!mobilenetModel) {
      showTrainingSpinner(status, translate('status.processingImages'));

      // Wait for MobileNet to load
      while (!mobilenetModel) {
        await new Promise(resolve => setTimeout(resolve, 100));
      }
    }

    // Show spinner while preparing dataset
    showTrainingSpinner(status, translate('status.processingImages'));

    // Reset training history
    trainingHistory = {
      epochs: [],
      accuracy: [],
      loss: []
    };

    const dataset = await prepareDataset();
    console.log('Dataset prepared:', dataset.xs.shape);

    // Always create a new model for training (in case number of classes changed)
    const embSize = dataset.xs.shape[1];
    console.log('Creating classifier with input shape:', embSize, 'and', classes.length, 'classes');

    classifierModel = createClassifier(classes.length, embSize);

    const epochs = parseInt(document.getElementById("epochs").value || CONFIG.DEFAULT_EPOCHS.toString(), 10);
    console.log('Training for', epochs, 'epochs');

    // Enable details button
    document.getElementById('model-details').disabled = false;

    // Calculate batch size - ensure it's at least 1 and not larger than total samples
    const totalSamples = dataset.xs.shape[0];
    const batchSize = Math.max(1, Math.min(CONFIG.DEFAULT_BATCH_SIZE, Math.floor(totalSamples * 0.2)));

    // Use validation split only if we have enough samples
    const validationSplit = totalSamples > 10 ? CONFIG.VALIDATION_SPLIT : 0;

    console.log('Using batch size:', batchSize, 'for', totalSamples, 'samples with validation split:', validationSplit);

    // Show spinner during training
    showTrainingSpinner(status, translate('status.training'));

    // Learning rate decay schedule for better convergence
    const initialLR = CONFIG.CLASSIFIER_LEARNING_RATE;
    const decayRate = 0.96;
    const decaySteps = Math.ceil(epochs / 3);

    // Early stopping to prevent overfitting (with higher patience for augmented data)
    let bestValLoss = Infinity;
    let patience = 10; // Increased from 5 to allow more time for convergence with augmented data
    let patienceCounter = 0;

    const history = await classifierModel.fit(dataset.xs, dataset.ys, {
      epochs,
      shuffle: true,
      batchSize,
      validationSplit,
      callbacks: {
        onEpochEnd: async (e, l) => {
          // Update training history
          trainingHistory.epochs.push(e + 1);
          trainingHistory.accuracy.push(l.acc);
          trainingHistory.loss.push(l.loss);

          // Apply learning rate decay every decaySteps epochs
          if ((e + 1) % decaySteps === 0) {
            const newLR = initialLR * Math.pow(decayRate, Math.floor((e + 1) / decaySteps));
            classifierModel.optimizer.learningRate = newLR;
            console.log(`Learning rate decayed to: ${newLR.toFixed(6)}`);
          }

          // Early stopping check (only if we have validation data and enough epochs)
          // Only enable early stopping after at least 15 epochs to give model time to learn
          if (validationSplit > 0 && l.val_loss !== undefined && e >= 14) {
            if (l.val_loss < bestValLoss) {
              bestValLoss = l.val_loss;
              patienceCounter = 0;
            } else {
              patienceCounter++;
              if (patienceCounter >= patience) {
                console.log(`Early stopping at epoch ${e + 1} due to no improvement in validation loss`);
                classifierModel.stopTraining = true;
              }
            }
          }

          const accDisplay = (l.acc * 100).toFixed(1);
          const valAccDisplay = l.val_acc ? ` | ${translate('status.val')}: ${(l.val_acc * 100).toFixed(1)}%` : '';
          const statusText = `${translate('status.training')} - ${translate('status.epoch')} ${e+1}: ${accDisplay}%${valAccDisplay}`;
          showTrainingSpinner(status, statusText);
          console.log(`${translate('status.epoch')} ${e+1}: ${accDisplay}%${valAccDisplay}`);
        }
      }
    });

    // Cleanup
    dataset.xs.dispose();
    dataset.ys.dispose();

    // Update UI after training - hide spinner
    hideTrainingSpinner(status, translate('status.trainingComplete'), '#4CAF50');
    document.getElementById('test-status').textContent = translate('status.modelReadyTest');

    // Show model details button after training completes
    const modelDetailsSection = document.getElementById('step-model-details');
    if (modelDetailsSection) {
      modelDetailsSection.classList.add('visible');
    }

    // Show project download button after training completes
    const projectDownloadSection = document.getElementById('step-project-download');
    if (projectDownloadSection) {
      projectDownloadSection.classList.add('visible');
    }

    // Show save model button after training completes
    const saveModelBtn = document.getElementById('save-model');
    if (saveModelBtn) {
      saveModelBtn.style.display = 'inline-block';
    }

    console.log('Training completed successfully');

  } catch (error) {
    console.error("Training error:", error);
    const status = document.getElementById("train-status");
    hideTrainingSpinner(status, translate('status.trainingFailed'), '#F44336');
    alert(translate('status.trainingFailed') + ": " + error.message);
  }
}


// Tab handling 
function setupTabs() {
  const tabs = document.querySelectorAll('.tab');
  const tabContents = document.querySelectorAll('.tab-content');
  
  tabs.forEach(tab => {
    tab.addEventListener('click', () => {
      const tabId = tab.getAttribute('data-tab');
      
      // Deactivate all tabs and contents
      tabs.forEach(t => t.classList.remove('active'));
      tabContents.forEach(c => c.classList.remove('active'));
      
      // Activate selected tab and content
      tab.classList.add('active');
      document.getElementById(`${tabId}-tab`).classList.add('active');
    });
  });
}

// Model Details Tab handling 
function setupModelDetailsTabs() {
  const tabs = document.querySelectorAll('.model-details-tab');
  const tabContents = document.querySelectorAll('.model-details-content');
  
  tabs.forEach(tab => {
    tab.addEventListener('click', () => {
      const tabId = tab.getAttribute('data-tab');
      
      // Deactivate all tabs and contents
      tabs.forEach(t => t.classList.remove('active'));
      tabContents.forEach(c => c.classList.remove('active'));
      
      // Activate selected tab and content
      tab.classList.add('active');
      document.getElementById(`${tabId}-tab`).classList.add('active');
    });
  });
}

// Navigation setup 
function setupNavigation() {

document.querySelectorAll('.header-btn').forEach(btn => {
  btn.addEventListener('click', () => {
    const view = btn.getAttribute('data-view');
    switchView(view);

    document.querySelectorAll('.header-btn').forEach(b => b.classList.remove('active'));
    btn.classList.add('active');
  });
});

}

document.addEventListener('DOMContentLoaded', () => {
  // Check URL parameters for mobile mode
  const urlParams = new URLSearchParams(window.location.search);
  const isMobileMode = urlParams.get('mobile') === 'true';

  // Hide "Programmieren" view and button in mobile mode
  if (isMobileMode) {
    const tryoutBtn = document.querySelector('.header-btn[data-view="tryout"]');
    const tryoutView = document.getElementById('tryout-view');
    if (tryoutBtn) tryoutBtn.style.display = 'none';
    if (tryoutView) tryoutView.style.display = 'none';
    console.log('Mobile mode activated - MakeCode editor hidden');
  }

  // Initialize language based on browser detection
  changeLanguage(currentLanguage);

  // Initialize cached DOM elements for performance
  initCachedElements();

  setupTabs();
  setupNavigation();
  setupModelDetailsTabs();

  // Capture button - press and hold
const captureBtn = document.getElementById('capture');
if (captureBtn) {
  captureBtn.addEventListener('mousedown', startCapture);
  captureBtn.addEventListener('mouseup', stopCapture);
  captureBtn.addEventListener('mouseleave', stopCapture);
  captureBtn.addEventListener('touchstart', (e) => {
    e.preventDefault();
    startCapture();
  });
  captureBtn.addEventListener('touchend', (e) => {
    e.preventDefault();
    stopCapture();
  });
}

// Beim Laden -> Training/Test aktivieren
document.querySelector('.header-btn[data-view="training"]')
  .classList.add('active');


  document.getElementById('create-class').onclick = () => {
    const name = document.getElementById('new-class-name').value.trim();
    if (!name) return;
    addClass(name);
    document.getElementById('new-class-name').value = '';
  };
  document.getElementById('active-class').onchange = e => setActiveClass(e.target.value);
  
  document.getElementById('file-input').onchange = async e => {
    if (!e.target.files.length) return;
    
    // Check if any of the files is a zip file
    const zipFiles = Array.from(e.target.files).filter(file => file.name.endsWith('.zip'));
    const imageFiles = Array.from(e.target.files).filter(file => !file.name.endsWith('.zip'));
    
    // Process zip files
    if (zipFiles.length > 0) {
      for (const zipFile of zipFiles) {
        await processZipFile(zipFile);
      }
    }
    
    // Process regular image files
    if (imageFiles.length > 0) {
      if (!activeClass) {
        alert(translate('status.selectClassFirst'));
        e.target.value = '';
        return;
      }
      
      for (const file of imageFiles) {
        const r = new FileReader();
        r.onload = ev => {
          examples[activeClass].push({ data: ev.target.result });
          renderClassList();
          renderThumbs();
        };
        r.readAsDataURL(file);
      }
    }
    
    e.target.value = ''; // Reset input so same file can be loaded again
  };
  
  document.getElementById('clear-class').onclick = () => {
    if (!activeClass) return;
    examples[activeClass] = [];
    renderClassList();
    renderThumbs();
  };

  document.getElementById('delete-class-btn').onclick = () => {
    if (!activeClass) return;
    deleteClass(activeClass);
  };

  document.getElementById('train').onclick = async () => {
    if (classes.length < 2) return alert(translate('status.minTwoClasses'));
    await trainModel();
  };
  
  // Model details button
  document.getElementById('model-details').onclick = showModelDetails;
  document.getElementById('close-details').onclick = hideModelDetails;
  document.getElementById('dialog-overlay').onclick = hideModelDetails;
  
  // Test button - toggle on/off
  const testBtn = document.getElementById('test-capture');
  if (testBtn) {
    testBtn.addEventListener('click', toggleTest);
  }
  
  // Model save/load buttons
  document.getElementById('save-model').onclick = saveModel;
  document.getElementById('load-model').addEventListener('change', e => {
    if (e.target.files.length > 0) {
      loadModel(e.target.files[0]);
      e.target.value = ''; // Reset input so same file can be loaded again
    }
  });
  
  // Tryout model load button
  document.getElementById('tryout-load-model').addEventListener('change', e => {
    if (e.target.files.length > 0) {
      loadTryoutModel(e.target.files[0]);
      e.target.value = ''; // Reset input so same file can be loaded again
    }
  });
  
  // Download buttons
  document.getElementById('download-all').onclick = downloadAllClassImages;
  
  // Project buttons
  document.getElementById('download-project').onclick = downloadProject;
  document.getElementById('import-project').addEventListener('change', e => {
    if (e.target.files.length > 0) {
      importProject(e.target.files[0]);
      e.target.value = ''; // Reset input so same file can be loaded again
    }
  });
  
  // Import dialog buttons
  document.getElementById('import-cancel').onclick = hideImportDialog;
  document.getElementById('import-confirm').onclick = confirmImport;
  
  // Bluetooth scan button
  document.getElementById('scan-bluetooth').onclick = connectButtonPressed;
  document.getElementById('disconnect-bluetooth').onclick = disconnectButtonPressed;
  



init();

  // Initialize help text on page load
  updateHelpText();
});

</script>


</body>
</html>